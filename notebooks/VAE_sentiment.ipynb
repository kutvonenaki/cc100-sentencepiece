{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GloVe!\n",
      "Vocabulary size withouth special tokens: 400000 Embedding dimension: 50\n",
      "Number of reviews: 568454\n"
     ]
    }
   ],
   "source": [
    "#load the word embeddings\n",
    "import numpy as np\n",
    "\n",
    "filename = 'glove.6B.50d.txt'\n",
    "\n",
    "def loadGloVe(filename):\n",
    "    vocab = []\n",
    "    embd = []\n",
    "    file = open(filename,'r',encoding=\"utf8\")\n",
    "    for line in file.readlines():\n",
    "        row = line.strip().split(' ')\n",
    "        vocab.append(row[0])\n",
    "        embd.append(row[1:])\n",
    "    print('Loaded GloVe!')\n",
    "    file.close()\n",
    "    return vocab,embd\n",
    "\n",
    "\n",
    "vocab,embedding = loadGloVe(filename)\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = len(embedding[0])\n",
    "\n",
    "print('Vocabulary size withouth special tokens:',vocab_size,'Embedding dimension:',embedding_dim)\n",
    "embedding = np.asarray(embedding)\n",
    "\n",
    "#make the vocabulary dictionary, save the 0 for pad, 1 for eos and 2 for unknown\n",
    "\n",
    "vocab_size=vocab_size+3\n",
    "\n",
    "\n",
    "sent_start_token='<GO>'\n",
    "sent_end_token='<EOS>'\n",
    "unknown_word_token='UNK'\n",
    "padding_token='<PAD>'\n",
    "\n",
    "vocab_dict = {}\n",
    "#make the word->index dictionary\n",
    "vocab_dict[padding_token]=0\n",
    "vocab_dict[sent_end_token]=1\n",
    "vocab_dict[sent_start_token]=2\n",
    "vocab_dict[unknown_word_token]=3\n",
    "for i in range(len(vocab)):\n",
    "    vocab_dict[vocab[i]] = i+4\n",
    "    \n",
    "#make the index->word dictionary\n",
    "vocab_inv={}\n",
    "for key, value in vocab_dict.items():\n",
    "    \n",
    "    vocab_inv[value]=key\n",
    "    \n",
    "#load the data food reviews data\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#load the data and peek how it looks\n",
    "Reviews_df = pd.read_csv('Reviews.csv')\n",
    "\n",
    "#cut only the relevant part\n",
    "scores=Reviews_df['Score'].values\n",
    "reviews=Reviews_df['Text'].values\n",
    "num_reviews=len(reviews)\n",
    "\n",
    "print(\"Number of reviews:\", num_reviews)\n",
    "\n",
    "#delete the dataframe from memory\n",
    "del Reviews_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preprocess the sentences into a suitable form\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "NLTK_TWEET_TOKENIZER=TweetTokenizer()\n",
    "\n",
    "reviews_tokenized=[]\n",
    "sentences=[]\n",
    "\n",
    "#compile for removing all weird letters and replace with whitespace\n",
    "regex = re.compile(\"\"\"[,+-\\/.!?*\"'#]\"\"\") #etc\n",
    "\n",
    "#we don't want these as a single words since they mess up stuff\n",
    "unwanted_words=set(['<','>','/','*','[',']','{','}','br',\"'\",\".\",\",\"])\n",
    "\n",
    "for review in reviews:\n",
    "    \n",
    "    temp=[]\n",
    "    for sent in sent_tokenize(review.lower()):\n",
    "    \n",
    "        sentence=sent #+\" \" +sent_end_token don't put the sentence end token here\n",
    "        sent_token=word_tokenize(sentence)\n",
    "        \n",
    "        #cut away weird single special letter words\n",
    "        sent_token=[word for word in sent_token if (word not in unwanted_words)]\n",
    "                \n",
    "        #cut away the words which are not in the vocabulary\n",
    "        num_newwords=0\n",
    "        for word_ind_init in range(len(sent_token)):\n",
    "            \n",
    "            word_ind=word_ind_init+num_newwords\n",
    "            word=sent_token[word_ind]\n",
    "            \n",
    "            if word not in vocab_dict:\n",
    "                \n",
    "                \n",
    "                #if it is and address, change the name to url\n",
    "                word=re.sub(r'http\\S+', 'url', word)\n",
    "                word=re.sub(r'www\\S+', 'url', word)\n",
    "                word=re.sub(r'href\\S+', 'link', word)\n",
    "                \n",
    "                #apply the previously defined regular expressions for cutting the words from -\n",
    "                #and removing excess. etc\n",
    "                #First parameter is the replacement, second parameter is your input string\n",
    "                word=regex.sub(' ', word)\n",
    "                newwords=word.split()\n",
    "            \n",
    "                #loop over new words\n",
    "                for newword_ind,newword in enumerate(newwords):\n",
    "                    \n",
    "                    #if the splitted words are not in dictionary\n",
    "                    if newword not in vocab_dict:\n",
    "                \n",
    "                        newwords[newword_ind]=unknown_word_token\n",
    "           \n",
    "                #attach the new words\n",
    "                sent_token[word_ind:word_ind+1]=newwords\n",
    "            \n",
    "                #print(sent_token)\n",
    "                #increase the counter accordingly\n",
    "                num_newwords+=(len(newwords)-1)\n",
    "                \n",
    "        #join back as sentences\n",
    "        #sentences.append(\" \".join(sent_token))\n",
    "        #sentences.append(sentence)\n",
    "        temp.append(sent_token)\n",
    "    reviews_tokenized.append(temp)\n",
    "    \n",
    "    \n",
    "#save the sentences\n",
    "with open('reviews_tokenized.pickled', 'wb') as fp:\n",
    "    pickle.dump(reviews_tokenized, fp)\n",
    "    \n",
    "del reviews\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after cutting the max sentence len to 15 and min to 4\n",
      "number of sentences: 1312470\n",
      "mean sentence len: 10.0160818914\n",
      "with standard deviation: 3.25511084524\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "#load the sentences and pick and easily trainable subset from the sentences\n",
    "with open ('reviews_tokenized.pickled', 'rb') as fp:\n",
    "    reviews_tokenized = pickle.load(fp)\n",
    "\n",
    "\n",
    "#take sentences which are max 10 words and min 6 words, there are sentences like \"thank you\" and \"!\"\n",
    "#those are better off removed-----------------------\n",
    "\n",
    "max_sent_len=15\n",
    "min_sent_len=4\n",
    "\n",
    "sentence_scores=[]\n",
    "sentences=[]\n",
    "\n",
    "for review_ind,review in enumerate(reviews_tokenized):  \n",
    "    for sentence in review:  \n",
    "        \n",
    "        sent_len=len(sentence)\n",
    "        if (sent_len <= max_sent_len) and (sent_len >= 4):\n",
    "            \n",
    "            sentences.append(sentence)\n",
    "            \n",
    "            #record the review scores for later\n",
    "            sentence_scores.append(scores[review_ind])\n",
    "\n",
    "#delete the reviews from memory\n",
    "del reviews_tokenized \n",
    "\n",
    "lens=np.zeros((len(sentences)))\n",
    "for i,sentence in enumerate(sentences):\n",
    "    \n",
    "    lens[i]=len(sentence)\n",
    "\n",
    "num_sentences=len(sentences)\n",
    "print('after cutting the max sentence len to', max_sent_len,'and min to', min_sent_len)\n",
    "print('number of sentences:', num_sentences)\n",
    "print('mean sentence len:', np.mean(lens))\n",
    "print('with standard deviation:', np.std(lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of words is 13145807\n",
      "number of different words is 40097\n",
      "number of unknowns: 69196 %: 0.5263731621801537\n",
      "after word min frequency is set to: 8\n",
      "number of different words is 15906\n",
      "number of unknowns: 126792 %: 0.9645052601183024\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "#get the distribution of words\n",
    "\n",
    "fdist = nltk.FreqDist()\n",
    "for sentence in sentences:\n",
    "    for word in sentence:\n",
    "        fdist[word] += 1\n",
    "            \n",
    "print('total number of words is',sum(fdist.values()))\n",
    "print('number of different words is',len(fdist))\n",
    "print('number of unknowns:', fdist[unknown_word_token],\"%:\", fdist[unknown_word_token]*100/sum(fdist.values()))\n",
    "\n",
    "#lets cut away the words which are less than 3 times in the vocabulary\n",
    "fdist_new = nltk.FreqDist()\n",
    "\n",
    "minfreq=8\n",
    "for sentence in sentences:\n",
    "    for word_ind,word in enumerate(sentence):\n",
    "            \n",
    "        if fdist[word] < minfreq:\n",
    "            sentence[word_ind]=unknown_word_token\n",
    "            fdist_new[unknown_word_token] += 1\n",
    "                \n",
    "        else:\n",
    "            fdist_new[word] += 1\n",
    "            \n",
    "print('after word min frequency is set to:',minfreq)\n",
    "print('number of different words is',len(fdist_new))\n",
    "print('number of unknowns:', fdist_new[unknown_word_token],\"%:\", fdist_new[unknown_word_token]*100/sum(fdist.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done, new vocabulary size is 15909\n"
     ]
    }
   ],
   "source": [
    "#clean the vocabulary and embeddings to consist only on the words used.\n",
    "used_words=set(fdist_new.keys())\n",
    "\n",
    "new_dict={}\n",
    "#-1 because unknown is already in the sentences\n",
    "new_emb=np.zeros((len(fdist_new)-1,embedding_dim))\n",
    "\n",
    "\n",
    "#loop over pretrained vocabulary\n",
    "newind=3 #reserve 0 to 3 for eos and pad sent end and sent start\n",
    "for key, value in vocab_dict.items():\n",
    "    \n",
    "    if key==unknown_word_token:\n",
    "        continue\n",
    "    \n",
    "    if key in used_words:\n",
    "        \n",
    "        new_dict[key]=newind\n",
    "        new_emb[newind-3,:]=embedding[value,:]\n",
    "        \n",
    "        newind +=1\n",
    "        \n",
    "vocab_dict=new_dict\n",
    "\n",
    "#add the special tokens\n",
    "\n",
    "vocab_dict[padding_token]=0\n",
    "vocab_dict[sent_end_token]=1\n",
    "vocab_dict[sent_start_token]=2\n",
    "vocab_dict[unknown_word_token]=3\n",
    "\n",
    "\n",
    "vocab_inv={}\n",
    "for key, value in vocab_dict.items():\n",
    "    \n",
    "    vocab_inv[value]=key\n",
    "    \n",
    "embedding=new_emb\n",
    "\n",
    "vocab_size=len(vocab_dict.items())\n",
    "\n",
    "print('done, new vocabulary size is', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size in mbs: 78.7482\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#transform the sentences into inputs and targets for the autoencoder\n",
    "\n",
    "#note: make here the save and load sentences\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.contrib import learn\n",
    "\n",
    "\n",
    "#we already did the preprocessing so the tokenizer should just split the words\n",
    "def tokenizer_custom(iterator):\n",
    "    for value in iterator:\n",
    "        \n",
    "        try:\n",
    "            #just return the thing itself since the tokenizing was already done\n",
    "            yield value #.split() #word_tokenize()\n",
    "        except TypeError:       # this is a hack to avoid the error\n",
    "            yield []  \n",
    "            \n",
    "#map the sentences to input vectors with padding            \n",
    "vocab_processor = learn.preprocessing.VocabularyProcessor(\n",
    "    max_document_length=max_sent_len, vocabulary=vocab_dict, tokenizer_fn=tokenizer_custom)\n",
    "\n",
    "#format is senteces, decoding (timesteps)\n",
    "input_sentences = np.array(list(vocab_processor.transform(sentences)))\n",
    "#change to 32bit\n",
    "input_sentences=input_sentences.astype(int)\n",
    "print('input size in mbs:', input_sentences.shape[0]*input_sentences.shape[1]*4/1000000)\n",
    "\n",
    "\n",
    "#now make the encoder and decored inputs/targets\n",
    "#---------------------------------------\n",
    "\n",
    "#special tokens\n",
    "PAD = 0\n",
    "EOS = 1\n",
    "GO = 2\n",
    "UNK = 3\n",
    "\n",
    "\n",
    "#make to list for a better handling\n",
    "input_sentences=input_sentences.tolist()\n",
    "\n",
    "#put the EOS symbol in the beginning of decoder inputs and the eend of decoder outputs\n",
    "decoder_inputs_full=[]\n",
    "decoder_targets_full=[]\n",
    "\n",
    "for sentence in input_sentences:\n",
    "    \n",
    "    #decoder input gets GO as the first feed\n",
    "    decoder_inputs_full.append([GO]+sentence)\n",
    "    \n",
    "    #in output the sentence has to end with EOS\n",
    "    for word_ind, word in enumerate(sentence):\n",
    "    \n",
    "        #if the end is before the maxlen\n",
    "        if word==0:\n",
    "            sentence[word_ind]=EOS\n",
    "            sentence.append(0)\n",
    "            decoder_targets_full.append(sentence)\n",
    "            break\n",
    "\n",
    "        #the sentence is longer than the vector\n",
    "        if (word_ind==max_sent_len-1):\n",
    "            sentence.append(EOS)\n",
    "            decoder_targets_full.append(sentence)\n",
    "            \n",
    "            \n",
    "#change the inputs to numpy arrays\n",
    "decoder_inputs_full=np.array(decoder_inputs_full)\n",
    "decoder_targets_full=np.array(decoder_targets_full)\n",
    "\n",
    "\n",
    "#free memory\n",
    "del input_sentences\n",
    "\n",
    "#make to int32\n",
    "decoder_inputs_full=decoder_inputs_full.astype(int)\n",
    "decoder_targets_full=decoder_targets_full.astype(int)\n",
    "\n",
    "#transpose\n",
    "decoder_inputs_full=np.transpose(decoder_inputs_full)\n",
    "decoder_targets_full=np.transpose(decoder_targets_full)\n",
    "\n",
    "##change the order of inputs for encoder inputs\n",
    "encoder_inputs_full=decoder_targets_full[::-1,:]\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The actual tensorflow code\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import timeit\n",
    "import sys\n",
    "import os\n",
    "\n",
    "#time the program\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "#reset and start session\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "\n",
    "#functions-------------------------------------------------------------\n",
    "\n",
    "#print a list of itegers as a sentence\n",
    "def printsentence(inputarray,reverse=False):\n",
    "     \n",
    "    word_list=[vocab_inv[index] for index in list(inputarray) if (index not in [0,1,2])]\n",
    "    \n",
    "    if reverse:\n",
    "        word_list=word_list[::-1]\n",
    "        \n",
    "    return (\" \".join(word_list))\n",
    "\n",
    "def printandwrite(file, line): #print to screen and write to file\n",
    "\n",
    "    file.write(\"%s \\n\" % line)\n",
    "    print(line)    \n",
    "\n",
    "#feed the next inputs\n",
    "def next_feed(index,keep_prob=1):\n",
    "    \n",
    "    #feed the encoder the inputs in reverse direction for better performance\n",
    "    encoder_inputs_ = encoder_inputs_full[:,index*batch_size:(index+1)*batch_size]\n",
    "    \n",
    "    decoder_targets_ = decoder_targets_full[:,index*batch_size:(index+1)*batch_size]\n",
    "\n",
    "    \n",
    "    #replace the decoder input words with unknown word with probability 1-keep_prob\n",
    "    #this forces the decoder to use the latent code instead\n",
    "    if keep_prob !=1:\n",
    "\n",
    "        inputs_shape=(max_sent_len+1,batch_size)\n",
    "\n",
    "        #careful here to make a copy instead of ending modifying the data\n",
    "        decoder_inputs_= np.zeros(inputs_shape)\n",
    "        decoder_inputs_[:,:] = decoder_inputs_full[:,index*batch_size:(index+1)*batch_size]\n",
    "\n",
    "        #make a replacement mask where True is with probability 1-keep_prob\n",
    "        mask=np.random.binomial(1, 1.0-keep_prob,size=inputs_shape).astype(np.bool)\n",
    "\n",
    "        #we want the first index to be False since we don't wnant to touch the <GO> symbol\n",
    "        mask[0,:]=False\n",
    "\n",
    "        #also we don't want to touch the the paddings\n",
    "        mask2=decoder_inputs_!=0\n",
    "\n",
    "        #full mask\n",
    "        mask=mask*mask2\n",
    "\n",
    "        #array full of UKN tokens (3)\n",
    "        uknowns=np.full(np.shape(decoder_inputs_), UNK)\n",
    "\n",
    "\n",
    "        #apply the mask and do assigment\n",
    "        decoder_inputs_[mask] = uknowns[mask]\n",
    "        \n",
    "    else:\n",
    "\n",
    "        #feed the decoder the decoder target\n",
    "        decoder_inputs_ = decoder_inputs_full[:,index*batch_size:(index+1)*batch_size]\n",
    " \n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        decoder_inputs: decoder_inputs_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }\n",
    "\n",
    "#return variable\n",
    "def ret_var(varshape):\n",
    "    \n",
    "    return tf.get_variable(shape = varshape,initializer=tf.random_normal_initializer(stddev=0.001))\n",
    "\n",
    "\n",
    "def Getprediction_from_latent(z,decoder_inputmode='prediction',reusing=True):\n",
    "    \n",
    "    with tf.variable_scope('decodercell'):\n",
    "        decoder_cell = tf.contrib.rnn.BasicLSTMCell(decoder_hidden_units,reuse=True)\n",
    "    \n",
    "    #map from z to suitable dimensions\n",
    "    decoder_initial_state = tf.contrib.layers.fully_connected(z, decoder_hidden_units, activation_fn=tf.nn.tanh,\n",
    "                                                              scope='z_decoder_c',reuse=reusing)\n",
    "\n",
    "        #has to be modified for lstm\n",
    "    cell_state =decoder_initial_state[0,:,:] \n",
    "    output_state =decoder_initial_state[1,:,:] \n",
    "    decoder_initial_state = tf.nn.rnn_cell.LSTMStateTuple(cell_state, output_state)\n",
    "\n",
    "    decoder_outputs, decoder_final_state = tf.nn.dynamic_rnn(decoder_cell, decoder_inputs_embedded,\n",
    "        initial_state=decoder_initial_state, dtype=tf.float32, time_major=True, scope=\"plain_decoder\")\n",
    "\n",
    "    decoder_logits=tf.contrib.layers.fully_connected(decoder_outputs, vocab_size,activation_fn=None,reuse=True,scope='lstm_to_logits')\n",
    "    decoder_prediction=tf.argmax(decoder_logits, 2)          \n",
    "            \n",
    "        \n",
    "    #stack outputs into workable tensor and return\n",
    "    return decoder_prediction\n",
    "\n",
    "#set up variables and netword--------------------------------------------------------------------------\n",
    "\n",
    "# set up latent dimension\n",
    "latent_dimension = 48\n",
    "decoder_hidden_units = 384\n",
    "encoder_hidden_units = 384\n",
    "batch_size=100\n",
    "train_len=num_sentences #number of sentences\n",
    "epochs=5 #0\n",
    "\n",
    "\n",
    "#dimension for inputs are max_rollout_time, batch_size (time_major=True)\n",
    "encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')\n",
    "decoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_inputs')\n",
    "\n",
    "#set up placeholder for pretrained embeddings which have to be feeded through variable\n",
    "#pretrained part , -3 here since the pretrained part is without special tokens\n",
    "pretrained_embedding_placeholder =  tf.placeholder(shape=(vocab_size-4, embedding_dim), dtype=tf.float32, name='pretrained_embedding_placeholder')\n",
    "W=tf.get_variable(name=\"W\", shape = [vocab_size-4, embedding_dim], trainable = False)\n",
    "pretrained_emb = W.assign(pretrained_embedding_placeholder)\n",
    "\n",
    "#embedding for padding, EOS and UKN\n",
    "spec_token_embedding = tf.get_variable(name = \"spec_token_embedding\", shape = [4, embedding_dim],\n",
    "      initializer=tf.random_uniform_initializer(-0.04, 0.04),trainable = True)\n",
    "\n",
    "embeddings=tf.concat([spec_token_embedding,W], axis=0)\n",
    "\n",
    "#latent variable\n",
    "#z=tf.get_variable(name=\"z\", shape = [2,batch_size,latent_dimension])\n",
    "\n",
    "#change the inputs with embedding\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\n",
    "decoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, decoder_inputs)\n",
    "\n",
    "#encoder and decoder cells will be LSTM\n",
    "encoder_cell = tf.contrib.rnn.BasicLSTMCell(encoder_hidden_units)\n",
    "\n",
    "with tf.variable_scope('decodercell'):\n",
    "    decoder_cell = tf.contrib.rnn.BasicLSTMCell(decoder_hidden_units,reuse=False)\n",
    "\n",
    "\n",
    "#encoder --------------------------------------------------------------------\n",
    "encoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(encoder_cell, encoder_inputs_embedded,\n",
    "    dtype=tf.float32, time_major=True, scope='encoder_h')\n",
    "#we are only interested in the final state\n",
    "del encoder_outputs\n",
    "\n",
    "#latent layer----------------------------------------------------------------------\n",
    "\n",
    "#mapping parameters\n",
    "mu=tf.contrib.layers.fully_connected(encoder_final_state, latent_dimension,activation_fn=None,\n",
    "                                     weights_initializer=tf.random_normal_initializer(mean=0.0,stddev=0.1),scope='encoder_mu')\n",
    "logsigma_sq=tf.contrib.layers.fully_connected(encoder_final_state, latent_dimension,activation_fn=None,\n",
    "                                    weights_initializer=tf.random_normal_initializer(mean=0.0,stddev=0.1),scope='encoder_logsigma2')\n",
    "\n",
    "#sample firs epsilon from N(0,1) and then rescale it with learned my and sigma to map the encoded\n",
    "#code to N(mu,sigma)\n",
    "\n",
    "# Sample latent variable\n",
    "epsilon = tf.random_normal(tf.shape(logsigma_sq), dtype=tf.float32, mean=0., stddev=1.0, name='epsilon')\n",
    "std_z = tf.exp(0.5 * logsigma_sq) #because logsigma_sq=log(std^2)\n",
    "z = mu + tf.multiply(std_z, epsilon) #now z is N(mu,sigma) where mu and sigma will be learned\n",
    "\n",
    "#decode the latent z with input-------------------------------------------------------------------------------\n",
    "\n",
    "#map from z to suitable dimensions\n",
    "decoder_initial_state = tf.contrib.layers.fully_connected(z, decoder_hidden_units, activation_fn=tf.nn.tanh,scope='z_decoder_c')\n",
    "\n",
    "\n",
    "#unpack for list which to loop over and feed it as input\n",
    "#inputs=tf.unstack(decoder_inputs_embedded,num=max_sent_len+1)\n",
    "#decoder_prediction_list=[]\n",
    "#decoder_logits_list=[]\n",
    "        \n",
    "#set up initial input and state\n",
    "#state = (cell_state,output_state)\n",
    "    \n",
    "#for input_ in inputs:\n",
    "        \n",
    "#    output, state = decoder_cell.__call__(input_, state,scope='manual_decoder')\n",
    "\n",
    "    #map the decoder output to words as logits\n",
    "#    decoder_logits=tf.contrib.layers.fully_connected(output, vocab_size,activation_fn=None,scope='lstm_to_logits')\n",
    "#    decoder_logits_list.append(decoder_logits)\n",
    "\n",
    "    #take a greedy prediction\n",
    "#    prediction=tf.argmax(decoder_logits, 1)\n",
    "#    decoder_prediction_list.append(prediction)\n",
    "\n",
    "#decoder_prediction = tf.stack(decoder_prediction_list, axis=0)\n",
    "#decoder_logits = tf.stack(decoder_logits_list, axis=0)\n",
    "\n",
    "\n",
    "#has to be modified for lstm\n",
    "cell_state =decoder_initial_state[0,:,:] \n",
    "output_state =decoder_initial_state[1,:,:] \n",
    "decoder_initial_state = tf.nn.rnn_cell.LSTMStateTuple(cell_state, output_state)\n",
    "\n",
    "decoder_outputs, decoder_final_state = tf.nn.dynamic_rnn(decoder_cell, decoder_inputs_embedded,\n",
    "    initial_state=decoder_initial_state, dtype=tf.float32, time_major=True, scope=\"plain_decoder\")\n",
    "\n",
    "decoder_logits=tf.contrib.layers.fully_connected(decoder_outputs, vocab_size,activation_fn=None,scope='lstm_to_logits')\n",
    "decoder_prediction=tf.argmax(decoder_logits, 2)                                                       \n",
    "\n",
    "#calculate the loss ------------------------------------------------------------------------------------------------\n",
    "\n",
    "# the Loss consists of 2 parts: the reconstruction error and penalty for diverginf from the prior \n",
    "\n",
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=tf.one_hot(decoder_targets,\n",
    "    depth=vocab_size, dtype=tf.float32),logits=decoder_logits)\n",
    "  \n",
    "#sum over the sequence and take the mean, axis 0 is the time sequence and axis=1 is the batch\n",
    "#so sum over sequence and mean over batch\n",
    "reconst_loss = tf.reduce_mean(tf.reduce_sum(stepwise_cross_entropy,axis=0))\n",
    "    \n",
    "#the KL -divergence. our prior and recognition networks are gaussion so we have an explicit form for the loss\n",
    "#shape is 2,batch,latent dim\n",
    "KLD_b = -0.5 * tf.reduce_sum(1 + logsigma_sq - tf.pow(mu, 2) - tf.exp(logsigma_sq), axis=[0,2])\n",
    "KLD = tf.reduce_mean(KLD_b) #the mean over batch\n",
    "\n",
    "#total loss and optimise it\n",
    "loss = reconst_loss+KLD                                 \n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "#create a saver to save the model, keep 3 lates versions\n",
    "saver = tf.train.Saver(max_to_keep=3)\n",
    "\n",
    "def train(load=False,keep_prob=1):\n",
    "    \n",
    "    train_output = open('train_output.txt','w')\n",
    "    \n",
    "    #initialize lists \n",
    "    loss_track = []\n",
    "    kll_track = []\n",
    "\n",
    "    if load==True:\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            printandwrite(train_output,\"Restoring saved parameters\")\n",
    "            saver_recover = tf.train.import_meta_graph('save/VAE-0.meta')\n",
    "            saver_recover.restore(sess, tf.train.latest_checkpoint('save'))\n",
    "\n",
    "        except Exception:\n",
    "\n",
    "            printandwrite(train_output,\"No pretrained model found\")\n",
    "            print(line)\n",
    "            sys.exit()\n",
    "            \n",
    "    else:\n",
    "\n",
    "            printandwrite(train_output,\"starting from beginning, initializing parameters\")\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            #feed the placeholders the pretrained ambeddings\n",
    "            sess.run(pretrained_emb, feed_dict={pretrained_embedding_placeholder: embedding})\n",
    "    \n",
    "    \n",
    "    num_batches=int(train_len/batch_size)\n",
    "\n",
    "    #loop over epochs\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        #shuffle the training values for each epoch\n",
    "        #rng_state = np.random.get_state()\n",
    "        #np.random.set_state(rng_state)\n",
    "        #np.random.shuffle(input_sentences)\n",
    "\n",
    "\n",
    "        #loop over the batches\n",
    "        for batch_ind in range(num_batches):\n",
    "\n",
    "            #generate next feed\n",
    "            feed=next_feed(batch_ind,keep_prob)\n",
    "            \n",
    "            #run optimizer\n",
    "            _, l,kll = sess.run([optimizer, loss,KLD], feed)\n",
    "            loss_track.append(l)   \n",
    "            kll_track.append(kll)\n",
    "\n",
    "            if (batch_ind == 0) or (((batch_ind+1) % 50) == 0):\n",
    "                printandwrite(train_output,'batch_ind/epoch: '+str(batch_ind+1)+'/'+str(epoch+1)+' out of '+str(num_batches)+'/'+str(epochs))\n",
    "                printandwrite(train_output,'Last batch loss:'+str(l)+ ' KDL: '+str(kll)+' KLD %: ' +str(100*kll/l))\n",
    "                predict_ = sess.run(decoder_prediction, feed)\n",
    "                printandwrite(train_output,'encoder inputs: '+ printsentence(feed[encoder_inputs][:,1],reverse=True))\n",
    "                printandwrite(train_output,'decoder inputs: '+printsentence(feed[decoder_inputs][:,1]))\n",
    "                printandwrite(train_output,'predictions: '+printsentence(predict_[:,1]))\n",
    "                train_output.flush()\n",
    "\n",
    "\n",
    "\n",
    "        # Save the variables to disk after each epoch\n",
    "        #we couold have global_step=epoch but then we have to specify it at loading\n",
    "        save_path=saver.save(sess, 'save/VAE',global_step=0)                \n",
    "        printandwrite(train_output,\"Model saved in file: %s\"+save_path)\n",
    "        printandwrite(train_output,'execution took: '+str(timeit.default_timer() - start_time)+' seconds')\n",
    "        train_output.flush()\n",
    "\n",
    "    train_output.close()\n",
    "    return loss_track, kll_track\n",
    "    \n",
    "    \n",
    "#gives the latent code for input of sentences\n",
    "def Givelatent(input_sentences):\n",
    "    \n",
    "    print(\"Restoring saved parameters\")\n",
    "    saver_recover = tf.train.import_meta_graph('save/VAE-0.meta')\n",
    "    saver_recover.restore(sess, tf.train.latest_checkpoint('save'))\n",
    "    \n",
    "    return sess.run([mu, std_z, logsigma_sq,z], {encoder_inputs: input_sentences})\n",
    "\n",
    "def Giveoutput_fromlatent(latent_var_in,input_sentences,decoder_inputmode='prediction'):\n",
    "\n",
    "    print(\"Restoring saved parameters\")\n",
    "    saver_recover = tf.train.import_meta_graph('save/VAE-0.meta')\n",
    "    saver_recover.restore(sess, tf.train.latest_checkpoint('save'))\n",
    "    \n",
    "    shapein=[np.shape(latent_var_in)[0],np.shape(latent_var_in)[1],np.shape(latent_var_in)[2]]\n",
    "    \n",
    "    #feed the latent variable value through placeholder\n",
    "    z_holder = tf.placeholder(shape=(2,None, None), dtype=tf.float32)\n",
    "    latent_input=tf.Variable(tf.constant(0.0, shape=shapein),trainable = False)\n",
    "    assign_z = latent_input.assign(z_holder)\n",
    "    \n",
    "    #assign z\n",
    "    sess.run(assign_z,{z_holder:latent_var_in})\n",
    "    \n",
    "    #decoder_prediction, decoder_logits\n",
    "    return sess.run(Getprediction_from_latent(latent_input,decoder_inputmode), {decoder_inputs: input_sentences})#, {decoder_inputs: input_sentences})\n",
    "\n",
    "\n",
    "\n",
    "#run the decoder with beam search\n",
    "#make bidirectional with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring saved parameters\n",
      "INFO:tensorflow:Restoring parameters from save\\VAE-0\n",
      "batch_ind/epoch: 1/1 out of 6961/5\n",
      "Last batch loss:116.826 KDL: 4.17606 KLD %: 3.57460750422\n",
      "encoder inputs: not too chewy , and very flavorful .\n",
      "decoder inputs: not too chewy , UNK very flavorful UNK\n",
      "predictions: nail filler simply blessings eaten eaten dreadful collection\n",
      "batch_ind/epoch: 50/1 out of 6961/5\n",
      "Last batch loss:50.6113 KDL: 3.64943 KLD %: 7.21069642837\n",
      "encoder inputs: tastes pretty crappy .\n",
      "decoder inputs: UNK pretty crappy UNK\n",
      "predictions: i is tea !\n",
      "batch_ind/epoch: 100/1 out of 6961/5\n",
      "Last batch loss:45.0851 KDL: 3.5333 KLD %: 7.83694862164\n",
      "encoder inputs: i 'm still not sure what flavor it is .\n",
      "decoder inputs: i 'm still UNK UNK what flavor it is .\n",
      "predictions: i will this these and and the it .\n",
      "batch_ind/epoch: 150/1 out of 6961/5\n",
      "Last batch loss:42.1988 KDL: 3.38671 KLD %: 8.025609304\n",
      "encoder inputs: now i have 5 lbs .\n",
      "decoder inputs: now i have 5 lbs UNK\n",
      "predictions: this i love a them .\n",
      "batch_ind/epoch: 200/1 out of 6961/5\n",
      "Last batch loss:42.2388 KDL: 3.27058 KLD %: 7.74306748749\n",
      "encoder inputs: the 4 packages arrived not in an outer box !\n",
      "decoder inputs: UNK UNK packages arrived not in UNK outer box !\n",
      "predictions: this is is , , and the the product .\n",
      "batch_ind/epoch: 250/1 out of 6961/5\n",
      "Last batch loss:47.0759 KDL: 3.11927 KLD %: 6.62604021922\n",
      "encoder inputs: they loved it !\n",
      "decoder inputs: they loved UNK !\n",
      "predictions: my are it !\n",
      "batch_ind/epoch: 300/1 out of 6961/5\n",
      "Last batch loss:40.9495 KDL: 3.22399 KLD %: 7.87308835334\n",
      "encoder inputs: the best thing ... no UNK .\n",
      "decoder inputs: the best thing ... no UNK .\n",
      "predictions: the flavor of the them . .\n",
      "batch_ind/epoch: 350/1 out of 6961/5\n",
      "Last batch loss:41.4176 KDL: 3.18537 KLD %: 7.69086711563\n",
      "encoder inputs: me , into a UNK ! )\n",
      "decoder inputs: UNK , into UNK UNK ! UNK\n",
      "predictions: these , it flavor and UNK !\n",
      "batch_ind/epoch: 400/1 out of 6961/5\n",
      "Last batch loss:40.882 KDL: 3.22994 KLD %: 7.90063980842\n",
      "encoder inputs: saying she loves these chews is a UNK understatement .\n",
      "decoder inputs: UNK she loves these chews UNK a UNK understatement .\n",
      "predictions: my is , a to for the great UNK .\n",
      "batch_ind/epoch: 450/1 out of 6961/5\n",
      "Last batch loss:42.8328 KDL: 3.19136 KLD %: 7.45075533812\n",
      "encoder inputs: i compete in UNK and crave carbs while dieting .\n",
      "decoder inputs: i compete in UNK and crave carbs while dieting UNK\n",
      "predictions: the have like the and the , and again .\n",
      "batch_ind/epoch: 500/1 out of 6961/5\n",
      "Last batch loss:40.627 KDL: 3.09816 KLD %: 7.62586197394\n",
      "encoder inputs: that 's really fast .\n",
      "decoder inputs: that 's really fast UNK\n",
      "predictions: this 's is good .\n",
      "batch_ind/epoch: 550/1 out of 6961/5\n",
      "Last batch loss:39.33 KDL: 3.13616 KLD %: 7.97396397251\n",
      "encoder inputs: but i was pleasantly surprised .\n",
      "decoder inputs: but i was pleasantly surprised .\n",
      "predictions: i i love a this .\n",
      "batch_ind/epoch: 600/1 out of 6961/5\n",
      "Last batch loss:40.5953 KDL: 3.21359 KLD %: 7.91616174069\n",
      "encoder inputs: pour the hot water out of the cup .\n",
      "decoder inputs: UNK the hot water out UNK the UNK UNK\n",
      "predictions: this is best is the of the taste .\n",
      "batch_ind/epoch: 650/1 out of 6961/5\n",
      "Last batch loss:39.9526 KDL: 3.13715 KLD %: 7.8521685927\n",
      "encoder inputs: stir until melted .\n",
      "decoder inputs: stir until melted .\n",
      "predictions: these to it .\n",
      "batch_ind/epoch: 700/1 out of 6961/5\n",
      "Last batch loss:37.4722 KDL: 3.1616 KLD %: 8.43720255092\n",
      "encoder inputs: i would never buy this coffee again .\n",
      "decoder inputs: UNK would never buy UNK UNK again UNK\n",
      "predictions: i would recommend buy it again . .\n",
      "batch_ind/epoch: 750/1 out of 6961/5\n",
      "Last batch loss:39.6235 KDL: 3.07836 KLD %: 7.76902790013\n",
      "encoder inputs: the above indicates a lifelong relationship .\n",
      "decoder inputs: UNK above indicates a lifelong relationship .\n",
      "predictions: the is a the great flavor .\n",
      "batch_ind/epoch: 800/1 out of 6961/5\n",
      "Last batch loss:39.7173 KDL: 3.14985 KLD %: 7.93067228909\n",
      "encoder inputs: the spicing really suits the cashews .\n",
      "decoder inputs: UNK UNK really suits the cashews UNK\n",
      "predictions: the is a good the best .\n",
      "batch_ind/epoch: 850/1 out of 6961/5\n",
      "Last batch loss:35.985 KDL: 3.18612 KLD %: 8.85401775866\n",
      "encoder inputs: it makes an excellent cup .\n",
      "decoder inputs: it makes an excellent UNK UNK\n",
      "predictions: it 's a excellent taste .\n",
      "batch_ind/epoch: 900/1 out of 6961/5\n",
      "Last batch loss:40.484 KDL: 3.14063 KLD %: 7.75770303003\n",
      "encoder inputs: these cookies are a favorite of mine .\n",
      "decoder inputs: UNK cookies are a UNK UNK mine .\n",
      "predictions: they , are really great and ! .\n",
      "batch_ind/epoch: 950/1 out of 6961/5\n",
      "Last batch loss:42.2122 KDL: 3.062 KLD %: 7.25380864322\n",
      "encoder inputs: worth a try !\n",
      "decoder inputs: worth UNK try UNK\n",
      "predictions: no the it .\n",
      "batch_ind/epoch: 1000/1 out of 6961/5\n",
      "Last batch loss:39.6287 KDL: 3.11518 KLD %: 7.86092909746\n",
      "encoder inputs: not to be .\n",
      "decoder inputs: not UNK be UNK\n",
      "predictions: these too great .\n",
      "batch_ind/epoch: 1050/1 out of 6961/5\n",
      "Last batch loss:39.1869 KDL: 3.17098 KLD %: 8.09193771216\n",
      "encoder inputs: i use it with plain yogurt and equal .\n",
      "decoder inputs: i use it with UNK yogurt UNK UNK .\n",
      "predictions: i will it 's the and the UNK .\n",
      "batch_ind/epoch: 1100/1 out of 6961/5\n",
      "Last batch loss:40.2974 KDL: 3.07306 KLD %: 7.62594468423\n",
      "encoder inputs: i would suggest those flavors over this one .\n",
      "decoder inputs: i would UNK UNK flavors over this one .\n",
      "predictions: i have recommend this this and it product .\n",
      "batch_ind/epoch: 1150/1 out of 6961/5\n",
      "Last batch loss:38.4442 KDL: 3.07968 KLD %: 8.01077042897\n",
      "encoder inputs: but i will be ordering again .\n",
      "decoder inputs: UNK UNK will be ordering again .\n",
      "predictions: but is a not buying more .\n",
      "batch_ind/epoch: 1200/1 out of 6961/5\n",
      "Last batch loss:37.1504 KDL: 2.99435 KLD %: 8.06006826224\n",
      "encoder inputs: love it on popcorn now too !\n",
      "decoder inputs: UNK UNK on UNK now too !\n",
      "predictions: just , , the and UNK .\n",
      "batch_ind/epoch: 1250/1 out of 6961/5\n",
      "Last batch loss:33.9013 KDL: 3.11702 KLD %: 9.19439543105\n",
      "encoder inputs: it is neat and resealable .\n",
      "decoder inputs: it is neat and resealable UNK\n",
      "predictions: this is a so delicious .\n",
      "batch_ind/epoch: 1300/1 out of 6961/5\n",
      "Last batch loss:35.2084 KDL: 2.96983 KLD %: 8.43502540342\n",
      "encoder inputs: it 's sweet with a slight tartness .\n",
      "decoder inputs: it 's sweet with UNK slight UNK .\n",
      "predictions: it 's a and a UNK . .\n",
      "batch_ind/epoch: 1350/1 out of 6961/5\n",
      "Last batch loss:40.0902 KDL: 2.93985 KLD %: 7.33307863319\n",
      "encoder inputs: it 's organic and seems to be nutritious !\n",
      "decoder inputs: UNK 's UNK and UNK UNK be nutritious !\n",
      "predictions: it is not , i is the disappointed .\n",
      "batch_ind/epoch: 1400/1 out of 6961/5\n",
      "Last batch loss:38.467 KDL: 3.00611 KLD %: 7.81476831328\n",
      "encoder inputs: i love the taste .\n",
      "decoder inputs: i love UNK UNK UNK\n",
      "predictions: i love this this . .\n",
      "batch_ind/epoch: 1450/1 out of 6961/5\n",
      "Last batch loss:37.2319 KDL: 3.06707 KLD %: 8.23774547698\n",
      "encoder inputs: we 'll see .\n",
      "decoder inputs: UNK 'll see UNK\n",
      "predictions: we a ! .\n",
      "batch_ind/epoch: 1500/1 out of 6961/5\n",
      "Last batch loss:36.2129 KDL: 2.98826 KLD %: 8.25194119699\n",
      "encoder inputs: i would n't buy it again .\n",
      "decoder inputs: i would UNK buy it UNK UNK\n",
      "predictions: the love recommend recommend this again .\n",
      "batch_ind/epoch: 1550/1 out of 6961/5\n",
      "Last batch loss:34.9257 KDL: 3.07593 KLD %: 8.80708584101\n",
      "encoder inputs: it is good for people on diets thanks\n",
      "decoder inputs: it is good UNK UNK on diets thanks\n",
      "predictions: it 's a , and and amazon .\n",
      "batch_ind/epoch: 1600/1 out of 6961/5\n",
      "Last batch loss:35.6956 KDL: 3.19597 KLD %: 8.95339317011\n",
      "encoder inputs: very good quality chocolate .\n",
      "decoder inputs: very good UNK UNK .\n",
      "predictions: these good and too .\n",
      "batch_ind/epoch: 1650/1 out of 6961/5\n",
      "Last batch loss:39.8519 KDL: 3.18286 KLD %: 7.98671658497\n",
      "encoder inputs: the duck pill pockets are a god send .\n",
      "decoder inputs: UNK duck pill pockets are a god send UNK\n",
      "predictions: the is i to , the great flavor .\n",
      "batch_ind/epoch: 1700/1 out of 6961/5\n",
      "Last batch loss:36.1062 KDL: 2.94887 KLD %: 8.16721510708\n",
      "encoder inputs: i really missed my moo .\n",
      "decoder inputs: UNK UNK missed my moo .\n",
      "predictions: i are a this favorite .\n",
      "batch_ind/epoch: 1750/1 out of 6961/5\n",
      "Last batch loss:38.1899 KDL: 3.0018 KLD %: 7.8601736394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder inputs: ca n't say enough good things about this cocoa .\n",
      "decoder inputs: ca UNK say enough good things UNK this cocoa .\n",
      "predictions: i n't to that for for to this coffee .\n",
      "batch_ind/epoch: 1800/1 out of 6961/5\n",
      "Last batch loss:36.9161 KDL: 3.10746 KLD %: 8.41763211852\n",
      "encoder inputs: i ca n't wait to try more flavors !\n",
      "decoder inputs: UNK ca n't wait to try more flavors UNK\n",
      "predictions: i have n't wait to try this it .\n",
      "batch_ind/epoch: 1850/1 out of 6961/5\n",
      "Last batch loss:36.6605 KDL: 3.04602 KLD %: 8.30872464698\n",
      "encoder inputs: the chai latte is delicious !\n",
      "decoder inputs: the chai UNK is delicious !\n",
      "predictions: i taste was is great .\n",
      "batch_ind/epoch: 1900/1 out of 6961/5\n",
      "Last batch loss:39.1909 KDL: 3.02396 KLD %: 7.71596748052\n",
      "encoder inputs: they arrived quickly and in good shape !\n",
      "decoder inputs: they UNK quickly and UNK UNK shape UNK\n",
      "predictions: a are a and not and UNK .\n",
      "batch_ind/epoch: 1950/1 out of 6961/5\n",
      "Last batch loss:36.4804 KDL: 2.97283 KLD %: 8.14913454896\n",
      "encoder inputs: i have to drink about two cups each time !\n",
      "decoder inputs: i have to drink about two UNK each time !\n",
      "predictions: i will been say it it for this again .\n",
      "batch_ind/epoch: 2000/1 out of 6961/5\n",
      "Last batch loss:36.3252 KDL: 3.04309 KLD %: 8.37735018496\n",
      "encoder inputs: also , the food looks like real food .\n",
      "decoder inputs: also , the food looks like real UNK UNK\n",
      "predictions: my , i price is is this ! .\n",
      "batch_ind/epoch: 2050/1 out of 6961/5\n",
      "Last batch loss:35.414 KDL: 3.03804 KLD %: 8.57863566578\n",
      "encoder inputs: i highly recommend this product .\n",
      "decoder inputs: i highly recommend UNK product UNK\n",
      "predictions: i love recommend this product .\n",
      "batch_ind/epoch: 2100/1 out of 6961/5\n",
      "Last batch loss:37.9227 KDL: 3.07302 KLD %: 8.10336989696\n",
      "encoder inputs: dry and tough .\n",
      "decoder inputs: dry UNK UNK UNK\n",
      "predictions: great of good .\n",
      "batch_ind/epoch: 2150/1 out of 6961/5\n",
      "Last batch loss:37.8634 KDL: 2.99133 KLD %: 7.90032280447\n",
      "encoder inputs: i never got sick once while on this stuff .\n",
      "decoder inputs: UNK never UNK sick once UNK on UNK stuff UNK\n",
      "predictions: i have have it this and and the UNK .\n",
      "batch_ind/epoch: 2200/1 out of 6961/5\n",
      "Last batch loss:35.2784 KDL: 2.97621 KLD %: 8.43634901113\n",
      "encoder inputs: this candy is addicting !\n",
      "decoder inputs: UNK candy is UNK UNK\n",
      "predictions: this is is great .\n",
      "batch_ind/epoch: 2250/1 out of 6961/5\n",
      "Last batch loss:36.9797 KDL: 3.18581 KLD %: 8.61502442644\n",
      "encoder inputs: it makes a great , easy lunch .\n",
      "decoder inputs: it makes UNK great UNK easy lunch .\n",
      "predictions: the 's a a for for day .\n",
      "batch_ind/epoch: 2300/1 out of 6961/5\n",
      "Last batch loss:35.2244 KDL: 3.07152 KLD %: 8.71985659628\n",
      "encoder inputs: the spices are perfect .\n",
      "decoder inputs: the UNK UNK perfect .\n",
      "predictions: this flavor is great .\n",
      "batch_ind/epoch: 2350/1 out of 6961/5\n",
      "Last batch loss:36.6419 KDL: 3.0405 KLD %: 8.29787975254\n",
      "encoder inputs: no more begging for food every 5 minutes .\n",
      "decoder inputs: no more begging for food every UNK minutes .\n",
      "predictions: but more , , the and to UNK .\n",
      "batch_ind/epoch: 2400/1 out of 6961/5\n",
      "Last batch loss:35.8548 KDL: 3.1396 KLD %: 8.75643105145\n",
      "encoder inputs: you 'll have to give it a try .\n",
      "decoder inputs: you 'll have to give it a try UNK\n",
      "predictions: the get be to say it a try ! .\n",
      "batch_ind/epoch: 2450/1 out of 6961/5\n",
      "Last batch loss:36.4933 KDL: 3.13297 KLD %: 8.58504318819\n",
      "encoder inputs: my stomach loves you .\n",
      "decoder inputs: my UNK UNK you UNK\n",
      "predictions: they dog loves it .\n",
      "batch_ind/epoch: 2500/1 out of 6961/5\n",
      "Last batch loss:40.1712 KDL: 2.99519 KLD %: 7.45608392606\n",
      "encoder inputs: it 's too much .\n",
      "decoder inputs: it 's too much .\n",
      "predictions: it is very sweet .\n",
      "batch_ind/epoch: 2550/1 out of 6961/5\n",
      "Last batch loss:34.9965 KDL: 2.99411 KLD %: 8.55545979401\n",
      "encoder inputs: and it worked out even better than the muffins .\n",
      "decoder inputs: and it worked UNK even better UNK the muffins .\n",
      "predictions: and it 's the , in than the price .\n",
      "batch_ind/epoch: 2600/1 out of 6961/5\n",
      "Last batch loss:38.6064 KDL: 2.98344 KLD %: 7.72783946978\n",
      "encoder inputs: great real coconut young coconut taste .\n",
      "decoder inputs: great real coconut UNK UNK taste .\n",
      "predictions: the product , , and UNK .\n",
      "batch_ind/epoch: 2650/1 out of 6961/5\n",
      "Last batch loss:37.9382 KDL: 3.04331 KLD %: 8.02174911551\n",
      "encoder inputs: i am very happy with this food ! ! !\n",
      "decoder inputs: i am very happy with this food ! ! !\n",
      "predictions: i am very pleased with this product .\n",
      "batch_ind/epoch: 2700/1 out of 6961/5\n",
      "Last batch loss:37.7189 KDL: 3.01539 KLD %: 7.99439287346\n",
      "encoder inputs: what do i do with it now ? ?\n",
      "decoder inputs: UNK do i do with UNK UNK UNK ?\n",
      "predictions: we , n't like n't the this again .\n",
      "batch_ind/epoch: 2750/1 out of 6961/5\n",
      "Last batch loss:38.2259 KDL: 3.149 KLD %: 8.23786548737\n",
      "encoder inputs: plus it 's rather noisy .\n",
      "decoder inputs: UNK it UNK UNK noisy .\n",
      "predictions: will , is a it .\n",
      "batch_ind/epoch: 2800/1 out of 6961/5\n",
      "Last batch loss:35.2904 KDL: 3.09392 KLD %: 8.76704435272\n",
      "encoder inputs: it overwhelms the flavor .\n",
      "decoder inputs: it UNK UNK flavor .\n",
      "predictions: the 's very good .\n",
      "batch_ind/epoch: 2850/1 out of 6961/5\n",
      "Last batch loss:34.3568 KDL: 2.99035 KLD %: 8.70381310607\n",
      "encoder inputs: i strongly recommend this popcorn .\n",
      "decoder inputs: UNK UNK UNK UNK popcorn .\n",
      "predictions: the is is the UNK .\n",
      "batch_ind/epoch: 2900/1 out of 6961/5\n",
      "Last batch loss:34.1654 KDL: 3.13648 KLD %: 9.18030236004\n",
      "encoder inputs: it smelled absolutely sinful while it brewed .\n",
      "decoder inputs: it UNK UNK sinful while it brewed UNK\n",
      "predictions: i 's a a and for ! .\n",
      "batch_ind/epoch: 2950/1 out of 6961/5\n",
      "Last batch loss:36.0223 KDL: 3.12324 KLD %: 8.67029126858\n",
      "encoder inputs: read every label peace\n",
      "decoder inputs: read every label peace\n",
      "predictions: these the time .\n",
      "batch_ind/epoch: 3000/1 out of 6961/5\n",
      "Last batch loss:36.0324 KDL: 3.04725 KLD %: 8.45698739518\n",
      "encoder inputs: the taste is very beef broth like .\n",
      "decoder inputs: the UNK is very UNK UNK UNK UNK\n",
      "predictions: i price is the good and and .\n",
      "batch_ind/epoch: 3050/1 out of 6961/5\n",
      "Last batch loss:36.4316 KDL: 3.09673 KLD %: 8.50009973472\n",
      "encoder inputs: i love it any time of the day .\n",
      "decoder inputs: UNK UNK it any time UNK the day .\n",
      "predictions: i will the to to and the best .\n",
      "batch_ind/epoch: 3100/1 out of 6961/5\n",
      "Last batch loss:36.0605 KDL: 2.98403 KLD %: 8.27505626229\n",
      "encoder inputs: best thing i 've ordered on line .\n",
      "decoder inputs: best thing i UNK UNK UNK line .\n",
      "predictions: you tea i 've a this . .\n",
      "batch_ind/epoch: 3150/1 out of 6961/5\n",
      "Last batch loss:35.1494 KDL: 3.14102 KLD %: 8.93620377281\n",
      "encoder inputs: you wo n't be disappointed .\n",
      "decoder inputs: you wo n't UNK disappointed .\n",
      "predictions: what wo n't be it .\n",
      "batch_ind/epoch: 3200/1 out of 6961/5\n",
      "Last batch loss:36.9445 KDL: 3.03547 KLD %: 8.2162936503\n",
      "encoder inputs: these wasabi flavored roasted UNK are okay .\n",
      "decoder inputs: these wasabi flavored roasted UNK are okay .\n",
      "predictions: they are are the the and great .\n",
      "batch_ind/epoch: 3250/1 out of 6961/5\n",
      "Last batch loss:34.8752 KDL: 3.02726 KLD %: 8.68026698596\n",
      "encoder inputs: enjoy ! gary peterson\n",
      "decoder inputs: UNK ! gary peterson\n",
      "predictions: these are ! !\n",
      "batch_ind/epoch: 3300/1 out of 6961/5\n",
      "Last batch loss:35.1441 KDL: 3.15356 KLD %: 8.97321240557\n",
      "encoder inputs: zico is still amazing .\n",
      "decoder inputs: UNK is still UNK UNK\n",
      "predictions: love a a . .\n",
      "batch_ind/epoch: 3350/1 out of 6961/5\n",
      "Last batch loss:34.7665 KDL: 3.03776 KLD %: 8.73758221286\n",
      "encoder inputs: no bitterness at all .\n",
      "decoder inputs: no UNK at all .\n",
      "predictions: no more for all .\n",
      "batch_ind/epoch: 3400/1 out of 6961/5\n",
      "Last batch loss:34.882 KDL: 3.0242 KLD %: 8.66979263154\n",
      "encoder inputs: only 100 calories per bag .\n",
      "decoder inputs: only UNK calories per bag UNK\n",
      "predictions: you this is per cup .\n",
      "batch_ind/epoch: 3450/1 out of 6961/5\n",
      "Last batch loss:33.9643 KDL: 3.14442 KLD %: 9.25802090988\n",
      "encoder inputs: it works 85 % of the time .\n",
      "decoder inputs: it works 85 UNK of the UNK UNK\n",
      "predictions: the is a , and the UNK .\n",
      "batch_ind/epoch: 3500/1 out of 6961/5\n",
      "Last batch loss:36.7256 KDL: 3.12745 KLD %: 8.51574222743\n",
      "encoder inputs: the flavor is excellent UNK great .\n",
      "decoder inputs: the UNK is UNK UNK great .\n",
      "predictions: the taste is very and too .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_ind/epoch: 3550/1 out of 6961/5\n",
      "Last batch loss:35.0935 KDL: 3.11923 KLD %: 8.88833700471\n",
      "encoder inputs: love this product !\n",
      "decoder inputs: love this UNK UNK\n",
      "predictions: very this product .\n",
      "batch_ind/epoch: 3600/1 out of 6961/5\n",
      "Last batch loss:33.0647 KDL: 2.96883 KLD %: 8.97885532448\n",
      "encoder inputs: her baking mixes are UNK .\n",
      "decoder inputs: her baking mixes are UNK .\n",
      "predictions: this is like are very .\n",
      "batch_ind/epoch: 3650/1 out of 6961/5\n",
      "Last batch loss:37.0375 KDL: 3.1422 KLD %: 8.48382582167\n",
      "encoder inputs: price with subscribe and save is very good .\n",
      "decoder inputs: price UNK subscribe and save UNK very UNK .\n",
      "predictions: i is the and save for the good .\n",
      "batch_ind/epoch: 3700/1 out of 6961/5\n",
      "Last batch loss:34.1619 KDL: 3.06672 KLD %: 8.97703736724\n",
      "encoder inputs: one end is covered with a sticker .\n",
      "decoder inputs: UNK end UNK UNK with a sticker .\n",
      "predictions: ( , , the and the lot .\n",
      "batch_ind/epoch: 3750/1 out of 6961/5\n",
      "Last batch loss:33.8116 KDL: 3.21261 KLD %: 9.5014953145\n",
      "encoder inputs: they are all meat - absolutely nothing else .\n",
      "decoder inputs: UNK are all UNK - absolutely nothing else .\n",
      "predictions: they are the , , the love else .\n",
      "batch_ind/epoch: 3800/1 out of 6961/5\n",
      "Last batch loss:34.6469 KDL: 2.98928 KLD %: 8.62784488371\n",
      "encoder inputs: these cookies taste like the real thing !\n",
      "decoder inputs: these UNK UNK like UNK real UNK !\n",
      "predictions: they are are are the and ! .\n",
      "batch_ind/epoch: 3850/1 out of 6961/5\n",
      "Last batch loss:35.3784 KDL: 3.12568 KLD %: 8.83499051297\n",
      "encoder inputs: ) , so give them a try .\n",
      "decoder inputs: ) UNK UNK UNK them a UNK .\n",
      "predictions: but , , , the for try .\n",
      "batch_ind/epoch: 3900/1 out of 6961/5\n",
      "Last batch loss:35.1877 KDL: 3.11105 KLD %: 8.84129580889\n",
      "encoder inputs: we definitely will be buying more .\n",
      "decoder inputs: UNK UNK will be buying more UNK\n",
      "predictions: we , , buy ordering more .\n",
      "batch_ind/epoch: 3950/1 out of 6961/5\n",
      "Last batch loss:41.326 KDL: 3.20784 KLD %: 7.76228320345\n",
      "encoder inputs: too expensive for 15 minutes of entertainment .\n",
      "decoder inputs: too expensive UNK 15 minutes UNK UNK .\n",
      "predictions: these bad , , for for UNK .\n",
      "batch_ind/epoch: 4000/1 out of 6961/5\n",
      "Last batch loss:34.1136 KDL: 3.09793 KLD %: 9.08121431644\n",
      "encoder inputs: would definitely order this again and good price too !\n",
      "decoder inputs: would UNK UNK this UNK and UNK price too UNK\n",
      "predictions: my not buy this product a the love . .\n",
      "batch_ind/epoch: 4050/1 out of 6961/5\n",
      "Last batch loss:35.1292 KDL: 3.13459 KLD %: 8.92305764197\n",
      "encoder inputs: this however is delicious !\n",
      "decoder inputs: this UNK UNK UNK !\n",
      "predictions: this is is great .\n",
      "batch_ind/epoch: 4100/1 out of 6961/5\n",
      "Last batch loss:35.369 KDL: 2.99169 KLD %: 8.45851470807\n",
      "encoder inputs: loved the spray !\n",
      "decoder inputs: loved UNK UNK !\n",
      "predictions: these it UNK .\n",
      "batch_ind/epoch: 4150/1 out of 6961/5\n",
      "Last batch loss:31.2412 KDL: 3.20325 KLD %: 10.2532939436\n",
      "encoder inputs: not what i hoped for .\n",
      "decoder inputs: not what UNK hoped for .\n",
      "predictions: and a i i . .\n",
      "batch_ind/epoch: 4200/1 out of 6961/5\n",
      "Last batch loss:33.3553 KDL: 3.03782 KLD %: 9.10744216771\n",
      "encoder inputs: my kids love it too .\n",
      "decoder inputs: UNK kids UNK it too .\n",
      "predictions: my dog love this again .\n",
      "batch_ind/epoch: 4250/1 out of 6961/5\n",
      "Last batch loss:32.415 KDL: 3.23814 KLD %: 9.98962579242\n",
      "encoder inputs: it 's perfect for movie night !\n",
      "decoder inputs: it 's UNK UNK movie UNK !\n",
      "predictions: it is a and and tea .\n",
      "batch_ind/epoch: 4300/1 out of 6961/5\n",
      "Last batch loss:31.7003 KDL: 3.17699 KLD %: 10.0219659057\n",
      "encoder inputs: this large package lasts us a long time .\n",
      "decoder inputs: this UNK UNK UNK us a UNK time .\n",
      "predictions: this is is a a for great product .\n",
      "batch_ind/epoch: 4350/1 out of 6961/5\n",
      "Last batch loss:33.2099 KDL: 3.22669 KLD %: 9.71605781015\n",
      "encoder inputs: big plus for me .\n",
      "decoder inputs: big plus for me UNK\n",
      "predictions: not , , me .\n",
      "batch_ind/epoch: 4400/1 out of 6961/5\n",
      "Last batch loss:34.1664 KDL: 3.13627 KLD %: 9.17940061015\n",
      "encoder inputs: perfect for snacking .\n",
      "decoder inputs: perfect for UNK .\n",
      "predictions: it for you .\n",
      "batch_ind/epoch: 4450/1 out of 6961/5\n",
      "Last batch loss:37.2275 KDL: 3.09352 KLD %: 8.30977615254\n",
      "encoder inputs: hard to tell that they are baked .\n",
      "decoder inputs: hard UNK tell that they UNK UNK .\n",
      "predictions: i to to the i are it .\n",
      "batch_ind/epoch: 4500/1 out of 6961/5\n",
      "Last batch loss:34.3743 KDL: 3.19734 KLD %: 9.30153536601\n",
      "encoder inputs: this yummy little baked confection was truly delicious .\n",
      "decoder inputs: UNK yummy UNK baked confection was truly delicious .\n",
      "predictions: this is is is of for a amazing .\n",
      "batch_ind/epoch: 4550/1 out of 6961/5\n",
      "Last batch loss:33.8594 KDL: 3.19108 KLD %: 9.42451323429\n",
      "encoder inputs: i was very happy with this product .\n",
      "decoder inputs: i UNK very UNK with this product .\n",
      "predictions: i love this disappointed with this product .\n",
      "batch_ind/epoch: 4600/1 out of 6961/5\n",
      "Last batch loss:33.0666 KDL: 3.21556 KLD %: 9.72449249049\n",
      "encoder inputs: use this over rice for a meal !\n",
      "decoder inputs: use this over rice UNK a meal !\n",
      "predictions: UNK the is is is UNK winner .\n",
      "batch_ind/epoch: 4650/1 out of 6961/5\n",
      "Last batch loss:31.8906 KDL: 3.1676 KLD %: 9.93272385241\n",
      "encoder inputs: no heavy flavor .\n",
      "decoder inputs: UNK heavy flavor .\n",
      "predictions: this is it .\n",
      "batch_ind/epoch: 4700/1 out of 6961/5\n",
      "Last batch loss:32.5904 KDL: 3.15819 KLD %: 9.69054274155\n",
      "encoder inputs: everything about this product is excellent .\n",
      "decoder inputs: everything about this product UNK UNK .\n",
      "predictions: very , the product is great .\n",
      "batch_ind/epoch: 4750/1 out of 6961/5\n",
      "Last batch loss:35.4997 KDL: 3.17425 KLD %: 8.94162392379\n",
      "encoder inputs: i love them !\n",
      "decoder inputs: i UNK UNK !\n",
      "predictions: i love it .\n",
      "batch_ind/epoch: 4800/1 out of 6961/5\n",
      "Last batch loss:34.3643 KDL: 3.23353 KLD %: 9.40955938053\n",
      "encoder inputs: this year everyone is going to be happy !\n",
      "decoder inputs: this year everyone UNK going to be UNK !\n",
      "predictions: this is is not a to be UNK .\n",
      "batch_ind/epoch: 4850/1 out of 6961/5\n",
      "Last batch loss:32.4137 KDL: 3.22297 KLD %: 9.94323273818\n",
      "encoder inputs: these are the best tasting pretzels !\n",
      "decoder inputs: these are UNK best UNK pretzels UNK\n",
      "predictions: these are the best i ever ever .\n",
      "batch_ind/epoch: 4900/1 out of 6961/5\n",
      "Last batch loss:36.4287 KDL: 3.346 KLD %: 9.18507651615\n",
      "encoder inputs: i do n't like overly sweet drinks .\n",
      "decoder inputs: i do n't like UNK UNK drinks .\n",
      "predictions: i will n't think the the coffee .\n",
      "batch_ind/epoch: 4950/1 out of 6961/5\n",
      "Last batch loss:31.932 KDL: 3.11852 KLD %: 9.76614664876\n",
      "encoder inputs: did you know it was invented by a doctor !\n",
      "decoder inputs: did UNK UNK it UNK invented by a doctor !\n",
      "predictions: but n't have the to a for the lot .\n",
      "batch_ind/epoch: 5000/1 out of 6961/5\n",
      "Last batch loss:32.993 KDL: 3.0904 KLD %: 9.36683171986\n",
      "encoder inputs: the tea is delicious .\n",
      "decoder inputs: the UNK is delicious UNK\n",
      "predictions: the price is great .\n",
      "batch_ind/epoch: 5050/1 out of 6961/5\n",
      "Last batch loss:34.4588 KDL: 3.12271 KLD %: 9.06216605667\n",
      "encoder inputs: good price even with the shipping costs .\n",
      "decoder inputs: good price even UNK the shipping costs .\n",
      "predictions: the price and a the same oz .\n",
      "batch_ind/epoch: 5100/1 out of 6961/5\n",
      "Last batch loss:34.3762 KDL: 3.31482 KLD %: 9.64278758899\n",
      "encoder inputs: thank you cesar !\n",
      "decoder inputs: thank you UNK !\n",
      "predictions: not you amazon !\n",
      "batch_ind/epoch: 5150/1 out of 6961/5\n",
      "Last batch loss:32.0651 KDL: 3.17421 KLD %: 9.8992538259\n",
      "encoder inputs: recipe available on UNK `` chocolate biscuit cake . ''\n",
      "decoder inputs: UNK available on UNK `` UNK biscuit cake UNK ''\n",
      "predictions: then , , the and UNK '' '' .\n",
      "batch_ind/epoch: 5200/1 out of 6961/5\n",
      "Last batch loss:36.6684 KDL: 3.16884 KLD %: 8.64188587769\n",
      "encoder inputs: this xylitol in packets is very chalky in taste .\n",
      "decoder inputs: this UNK UNK packets is very chalky UNK taste .\n",
      "predictions: this is is a and the good and flavor .\n",
      "batch_ind/epoch: 5250/1 out of 6961/5\n",
      "Last batch loss:34.41 KDL: 3.12926 KLD %: 9.09403609845\n",
      "encoder inputs: even the hot coco has the artificial sweetener .\n",
      "decoder inputs: UNK the hot UNK has the artificial UNK .\n",
      "predictions: a , best and the a best flavors .\n",
      "batch_ind/epoch: 5300/1 out of 6961/5\n",
      "Last batch loss:32.7782 KDL: 3.14968 KLD %: 9.60909431689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder inputs: ca n't beat that !\n",
      "decoder inputs: ca n't beat that !\n",
      "predictions: what n't beat ! !\n",
      "batch_ind/epoch: 5350/1 out of 6961/5\n",
      "Last batch loss:35.8831 KDL: 3.15008 KLD %: 8.77871988747\n",
      "encoder inputs: she devours every bite .\n",
      "decoder inputs: she UNK every UNK UNK\n",
      "predictions: these always it penny .\n",
      "batch_ind/epoch: 5400/1 out of 6961/5\n",
      "Last batch loss:35.0291 KDL: 3.18207 KLD %: 9.08407414853\n",
      "encoder inputs: this really tastes like ginger and honey !\n",
      "decoder inputs: UNK UNK tastes like ginger UNK honey !\n",
      "predictions: this is is like a and flavor .\n",
      "batch_ind/epoch: 5450/1 out of 6961/5\n",
      "Last batch loss:37.6257 KDL: 3.12081 KLD %: 8.29435523812\n",
      "encoder inputs: i could n't be happier !\n",
      "decoder inputs: UNK UNK n't be UNK UNK\n",
      "predictions: i love this be disappointed .\n",
      "batch_ind/epoch: 5500/1 out of 6961/5\n",
      "Last batch loss:33.0241 KDL: 3.21898 KLD %: 9.74738127122\n",
      "encoder inputs: my havanese just loves these treats with the apples !\n",
      "decoder inputs: my havanese just UNK UNK treats with the apples UNK\n",
      "predictions: my husband is loves this and for the UNK .\n",
      "batch_ind/epoch: 5550/1 out of 6961/5\n",
      "Last batch loss:34.067 KDL: 3.30069 KLD %: 9.68882744496\n",
      "encoder inputs: all six cans were rancid .\n",
      "decoder inputs: all UNK cans UNK UNK .\n",
      "predictions: the of , were UNK .\n",
      "batch_ind/epoch: 5600/1 out of 6961/5\n",
      "Last batch loss:39.789 KDL: 3.15038 KLD %: 7.9177314986\n",
      "encoder inputs: this particular one is the mild sweet style .\n",
      "decoder inputs: this UNK one is the mild sweet UNK .\n",
      "predictions: the is is of a best is flavor .\n",
      "batch_ind/epoch: 5650/1 out of 6961/5\n",
      "Last batch loss:35.6136 KDL: 3.16557 KLD %: 8.88865097782\n",
      "encoder inputs: i wanted to love these .\n",
      "decoder inputs: UNK UNK to love UNK .\n",
      "predictions: i love this buy it .\n",
      "batch_ind/epoch: 5700/1 out of 6961/5\n",
      "Last batch loss:32.5581 KDL: 3.25017 KLD %: 9.98268595865\n",
      "encoder inputs: however , the UNK process is UNK .\n",
      "decoder inputs: however UNK UNK UNK process UNK UNK .\n",
      "predictions: UNK , is is a and UNK .\n",
      "batch_ind/epoch: 5750/1 out of 6961/5\n",
      "Last batch loss:37.4325 KDL: 3.1526 KLD %: 8.42209372323\n",
      "encoder inputs: on to a chinese type dish next .\n",
      "decoder inputs: on UNK a UNK type dish UNK .\n",
      "predictions: but the , great of of UNK .\n",
      "batch_ind/epoch: 5800/1 out of 6961/5\n",
      "Last batch loss:34.968 KDL: 3.44654 KLD %: 9.85627634685\n",
      "encoder inputs: would n't have it any other way !\n",
      "decoder inputs: UNK n't have it any UNK way UNK\n",
      "predictions: very , be a to other UNK .\n",
      "batch_ind/epoch: 5850/1 out of 6961/5\n",
      "Last batch loss:34.3721 KDL: 3.26678 KLD %: 9.50418609462\n",
      "encoder inputs: and far more nutritious than a standard fruit snack .\n",
      "decoder inputs: UNK far UNK nutritious than a standard UNK snack .\n",
      "predictions: if , , the , a great UNK . .\n",
      "batch_ind/epoch: 5900/1 out of 6961/5\n",
      "Last batch loss:35.8011 KDL: 3.32576 KLD %: 9.28952861621\n",
      "encoder inputs: i had my package within 4 days .\n",
      "decoder inputs: UNK UNK my package UNK 4 UNK UNK\n",
      "predictions: i am not order to this stars .\n",
      "batch_ind/epoch: 5950/1 out of 6961/5\n",
      "Last batch loss:30.0726 KDL: 3.18999 KLD %: 10.6076493749\n",
      "encoder inputs: i love the convenience of the auto ship program .\n",
      "decoder inputs: i love the convenience of the auto UNK program .\n",
      "predictions: i have the taste and the best ship UNK .\n",
      "batch_ind/epoch: 6000/1 out of 6961/5\n",
      "Last batch loss:39.5462 KDL: 3.00021 KLD %: 7.58660183694\n",
      "encoder inputs: friends of ours were in from great britain .\n",
      "decoder inputs: friends of ours UNK in UNK great britain .\n",
      "predictions: just taste the a and the and taste .\n",
      "batch_ind/epoch: 6050/1 out of 6961/5\n",
      "Last batch loss:36.2402 KDL: 3.17481 KLD %: 8.76047142684\n",
      "encoder inputs: skip this one .\n",
      "decoder inputs: skip this one .\n",
      "predictions: great a product .\n",
      "batch_ind/epoch: 6100/1 out of 6961/5\n",
      "Last batch loss:36.9205 KDL: 3.12629 KLD %: 8.46762915615\n",
      "encoder inputs: they are really amazing .\n",
      "decoder inputs: UNK UNK really amazing .\n",
      "predictions: these are are good .\n",
      "batch_ind/epoch: 6150/1 out of 6961/5\n",
      "Last batch loss:32.1501 KDL: 3.30549 KLD %: 10.2814253909\n",
      "encoder inputs: this is a dark , chocolaty UNK .\n",
      "decoder inputs: this UNK a UNK UNK chocolaty UNK UNK\n",
      "predictions: this is a great of of product .\n",
      "batch_ind/epoch: 6200/1 out of 6961/5\n",
      "Last batch loss:31.1215 KDL: 3.29328 KLD %: 10.5820272414\n",
      "encoder inputs: i contacted the seller but got no response .\n",
      "decoder inputs: UNK UNK UNK seller but UNK UNK response .\n",
      "predictions: it was the the to not UNK . .\n",
      "batch_ind/epoch: 6250/1 out of 6961/5\n",
      "Last batch loss:33.7412 KDL: 3.26908 KLD %: 9.6886781643\n",
      "encoder inputs: most importantly my house is bug free .\n",
      "decoder inputs: most importantly my UNK UNK bug free .\n",
      "predictions: they of , cats love this it .\n",
      "batch_ind/epoch: 6300/1 out of 6961/5\n",
      "Last batch loss:33.6094 KDL: 3.38782 KLD %: 10.0799636071\n",
      "encoder inputs: no nasty aftertaste .\n",
      "decoder inputs: UNK nasty aftertaste .\n",
      "predictions: no a it .\n",
      "batch_ind/epoch: 6350/1 out of 6961/5\n",
      "Last batch loss:36.3997 KDL: 3.2946 KLD %: 9.05118848212\n",
      "encoder inputs: catches everything from UNK to UNK .\n",
      "decoder inputs: catches everything from UNK UNK UNK .\n",
      "predictions: the is , the and UNK .\n",
      "batch_ind/epoch: 6400/1 out of 6961/5\n",
      "Last batch loss:38.1096 KDL: 3.32262 KLD %: 8.71859794458\n",
      "encoder inputs: give it a try , it 's delicious !\n",
      "decoder inputs: give it a UNK , it 's UNK !\n",
      "predictions: a it a try , but 's delicious .\n",
      "batch_ind/epoch: 6450/1 out of 6961/5\n",
      "Last batch loss:35.2269 KDL: 3.20257 KLD %: 9.09126866083\n",
      "encoder inputs: really delicious seasoning and UNK that i highly recommend .\n",
      "decoder inputs: really UNK seasoning and UNK that i highly recommend UNK\n",
      "predictions: if like , , the , is love recommend .\n",
      "batch_ind/epoch: 6500/1 out of 6961/5\n",
      "Last batch loss:34.8905 KDL: 3.19729 KLD %: 9.16378012764\n",
      "encoder inputs: not just pleasantly surprised but actually amazed .\n",
      "decoder inputs: not UNK pleasantly UNK but UNK amazed .\n",
      "predictions: and too , , a not great .\n",
      "batch_ind/epoch: 6550/1 out of 6961/5\n",
      "Last batch loss:34.8197 KDL: 3.35371 KLD %: 9.63163847651\n",
      "encoder inputs: plus they 're biodegradable !\n",
      "decoder inputs: UNK they 're biodegradable UNK\n",
      "predictions: just , are great .\n",
      "batch_ind/epoch: 6600/1 out of 6961/5\n",
      "Last batch loss:37.0671 KDL: 3.30337 KLD %: 8.91185703418\n",
      "encoder inputs: the cats love it .\n",
      "decoder inputs: the cats love it .\n",
      "predictions: the taste love it .\n",
      "batch_ind/epoch: 6650/1 out of 6961/5\n",
      "Last batch loss:33.264 KDL: 3.27984 KLD %: 9.86002047717\n",
      "encoder inputs: somehow it turned salty soapy very bitter taste .\n",
      "decoder inputs: UNK UNK turned salty soapy very bitter UNK .\n",
      "predictions: just , , a , stars good taste .\n",
      "batch_ind/epoch: 6700/1 out of 6961/5\n",
      "Last batch loss:29.8697 KDL: 3.30599 KLD %: 11.0680351941\n",
      "encoder inputs: you choose how often to receive delivery .\n",
      "decoder inputs: UNK choose how often to UNK delivery .\n",
      "predictions: the , , good and the it .\n",
      "batch_ind/epoch: 6750/1 out of 6961/5\n",
      "Last batch loss:33.2905 KDL: 3.25761 KLD %: 9.78541296356\n",
      "encoder inputs: there is no nasty after taste or any jitters .\n",
      "decoder inputs: there UNK no UNK after taste UNK any UNK .\n",
      "predictions: the is no more , taste of the UNK .\n",
      "batch_ind/epoch: 6800/1 out of 6961/5\n",
      "Last batch loss:33.8684 KDL: 3.21243 KLD %: 9.48502290445\n",
      "encoder inputs: amazon , of course , popped up !\n",
      "decoder inputs: amazon UNK of UNK , popped up !\n",
      "predictions: the has the the is not it .\n",
      "batch_ind/epoch: 6850/1 out of 6961/5\n",
      "Last batch loss:30.4595 KDL: 3.28109 KLD %: 10.7719860242\n",
      "encoder inputs: this brand is the best tasting to me .\n",
      "decoder inputs: this brand is the best UNK UNK me .\n",
      "predictions: this is is a best coffee i ever .\n",
      "batch_ind/epoch: 6900/1 out of 6961/5\n",
      "Last batch loss:31.6812 KDL: 3.3317 KLD %: 10.516341655\n",
      "encoder inputs: i would recommend these for kids and adults !\n",
      "decoder inputs: i UNK recommend UNK for kids UNK adults UNK\n",
      "predictions: i will the this to my love them .\n",
      "batch_ind/epoch: 6950/1 out of 6961/5\n",
      "Last batch loss:36.1992 KDL: 3.36494 KLD %: 9.29561677175\n",
      "encoder inputs: it is simply superior rice .\n",
      "decoder inputs: UNK is simply superior UNK .\n",
      "predictions: it 's a amazing . .\n",
      "WARNING:tensorflow:Error encountered when serializing model_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'bytes' object has no attribute 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: %ssave/VAE-0\n",
      "execution took: 12312.408630230986 seconds\n",
      "batch_ind/epoch: 1/2 out of 6961/5\n",
      "Last batch loss:32.1628 KDL: 3.31681 KLD %: 10.3125505187\n",
      "encoder inputs: not too chewy , and very flavorful .\n",
      "decoder inputs: not UNK chewy , UNK very flavorful .\n",
      "predictions: not too , , but , good .\n",
      "batch_ind/epoch: 50/2 out of 6961/5\n",
      "Last batch loss:34.8133 KDL: 3.16679 KLD %: 9.09650972766\n",
      "encoder inputs: tastes pretty crappy .\n",
      "decoder inputs: UNK pretty crappy .\n",
      "predictions: they are good .\n",
      "batch_ind/epoch: 100/2 out of 6961/5\n",
      "Last batch loss:30.9039 KDL: 3.34801 KLD %: 10.8335903915\n",
      "encoder inputs: i 'm still not sure what flavor it is .\n",
      "decoder inputs: i UNK still not sure what flavor UNK UNK UNK\n",
      "predictions: i 'm this to a what it is it .\n",
      "batch_ind/epoch: 150/2 out of 6961/5\n",
      "Last batch loss:32.6378 KDL: 3.07147 KLD %: 9.41077136679\n",
      "encoder inputs: now i have 5 lbs .\n",
      "decoder inputs: UNK i have 5 UNK .\n",
      "predictions: great , love a stars .\n",
      "batch_ind/epoch: 200/2 out of 6961/5\n",
      "Last batch loss:33.1212 KDL: 3.25164 KLD %: 9.81741917747\n",
      "encoder inputs: the 4 packages arrived not in an outer box !\n",
      "decoder inputs: the 4 packages UNK UNK in an outer box !\n",
      "predictions: it price equivalent is is is the excellent treat .\n",
      "batch_ind/epoch: 250/2 out of 6961/5\n",
      "Last batch loss:38.1877 KDL: 3.2775 KLD %: 8.58260743265\n",
      "encoder inputs: they loved it !\n",
      "decoder inputs: they UNK it !\n",
      "predictions: they are great .\n",
      "batch_ind/epoch: 300/2 out of 6961/5\n",
      "Last batch loss:33.9937 KDL: 3.34688 KLD %: 9.84560529322\n",
      "encoder inputs: the best thing ... no UNK .\n",
      "decoder inputs: the UNK thing ... UNK UNK .\n",
      "predictions: the taste is are are it .\n",
      "batch_ind/epoch: 350/2 out of 6961/5\n",
      "Last batch loss:33.2684 KDL: 3.24239 KLD %: 9.74615350525\n",
      "encoder inputs: me , into a UNK ! )\n",
      "decoder inputs: UNK UNK into a UNK UNK )\n",
      "predictions: these are and a great . .\n",
      "batch_ind/epoch: 400/2 out of 6961/5\n",
      "Last batch loss:34.2096 KDL: 3.32622 KLD %: 9.7230623389\n",
      "encoder inputs: saying she loves these chews is a UNK understatement .\n",
      "decoder inputs: UNK she loves these UNK is UNK UNK understatement .\n",
      "predictions: not , is them are are a good . .\n",
      "batch_ind/epoch: 450/2 out of 6961/5\n",
      "Last batch loss:36.2912 KDL: 3.21846 KLD %: 8.86841151358\n",
      "encoder inputs: i compete in UNK and crave carbs while dieting .\n",
      "decoder inputs: i compete UNK UNK and crave carbs while UNK .\n",
      "predictions: i was it the the it , and it .\n",
      "batch_ind/epoch: 500/2 out of 6961/5\n",
      "Last batch loss:35.2133 KDL: 3.28232 KLD %: 9.32126773057\n",
      "encoder inputs: that 's really fast .\n",
      "decoder inputs: that 's UNK UNK UNK\n",
      "predictions: the 's a good .\n",
      "batch_ind/epoch: 550/2 out of 6961/5\n",
      "Last batch loss:33.1484 KDL: 3.33415 KLD %: 10.0582502653\n",
      "encoder inputs: but i was pleasantly surprised .\n",
      "decoder inputs: but i was UNK UNK .\n",
      "predictions: what this love very disappointed .\n",
      "batch_ind/epoch: 600/2 out of 6961/5\n",
      "Last batch loss:35.6259 KDL: 3.31485 KLD %: 9.30460058237\n",
      "encoder inputs: pour the hot water out of the cup .\n",
      "decoder inputs: pour UNK hot water out UNK the cup .\n",
      "predictions: but it is chocolate and of the UNK .\n",
      "batch_ind/epoch: 650/2 out of 6961/5\n",
      "Last batch loss:34.2085 KDL: 3.28268 KLD %: 9.59609690365\n",
      "encoder inputs: stir until melted .\n",
      "decoder inputs: stir until melted .\n",
      "predictions: they it chocolate .\n",
      "batch_ind/epoch: 700/2 out of 6961/5\n",
      "Last batch loss:30.8642 KDL: 3.50279 KLD %: 11.3490682131\n",
      "encoder inputs: i would never buy this coffee again .\n",
      "decoder inputs: i would never buy this coffee again .\n",
      "predictions: i will not buy this again .\n",
      "batch_ind/epoch: 750/2 out of 6961/5\n",
      "Last batch loss:35.1469 KDL: 3.23314 KLD %: 9.1989513149\n",
      "encoder inputs: the above indicates a lifelong relationship .\n",
      "decoder inputs: the UNK indicates a lifelong relationship .\n",
      "predictions: i UNK is was great flavor .\n",
      "batch_ind/epoch: 800/2 out of 6961/5\n",
      "Last batch loss:36.0627 KDL: 3.346 KLD %: 9.27826759576\n",
      "encoder inputs: the spicing really suits the cashews .\n",
      "decoder inputs: the UNK UNK UNK UNK cashews UNK\n",
      "predictions: the taste is is and good .\n",
      "batch_ind/epoch: 850/2 out of 6961/5\n",
      "Last batch loss:31.1283 KDL: 3.38825 KLD %: 10.8848059744\n",
      "encoder inputs: it makes an excellent cup .\n",
      "decoder inputs: UNK makes an excellent UNK .\n",
      "predictions: it is a excellent product .\n",
      "batch_ind/epoch: 900/2 out of 6961/5\n",
      "Last batch loss:35.6119 KDL: 3.3299 KLD %: 9.35051270672\n",
      "encoder inputs: these cookies are a favorite of mine .\n",
      "decoder inputs: these cookies UNK a favorite of mine .\n",
      "predictions: they are are are little of all .\n",
      "batch_ind/epoch: 950/2 out of 6961/5\n",
      "Last batch loss:36.8618 KDL: 3.22677 KLD %: 8.75371775488\n",
      "encoder inputs: worth a try !\n",
      "decoder inputs: worth a UNK !\n",
      "predictions: love every try .\n",
      "batch_ind/epoch: 1000/2 out of 6961/5\n",
      "Last batch loss:34.0435 KDL: 3.48118 KLD %: 10.2256632951\n",
      "encoder inputs: not to be .\n",
      "decoder inputs: not to UNK .\n",
      "predictions: these too me .\n",
      "batch_ind/epoch: 1050/2 out of 6961/5\n",
      "Last batch loss:34.6769 KDL: 3.51183 KLD %: 10.1272912664\n",
      "encoder inputs: i use it with plain yogurt and equal .\n",
      "decoder inputs: i use it UNK plain yogurt and equal .\n",
      "predictions: i am it for a and and UNK .\n",
      "batch_ind/epoch: 1100/2 out of 6961/5\n",
      "Last batch loss:35.8282 KDL: 3.28962 KLD %: 9.18164918414\n",
      "encoder inputs: i would suggest those flavors over this one .\n",
      "decoder inputs: i would UNK those flavors UNK this UNK UNK\n",
      "predictions: i have recommend recommend this in the product .\n",
      "batch_ind/epoch: 1150/2 out of 6961/5\n",
      "Last batch loss:32.5535 KDL: 3.46447 KLD %: 10.6423889663\n",
      "encoder inputs: but i will be ordering again .\n",
      "decoder inputs: UNK UNK UNK be ordering again .\n",
      "predictions: the , is is good . .\n",
      "batch_ind/epoch: 1200/2 out of 6961/5\n",
      "Last batch loss:28.3987 KDL: 3.26027 KLD %: 11.4803738094\n",
      "encoder inputs: love it on popcorn now too !\n",
      "decoder inputs: love it on UNK UNK UNK UNK\n",
      "predictions: we the , the and and . .\n",
      "batch_ind/epoch: 1250/2 out of 6961/5\n",
      "Last batch loss:29.432 KDL: 3.47722 KLD %: 11.81444685\n",
      "encoder inputs: it is neat and resealable .\n",
      "decoder inputs: UNK UNK UNK and resealable .\n",
      "predictions: it is a great delicious .\n",
      "batch_ind/epoch: 1300/2 out of 6961/5\n",
      "Last batch loss:30.8842 KDL: 3.41428 KLD %: 11.0551083549\n",
      "encoder inputs: it 's sweet with a slight tartness .\n",
      "decoder inputs: it 's sweet with a slight tartness .\n",
      "predictions: it 's a , a little gift .\n",
      "batch_ind/epoch: 1350/2 out of 6961/5\n",
      "Last batch loss:37.0939 KDL: 3.33575 KLD %: 8.99273275545\n",
      "encoder inputs: it 's organic and seems to be nutritious !\n",
      "decoder inputs: it 's organic and seems to UNK nutritious !\n",
      "predictions: it is a and the to be it .\n",
      "batch_ind/epoch: 1400/2 out of 6961/5\n",
      "Last batch loss:34.2673 KDL: 3.34293 KLD %: 9.75546339959\n",
      "encoder inputs: i love the taste .\n",
      "decoder inputs: UNK love the UNK .\n",
      "predictions: i love this flavor .\n",
      "batch_ind/epoch: 1450/2 out of 6961/5\n",
      "Last batch loss:33.927 KDL: 3.32787 KLD %: 9.80892108804\n",
      "encoder inputs: we 'll see .\n",
      "decoder inputs: we UNK see .\n",
      "predictions: we love it .\n",
      "batch_ind/epoch: 1500/2 out of 6961/5\n",
      "Last batch loss:32.3061 KDL: 3.37523 KLD %: 10.4476399311\n",
      "encoder inputs: i would n't buy it again .\n",
      "decoder inputs: i would n't buy it again .\n",
      "predictions: i would recommend buy this again .\n",
      "batch_ind/epoch: 1550/2 out of 6961/5\n",
      "Last batch loss:31.234 KDL: 3.25409 KLD %: 10.4184207974\n",
      "encoder inputs: it is good for people on diets thanks\n",
      "decoder inputs: it is good for people on diets UNK\n",
      "predictions: it 's a , you and time .\n",
      "batch_ind/epoch: 1600/2 out of 6961/5\n",
      "Last batch loss:31.7173 KDL: 3.47026 KLD %: 10.9412203415\n",
      "encoder inputs: very good quality chocolate .\n",
      "decoder inputs: UNK good UNK chocolate .\n",
      "predictions: not you for too .\n",
      "batch_ind/epoch: 1650/2 out of 6961/5\n",
      "Last batch loss:35.1959 KDL: 3.42449 KLD %: 9.72979252334\n",
      "encoder inputs: the duck pill pockets are a god send .\n",
      "decoder inputs: the duck pill UNK are UNK god send UNK\n",
      "predictions: the taste was was was very good . .\n",
      "batch_ind/epoch: 1700/2 out of 6961/5\n",
      "Last batch loss:32.8636 KDL: 3.22307 KLD %: 9.8073988573\n",
      "encoder inputs: i really missed my moo .\n",
      "decoder inputs: i UNK missed UNK UNK UNK\n",
      "predictions: i love this this UNK .\n",
      "batch_ind/epoch: 1750/2 out of 6961/5\n",
      "Last batch loss:34.3265 KDL: 3.28914 KLD %: 9.58192143041\n",
      "encoder inputs: ca n't say enough good things about this cocoa .\n",
      "decoder inputs: ca n't UNK enough good things about this UNK .\n",
      "predictions: these n't wait enough to for to this product .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_ind/epoch: 1800/2 out of 6961/5\n",
      "Last batch loss:33.224 KDL: 3.53572 KLD %: 10.6420746495\n",
      "encoder inputs: i ca n't wait to try more flavors !\n",
      "decoder inputs: i UNK UNK wait to try more flavors !\n",
      "predictions: it was this to to try it soon .\n",
      "batch_ind/epoch: 1850/2 out of 6961/5\n",
      "Last batch loss:33.1323 KDL: 3.35178 KLD %: 10.1163703447\n",
      "encoder inputs: the chai latte is delicious !\n",
      "decoder inputs: UNK UNK latte is delicious !\n",
      "predictions: the is is is great .\n",
      "batch_ind/epoch: 1900/2 out of 6961/5\n",
      "Last batch loss:35.707 KDL: 3.37122 KLD %: 9.44132671103\n",
      "encoder inputs: they arrived quickly and in good shape !\n",
      "decoder inputs: UNK UNK quickly and UNK UNK UNK !\n",
      "predictions: these , the and a are good .\n",
      "batch_ind/epoch: 1950/2 out of 6961/5\n",
      "Last batch loss:32.8387 KDL: 3.29824 KLD %: 10.0437668497\n",
      "encoder inputs: i have to drink about two cups each time !\n",
      "decoder inputs: UNK have to drink about two cups UNK time !\n",
      "predictions: i have been try it the weeks of day .\n",
      "batch_ind/epoch: 2000/2 out of 6961/5\n",
      "Last batch loss:32.3552 KDL: 3.38957 KLD %: 10.4761027316\n",
      "encoder inputs: also , the food looks like real food .\n",
      "decoder inputs: also , the food looks like UNK UNK .\n",
      "predictions: these , the price is like a UNK .\n",
      "batch_ind/epoch: 2050/2 out of 6961/5\n",
      "Last batch loss:32.5634 KDL: 3.37254 KLD %: 10.3568530026\n",
      "encoder inputs: i highly recommend this product .\n",
      "decoder inputs: UNK highly UNK UNK product UNK\n",
      "predictions: i will recommend this product .\n",
      "batch_ind/epoch: 2100/2 out of 6961/5\n",
      "Last batch loss:34.8678 KDL: 3.42748 KLD %: 9.82993644573\n",
      "encoder inputs: dry and tough .\n",
      "decoder inputs: UNK and tough .\n",
      "predictions: thanks , delicious !\n",
      "batch_ind/epoch: 2150/2 out of 6961/5\n",
      "Last batch loss:33.8785 KDL: 3.30271 KLD %: 9.74871234069\n",
      "encoder inputs: i never got sick once while on this stuff .\n",
      "decoder inputs: i never got sick UNK while on this stuff .\n",
      "predictions: i 'm had this to a for the stuff .\n",
      "batch_ind/epoch: 2200/2 out of 6961/5\n",
      "Last batch loss:31.8478 KDL: 3.37289 KLD %: 10.5906384452\n",
      "encoder inputs: this candy is addicting !\n",
      "decoder inputs: UNK UNK is addicting !\n",
      "predictions: it 's great great !\n",
      "batch_ind/epoch: 2250/2 out of 6961/5\n",
      "Last batch loss:33.8544 KDL: 3.404 KLD %: 10.054817467\n",
      "encoder inputs: it makes a great , easy lunch .\n",
      "decoder inputs: it makes UNK UNK , UNK lunch UNK\n",
      "predictions: it 's a a and too . .\n",
      "batch_ind/epoch: 2300/2 out of 6961/5\n",
      "Last batch loss:31.9475 KDL: 3.3969 KLD %: 10.6327711555\n",
      "encoder inputs: the spices are perfect .\n",
      "decoder inputs: the spices are perfect .\n",
      "predictions: the taste are great .\n",
      "batch_ind/epoch: 2350/2 out of 6961/5\n",
      "Last batch loss:33.3208 KDL: 3.41138 KLD %: 10.2379953849\n",
      "encoder inputs: no more begging for food every 5 minutes .\n",
      "decoder inputs: UNK more begging for food every 5 minutes UNK\n",
      "predictions: we the UNK than a to morning minutes .\n",
      "batch_ind/epoch: 2400/2 out of 6961/5\n",
      "Last batch loss:31.9524 KDL: 3.40176 KLD %: 10.6463413433\n",
      "encoder inputs: you 'll have to give it a try .\n",
      "decoder inputs: UNK 'll have to UNK UNK a try .\n",
      "predictions: i have be a try it for day .\n",
      "batch_ind/epoch: 2450/2 out of 6961/5\n",
      "Last batch loss:33.5217 KDL: 3.42646 KLD %: 10.2216231773\n",
      "encoder inputs: my stomach loves you .\n",
      "decoder inputs: my stomach UNK UNK .\n",
      "predictions: my dog loves . .\n",
      "batch_ind/epoch: 2500/2 out of 6961/5\n",
      "Last batch loss:35.8009 KDL: 3.30148 KLD %: 9.2217971549\n",
      "encoder inputs: it 's too much .\n",
      "decoder inputs: it 's too much .\n",
      "predictions: it 's very sweet .\n",
      "batch_ind/epoch: 2550/2 out of 6961/5\n",
      "Last batch loss:31.8738 KDL: 3.57018 KLD %: 11.2009947187\n",
      "encoder inputs: and it worked out even better than the muffins .\n",
      "decoder inputs: UNK it worked out even better than UNK UNK .\n",
      "predictions: if , is for of better than the UNK .\n",
      "batch_ind/epoch: 2600/2 out of 6961/5\n",
      "Last batch loss:35.7126 KDL: 3.24066 KLD %: 9.07429419049\n",
      "encoder inputs: great real coconut young coconut taste .\n",
      "decoder inputs: UNK real coconut UNK coconut UNK UNK\n",
      "predictions: great , is oil UNK .\n",
      "batch_ind/epoch: 2650/2 out of 6961/5\n",
      "Last batch loss:34.1715 KDL: 3.414 KLD %: 9.99080666062\n",
      "encoder inputs: i am very happy with this food ! ! !\n",
      "decoder inputs: i am UNK UNK with this UNK ! UNK !\n",
      "predictions: i have a happy with this product .\n",
      "batch_ind/epoch: 2700/2 out of 6961/5\n",
      "Last batch loss:34.1566 KDL: 3.27838 KLD %: 9.59809968636\n",
      "encoder inputs: what do i do with it now ? ?\n",
      "decoder inputs: what do i do with it now ? ?\n",
      "predictions: no more i do n't the ? ? ?\n",
      "batch_ind/epoch: 2750/2 out of 6961/5\n",
      "Last batch loss:32.7537 KDL: 3.49712 KLD %: 10.6770106634\n",
      "encoder inputs: plus it 's rather noisy .\n",
      "decoder inputs: plus it 's rather noisy UNK\n",
      "predictions: very , 's really . .\n",
      "batch_ind/epoch: 2800/2 out of 6961/5\n",
      "Last batch loss:30.2237 KDL: 3.48441 KLD %: 11.5287293548\n",
      "encoder inputs: it overwhelms the flavor .\n",
      "decoder inputs: it UNK the UNK .\n",
      "predictions: the is so best .\n",
      "batch_ind/epoch: 2850/2 out of 6961/5\n",
      "Last batch loss:31.1977 KDL: 3.30073 KLD %: 10.5800229803\n",
      "encoder inputs: i strongly recommend this popcorn .\n",
      "decoder inputs: i UNK recommend this popcorn .\n",
      "predictions: i love this this product .\n",
      "batch_ind/epoch: 2900/2 out of 6961/5\n",
      "Last batch loss:32.0105 KDL: 3.38777 KLD %: 10.5833235514\n",
      "encoder inputs: it smelled absolutely sinful while it brewed .\n",
      "decoder inputs: it UNK absolutely sinful while UNK brewed .\n",
      "predictions: it 's a delicious and and flavor .\n",
      "batch_ind/epoch: 2950/2 out of 6961/5\n",
      "Last batch loss:33.6333 KDL: 3.42178 KLD %: 10.1738047331\n",
      "encoder inputs: read every label peace\n",
      "decoder inputs: read every label peace\n",
      "predictions: great the time .\n",
      "batch_ind/epoch: 3000/2 out of 6961/5\n",
      "Last batch loss:34.0707 KDL: 3.34512 KLD %: 9.81817791471\n",
      "encoder inputs: the taste is very beef broth like .\n",
      "decoder inputs: the taste UNK UNK beef broth like .\n",
      "predictions: it taste is the and jerky . .\n",
      "batch_ind/epoch: 3050/2 out of 6961/5\n",
      "Last batch loss:33.4238 KDL: 3.38517 KLD %: 10.1280445945\n",
      "encoder inputs: i love it any time of the day .\n",
      "decoder inputs: UNK UNK UNK any time of the day .\n",
      "predictions: i have the to other of the bag .\n",
      "batch_ind/epoch: 3100/2 out of 6961/5\n",
      "Last batch loss:32.8329 KDL: 3.37164 KLD %: 10.2690879264\n",
      "encoder inputs: best thing i 've ordered on line .\n",
      "decoder inputs: UNK UNK i 've ordered on line UNK\n",
      "predictions: the is is have found this it .\n",
      "batch_ind/epoch: 3150/2 out of 6961/5\n",
      "Last batch loss:32.0592 KDL: 3.45801 KLD %: 10.7863075352\n",
      "encoder inputs: you wo n't be disappointed .\n",
      "decoder inputs: you wo n't be disappointed .\n",
      "predictions: i wo n't be disappointed .\n",
      "batch_ind/epoch: 3200/2 out of 6961/5\n",
      "Last batch loss:34.2244 KDL: 3.28347 KLD %: 9.59392056696\n",
      "encoder inputs: these wasabi flavored roasted UNK are okay .\n",
      "decoder inputs: these wasabi UNK roasted UNK UNK UNK .\n",
      "predictions: these are are are the and UNK .\n",
      "batch_ind/epoch: 3250/2 out of 6961/5\n",
      "Last batch loss:31.664 KDL: 3.33152 KLD %: 10.5214594537\n",
      "encoder inputs: enjoy ! gary peterson\n",
      "decoder inputs: UNK ! gary peterson\n",
      "predictions: will , ! peterson !\n",
      "batch_ind/epoch: 3300/2 out of 6961/5\n",
      "Last batch loss:32.5811 KDL: 3.46544 KLD %: 10.636329025\n",
      "encoder inputs: zico is still amazing .\n",
      "decoder inputs: zico UNK UNK UNK .\n",
      "predictions: what a UNK . .\n",
      "batch_ind/epoch: 3350/2 out of 6961/5\n",
      "Last batch loss:32.6546 KDL: 3.29945 KLD %: 10.1041069061\n",
      "encoder inputs: no bitterness at all .\n",
      "decoder inputs: no bitterness at all .\n",
      "predictions: we more or all .\n",
      "batch_ind/epoch: 3400/2 out of 6961/5\n",
      "Last batch loss:31.936 KDL: 3.30379 KLD %: 10.3450335059\n",
      "encoder inputs: only 100 calories per bag .\n",
      "decoder inputs: only 100 calories per bag UNK\n",
      "predictions: great problem % per serving .\n",
      "batch_ind/epoch: 3450/2 out of 6961/5\n",
      "Last batch loss:31.2671 KDL: 3.46164 KLD %: 11.0711746951\n",
      "encoder inputs: it works 85 % of the time .\n",
      "decoder inputs: it works 85 UNK of the time .\n",
      "predictions: it 's well , a the best .\n",
      "batch_ind/epoch: 3500/2 out of 6961/5\n",
      "Last batch loss:34.5534 KDL: 3.54502 KLD %: 10.259537905\n",
      "encoder inputs: the flavor is excellent UNK great .\n",
      "decoder inputs: the UNK is excellent UNK great .\n",
      "predictions: the taste is very and too .\n",
      "batch_ind/epoch: 3550/2 out of 6961/5\n",
      "Last batch loss:33.3292 KDL: 3.37548 KLD %: 10.1276895227\n",
      "encoder inputs: love this product !\n",
      "decoder inputs: love UNK UNK !\n",
      "predictions: we this product !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_ind/epoch: 3600/2 out of 6961/5\n",
      "Last batch loss:30.7718 KDL: 3.30304 KLD %: 10.7339881209\n",
      "encoder inputs: her baking mixes are UNK .\n",
      "decoder inputs: UNK UNK mixes are UNK UNK\n",
      "predictions: the is is are great .\n",
      "batch_ind/epoch: 3650/2 out of 6961/5\n",
      "Last batch loss:35.0296 KDL: 3.55827 KLD %: 10.1578766811\n",
      "encoder inputs: price with subscribe and save is very good .\n",
      "decoder inputs: price UNK subscribe UNK UNK is very good .\n",
      "predictions: the is the and save is a good .\n",
      "batch_ind/epoch: 3700/2 out of 6961/5\n",
      "Last batch loss:32.1339 KDL: 3.44346 KLD %: 10.7159593495\n",
      "encoder inputs: one end is covered with a sticker .\n",
      "decoder inputs: one UNK UNK covered with a sticker .\n",
      "predictions: so of my and and this UNK .\n",
      "batch_ind/epoch: 3750/2 out of 6961/5\n",
      "Last batch loss:31.3799 KDL: 3.54723 KLD %: 11.3041490407\n",
      "encoder inputs: they are all meat - absolutely nothing else .\n",
      "decoder inputs: they are all meat - absolutely nothing else UNK\n",
      "predictions: these are a the , i love special .\n",
      "batch_ind/epoch: 3800/2 out of 6961/5\n",
      "Last batch loss:31.8806 KDL: 3.23748 KLD %: 10.1550097884\n",
      "encoder inputs: these cookies taste like the real thing !\n",
      "decoder inputs: these cookies taste like the UNK thing !\n",
      "predictions: they are are great a taste . .\n",
      "batch_ind/epoch: 3850/2 out of 6961/5\n",
      "Last batch loss:33.0414 KDL: 3.45844 KLD %: 10.4669881469\n",
      "encoder inputs: ) , so give them a try .\n",
      "decoder inputs: ) UNK so give them a UNK UNK\n",
      "predictions: but , the much it a try .\n",
      "batch_ind/epoch: 3900/2 out of 6961/5\n",
      "Last batch loss:33.1561 KDL: 3.41582 KLD %: 10.3022569564\n",
      "encoder inputs: we definitely will be buying more .\n",
      "decoder inputs: we UNK will UNK buying more .\n",
      "predictions: but have n't be be more .\n",
      "batch_ind/epoch: 3950/2 out of 6961/5\n",
      "Last batch loss:38.5914 KDL: 3.63106 KLD %: 9.40898807088\n",
      "encoder inputs: too expensive for 15 minutes of entertainment .\n",
      "decoder inputs: UNK UNK for 15 minutes of entertainment .\n",
      "predictions: these , , a years for them .\n",
      "batch_ind/epoch: 4000/2 out of 6961/5\n",
      "Last batch loss:32.1735 KDL: 3.35817 KLD %: 10.4376974059\n",
      "encoder inputs: would definitely order this again and good price too !\n",
      "decoder inputs: would definitely UNK UNK again and good price UNK !\n",
      "predictions: a not recommend this again and again for too .\n",
      "batch_ind/epoch: 4050/2 out of 6961/5\n",
      "Last batch loss:33.2821 KDL: 3.38624 KLD %: 10.1743527831\n",
      "encoder inputs: this however is delicious !\n",
      "decoder inputs: this however is delicious UNK\n",
      "predictions: this product is awesome .\n",
      "batch_ind/epoch: 4100/2 out of 6961/5\n",
      "Last batch loss:34.3624 KDL: 3.37369 KLD %: 9.81797356921\n",
      "encoder inputs: loved the spray !\n",
      "decoder inputs: loved UNK spray !\n",
      "predictions: UNK it UNK .\n",
      "batch_ind/epoch: 4150/2 out of 6961/5\n",
      "Last batch loss:29.1555 KDL: 3.46466 KLD %: 11.8833967993\n",
      "encoder inputs: not what i hoped for .\n",
      "decoder inputs: not what UNK UNK for UNK\n",
      "predictions: will a i was for .\n",
      "batch_ind/epoch: 4200/2 out of 6961/5\n",
      "Last batch loss:30.7978 KDL: 3.36443 KLD %: 10.9242551098\n",
      "encoder inputs: my kids love it too .\n",
      "decoder inputs: my UNK UNK it too .\n",
      "predictions: my dog loves these too .\n",
      "batch_ind/epoch: 4250/2 out of 6961/5\n",
      "Last batch loss:30.021 KDL: 3.54123 KLD %: 11.7958323652\n",
      "encoder inputs: it 's perfect for movie night !\n",
      "decoder inputs: it UNK perfect for movie UNK !\n",
      "predictions: it is a for my UNK .\n",
      "batch_ind/epoch: 4300/2 out of 6961/5\n",
      "Last batch loss:30.3724 KDL: 3.61647 KLD %: 11.9070954777\n",
      "encoder inputs: this large package lasts us a long time .\n",
      "decoder inputs: this large package UNK UNK a long time .\n",
      "predictions: this is the is a a great time .\n",
      "batch_ind/epoch: 4350/2 out of 6961/5\n",
      "Last batch loss:30.6122 KDL: 3.39477 KLD %: 11.089607625\n",
      "encoder inputs: big plus for me .\n",
      "decoder inputs: big plus UNK me .\n",
      "predictions: and , , . .\n",
      "batch_ind/epoch: 4400/2 out of 6961/5\n",
      "Last batch loss:32.8366 KDL: 3.44846 KLD %: 10.5018812606\n",
      "encoder inputs: perfect for snacking .\n",
      "decoder inputs: UNK UNK snacking UNK\n",
      "predictions: perfect love great !\n",
      "batch_ind/epoch: 4450/2 out of 6961/5\n",
      "Last batch loss:35.4533 KDL: 3.37127 KLD %: 9.50904902812\n",
      "encoder inputs: hard to tell that they are baked .\n",
      "decoder inputs: UNK to tell that they UNK baked .\n",
      "predictions: so is be the i are great .\n",
      "batch_ind/epoch: 4500/2 out of 6961/5\n",
      "Last batch loss:32.4349 KDL: 3.45983 KLD %: 10.666987362\n",
      "encoder inputs: this yummy little baked confection was truly delicious .\n",
      "decoder inputs: this yummy little UNK confection UNK truly UNK UNK\n",
      "predictions: this is is honey , of and taste .\n",
      "batch_ind/epoch: 4550/2 out of 6961/5\n",
      "Last batch loss:31.8489 KDL: 3.47416 KLD %: 10.908246334\n",
      "encoder inputs: i was very happy with this product .\n",
      "decoder inputs: i was UNK happy with UNK product .\n",
      "predictions: you was very disappointed with this product .\n",
      "batch_ind/epoch: 4600/2 out of 6961/5\n",
      "Last batch loss:31.9751 KDL: 3.43308 KLD %: 10.73674564\n",
      "encoder inputs: use this over rice for a meal !\n",
      "decoder inputs: UNK this over UNK for UNK UNK !\n",
      "predictions: just , is a a the UNK .\n",
      "batch_ind/epoch: 4650/2 out of 6961/5\n",
      "Last batch loss:26.6549 KDL: 3.35831 KLD %: 12.5992266593\n",
      "encoder inputs: no heavy flavor .\n",
      "decoder inputs: no heavy flavor .\n",
      "predictions: we more here .\n",
      "batch_ind/epoch: 4700/2 out of 6961/5\n",
      "Last batch loss:30.2204 KDL: 3.48827 KLD %: 11.5427719038\n",
      "encoder inputs: everything about this product is excellent .\n",
      "decoder inputs: UNK UNK this product is excellent UNK\n",
      "predictions: the , is is is great .\n",
      "batch_ind/epoch: 4750/2 out of 6961/5\n",
      "Last batch loss:33.6798 KDL: 3.37644 KLD %: 10.0251097044\n",
      "encoder inputs: i love them !\n",
      "decoder inputs: i love UNK !\n",
      "predictions: i love this tea\n",
      "batch_ind/epoch: 4800/2 out of 6961/5\n",
      "Last batch loss:32.0995 KDL: 3.601 KLD %: 11.2182483884\n",
      "encoder inputs: this year everyone is going to be happy !\n",
      "decoder inputs: this UNK everyone UNK going UNK be happy !\n",
      "predictions: it is is is a to of UNK .\n",
      "batch_ind/epoch: 4850/2 out of 6961/5\n",
      "Last batch loss:30.2911 KDL: 3.46519 KLD %: 11.4396464096\n",
      "encoder inputs: these are the best tasting pretzels !\n",
      "decoder inputs: these are the UNK UNK pretzels !\n",
      "predictions: these are the best best ever .\n",
      "batch_ind/epoch: 4900/2 out of 6961/5\n",
      "Last batch loss:34.8031 KDL: 3.54179 KLD %: 10.1766555791\n",
      "encoder inputs: i do n't like overly sweet drinks .\n",
      "decoder inputs: UNK do UNK UNK overly UNK UNK UNK\n",
      "predictions: they are n't like the for it .\n",
      "batch_ind/epoch: 4950/2 out of 6961/5\n",
      "Last batch loss:29.2281 KDL: 3.3808 KLD %: 11.5669259535\n",
      "encoder inputs: did you know it was invented by a doctor !\n",
      "decoder inputs: did UNK know it UNK invented by a doctor UNK\n",
      "predictions: however n't like the was a , the case .\n",
      "batch_ind/epoch: 5000/2 out of 6961/5\n",
      "Last batch loss:30.7862 KDL: 3.37597 KLD %: 10.9658643181\n",
      "encoder inputs: the tea is delicious .\n",
      "decoder inputs: the tea is delicious .\n",
      "predictions: great taste is great .\n",
      "batch_ind/epoch: 5050/2 out of 6961/5\n",
      "Last batch loss:31.5569 KDL: 3.368 KLD %: 10.6727611046\n",
      "encoder inputs: good price even with the shipping costs .\n",
      "decoder inputs: good price even with the shipping costs .\n",
      "predictions: it price and a a quality oz .\n",
      "batch_ind/epoch: 5100/2 out of 6961/5\n",
      "Last batch loss:30.1827 KDL: 3.55675 KLD %: 11.7840590474\n",
      "encoder inputs: thank you cesar !\n",
      "decoder inputs: thank you UNK UNK\n",
      "predictions: not you amazon !\n",
      "batch_ind/epoch: 5150/2 out of 6961/5\n",
      "Last batch loss:30.3428 KDL: 3.49674 KLD %: 11.5241035451\n",
      "encoder inputs: recipe available on UNK `` chocolate biscuit cake . ''\n",
      "decoder inputs: recipe available on UNK `` chocolate UNK cake . ''\n",
      "predictions: but , with the and UNK '' '' .\n",
      "batch_ind/epoch: 5200/2 out of 6961/5\n",
      "Last batch loss:34.8082 KDL: 3.45789 KLD %: 9.93413094953\n",
      "encoder inputs: this xylitol in packets is very chalky in taste .\n",
      "decoder inputs: this xylitol in packets is UNK chalky in taste .\n",
      "predictions: the product is the and a to in taste .\n",
      "batch_ind/epoch: 5250/2 out of 6961/5\n",
      "Last batch loss:33.0658 KDL: 3.43496 KLD %: 10.3882481989\n",
      "encoder inputs: even the hot coco has the artificial sweetener .\n",
      "decoder inputs: UNK the UNK UNK UNK the artificial sweetener UNK\n",
      "predictions: and you best of i the best flavors .\n",
      "batch_ind/epoch: 5300/2 out of 6961/5\n",
      "Last batch loss:30.013 KDL: 3.40351 KLD %: 11.3401118176\n",
      "encoder inputs: ca n't beat that !\n",
      "decoder inputs: ca n't beat that !\n",
      "predictions: will n't go . !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_ind/epoch: 5350/2 out of 6961/5\n",
      "Last batch loss:33.6924 KDL: 3.36422 KLD %: 9.98510064579\n",
      "encoder inputs: she devours every bite .\n",
      "decoder inputs: she devours every bite .\n",
      "predictions: it always so too .\n",
      "batch_ind/epoch: 5400/2 out of 6961/5\n",
      "Last batch loss:33.3432 KDL: 3.48904 KLD %: 10.4640280656\n",
      "encoder inputs: this really tastes like ginger and honey !\n",
      "decoder inputs: this really UNK like UNK UNK honey !\n",
      "predictions: this is is the a UNK coffee .\n",
      "batch_ind/epoch: 5450/2 out of 6961/5\n",
      "Last batch loss:36.3213 KDL: 3.41247 KLD %: 9.39523105246\n",
      "encoder inputs: i could n't be happier !\n",
      "decoder inputs: i could n't UNK happier !\n",
      "predictions: i would n't be it .\n",
      "batch_ind/epoch: 5500/2 out of 6961/5\n",
      "Last batch loss:29.6037 KDL: 3.55349 KLD %: 12.0035411083\n",
      "encoder inputs: my havanese just loves these treats with the apples !\n",
      "decoder inputs: my havanese just loves these treats UNK the apples !\n",
      "predictions: my husband loves loves these and for the best .\n",
      "batch_ind/epoch: 5550/2 out of 6961/5\n",
      "Last batch loss:32.8712 KDL: 3.60632 KLD %: 10.9710499905\n",
      "encoder inputs: all six cans were rancid .\n",
      "decoder inputs: UNK six cans were rancid UNK\n",
      "predictions: UNK , , were dented .\n",
      "batch_ind/epoch: 5600/2 out of 6961/5\n",
      "Last batch loss:37.551 KDL: 3.42937 KLD %: 9.13257157904\n",
      "encoder inputs: this particular one is the mild sweet style .\n",
      "decoder inputs: this particular one is the mild sweet style .\n",
      "predictions: the is is of a best is flavor .\n",
      "batch_ind/epoch: 5650/2 out of 6961/5\n",
      "Last batch loss:33.5875 KDL: 3.49881 KLD %: 10.4169778143\n",
      "encoder inputs: i wanted to love these .\n",
      "decoder inputs: UNK UNK to love UNK UNK\n",
      "predictions: i love n't buy this . .\n",
      "batch_ind/epoch: 5700/2 out of 6961/5\n",
      "Last batch loss:31.406 KDL: 3.60655 KLD %: 11.4836273476\n",
      "encoder inputs: however , the UNK process is UNK .\n",
      "decoder inputs: UNK UNK the UNK UNK is UNK .\n",
      "predictions: and , , best of this great .\n",
      "batch_ind/epoch: 5750/2 out of 6961/5\n",
      "Last batch loss:35.4292 KDL: 3.46701 KLD %: 9.78574964797\n",
      "encoder inputs: on to a chinese type dish next .\n",
      "decoder inputs: UNK to a chinese type UNK next .\n",
      "predictions: great , find little in of UNK .\n",
      "batch_ind/epoch: 5800/2 out of 6961/5\n",
      "Last batch loss:32.5037 KDL: 3.76357 KLD %: 11.5789076506\n",
      "encoder inputs: would n't have it any other way !\n",
      "decoder inputs: would UNK have it any UNK way !\n",
      "predictions: will definitely recommend to to other . .\n",
      "batch_ind/epoch: 5850/2 out of 6961/5\n",
      "Last batch loss:32.8626 KDL: 3.55701 KLD %: 10.8238803427\n",
      "encoder inputs: and far more nutritious than a standard fruit snack .\n",
      "decoder inputs: and far more nutritious than a UNK UNK snack .\n",
      "predictions: we the , than , a little of UNK .\n",
      "batch_ind/epoch: 5900/2 out of 6961/5\n",
      "Last batch loss:34.2388 KDL: 3.58776 KLD %: 10.4786470823\n",
      "encoder inputs: i had my package within 4 days .\n",
      "decoder inputs: i UNK my package UNK 4 days UNK\n",
      "predictions: i have n't UNK to this stars .\n",
      "batch_ind/epoch: 5950/2 out of 6961/5\n",
      "Last batch loss:27.6583 KDL: 3.45322 KLD %: 12.4852871526\n",
      "encoder inputs: i love the convenience of the auto ship program .\n",
      "decoder inputs: UNK love the convenience of UNK UNK UNK program UNK\n",
      "predictions: i are the taste and the the the UNK .\n",
      "batch_ind/epoch: 6000/2 out of 6961/5\n",
      "Last batch loss:37.2452 KDL: 3.24563 KLD %: 8.71422185469\n",
      "encoder inputs: friends of ours were in from great britain .\n",
      "decoder inputs: friends UNK ours UNK in from great UNK .\n",
      "predictions: a , this you the the UNK choices .\n",
      "batch_ind/epoch: 6050/2 out of 6961/5\n",
      "Last batch loss:34.2093 KDL: 3.4238 KLD %: 10.0083815402\n",
      "encoder inputs: skip this one .\n",
      "decoder inputs: skip this UNK .\n",
      "predictions: love this one .\n",
      "batch_ind/epoch: 6100/2 out of 6961/5\n",
      "Last batch loss:32.61 KDL: 3.27213 KLD %: 10.0341231342\n",
      "encoder inputs: they are really amazing .\n",
      "decoder inputs: they are UNK UNK .\n",
      "predictions: these are very good .\n",
      "batch_ind/epoch: 6150/2 out of 6961/5\n",
      "Last batch loss:29.8761 KDL: 3.68163 KLD %: 12.3229980699\n",
      "encoder inputs: this is a dark , chocolaty UNK .\n",
      "decoder inputs: this is a UNK , chocolaty UNK UNK\n",
      "predictions: this is a great product UNK product .\n",
      "batch_ind/epoch: 6200/2 out of 6961/5\n",
      "Last batch loss:28.9505 KDL: 3.56644 KLD %: 12.3191011884\n",
      "encoder inputs: i contacted the seller but got no response .\n",
      "decoder inputs: i contacted the seller but got no UNK .\n",
      "predictions: i was the flavor and not a UNK .\n",
      "batch_ind/epoch: 6250/2 out of 6961/5\n",
      "Last batch loss:32.4974 KDL: 3.54321 KLD %: 10.9030757886\n",
      "encoder inputs: most importantly my house is bug free .\n",
      "decoder inputs: most importantly my house is bug free .\n",
      "predictions: the of , dog is the there .\n",
      "batch_ind/epoch: 6300/2 out of 6961/5\n",
      "Last batch loss:32.6597 KDL: 3.63739 KLD %: 11.1372419158\n",
      "encoder inputs: no nasty aftertaste .\n",
      "decoder inputs: UNK nasty aftertaste .\n",
      "predictions: no more it .\n",
      "batch_ind/epoch: 6350/2 out of 6961/5\n",
      "Last batch loss:35.0803 KDL: 3.53297 KLD %: 10.0710987925\n",
      "encoder inputs: catches everything from UNK to UNK .\n",
      "decoder inputs: catches UNK from UNK to UNK .\n",
      "predictions: the one and the on me .\n",
      "batch_ind/epoch: 6400/2 out of 6961/5\n",
      "Last batch loss:36.6471 KDL: 3.60868 KLD %: 9.84709262825\n",
      "encoder inputs: give it a try , it 's delicious !\n",
      "decoder inputs: give it a try , it 's delicious !\n",
      "predictions: the it a try , you 's not .\n",
      "batch_ind/epoch: 6450/2 out of 6961/5\n",
      "Last batch loss:32.4043 KDL: 3.49985 KLD %: 10.8005559183\n",
      "encoder inputs: really delicious seasoning and UNK that i highly recommend .\n",
      "decoder inputs: really delicious seasoning and UNK that i highly recommend .\n",
      "predictions: if , , , you , is love recommend .\n",
      "batch_ind/epoch: 6500/2 out of 6961/5\n",
      "Last batch loss:33.7423 KDL: 3.54368 KLD %: 10.5022020347\n",
      "encoder inputs: not just pleasantly surprised but actually amazed .\n",
      "decoder inputs: UNK UNK pleasantly UNK but actually amazed .\n",
      "predictions: and , , surprised the not . .\n",
      "batch_ind/epoch: 6550/2 out of 6961/5\n",
      "Last batch loss:33.2356 KDL: 3.60063 KLD %: 10.8336507887\n",
      "encoder inputs: plus they 're biodegradable !\n",
      "decoder inputs: plus they 're biodegradable UNK\n",
      "predictions: these it are good .\n",
      "batch_ind/epoch: 6600/2 out of 6961/5\n",
      "Last batch loss:34.2254 KDL: 3.47627 KLD %: 10.1569871914\n",
      "encoder inputs: the cats love it .\n",
      "decoder inputs: the cats love it UNK\n",
      "predictions: the taste love it .\n",
      "batch_ind/epoch: 6650/2 out of 6961/5\n",
      "Last batch loss:31.7495 KDL: 3.45603 KLD %: 10.8853116262\n",
      "encoder inputs: somehow it turned salty soapy very bitter taste .\n",
      "decoder inputs: somehow UNK turned salty soapy very bitter taste .\n",
      "predictions: but , the out , stars good taste .\n",
      "batch_ind/epoch: 6700/2 out of 6961/5\n",
      "Last batch loss:27.7878 KDL: 3.5597 KLD %: 12.8102895418\n",
      "encoder inputs: you choose how often to receive delivery .\n",
      "decoder inputs: UNK choose how often to receive delivery .\n",
      "predictions: so , and good are the food .\n",
      "batch_ind/epoch: 6750/2 out of 6961/5\n",
      "Last batch loss:31.889 KDL: 3.53715 KLD %: 11.0920558977\n",
      "encoder inputs: there is no nasty after taste or any jitters .\n",
      "decoder inputs: there is UNK UNK UNK UNK or any jitters UNK\n",
      "predictions: it is no of of and a a day .\n",
      "batch_ind/epoch: 6800/2 out of 6961/5\n",
      "Last batch loss:32.2572 KDL: 3.48084 KLD %: 10.7908941903\n",
      "encoder inputs: amazon , of course , popped up !\n",
      "decoder inputs: UNK , of course , popped UNK UNK\n",
      "predictions: so is i course , and is .\n",
      "batch_ind/epoch: 6850/2 out of 6961/5\n",
      "Last batch loss:29.235 KDL: 3.48247 KLD %: 11.9120050941\n",
      "encoder inputs: this brand is the best tasting to me .\n",
      "decoder inputs: this brand UNK the UNK UNK UNK me .\n",
      "predictions: this is is a best of of UNK .\n",
      "batch_ind/epoch: 6900/2 out of 6961/5\n",
      "Last batch loss:30.5455 KDL: 3.6005 KLD %: 11.787333162\n",
      "encoder inputs: i would recommend these for kids and adults !\n",
      "decoder inputs: UNK would recommend these UNK kids UNK adults !\n",
      "predictions: i am recommend this to to to them .\n",
      "batch_ind/epoch: 6950/2 out of 6961/5\n",
      "Last batch loss:34.0736 KDL: 3.50676 KLD %: 10.2917323934\n",
      "encoder inputs: it is simply superior rice .\n",
      "decoder inputs: it UNK UNK UNK UNK .\n",
      "predictions: it is a and taste .\n",
      "WARNING:tensorflow:Error encountered when serializing model_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'bytes' object has no attribute 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: %ssave/VAE-0\n",
      "execution took: 30631.72450455546 seconds\n",
      "batch_ind/epoch: 1/3 out of 6961/5\n",
      "Last batch loss:31.419 KDL: 3.61159 KLD %: 11.4948962606\n",
      "encoder inputs: not too chewy , and very flavorful .\n",
      "decoder inputs: not too chewy UNK and very UNK .\n",
      "predictions: a too sweet , a not tasty .\n",
      "batch_ind/epoch: 50/3 out of 6961/5\n",
      "Last batch loss:32.737 KDL: 3.39824 KLD %: 10.3804083111\n",
      "encoder inputs: tastes pretty crappy .\n",
      "decoder inputs: tastes pretty crappy .\n",
      "predictions: very like good !\n",
      "batch_ind/epoch: 100/3 out of 6961/5\n",
      "Last batch loss:28.6045 KDL: 3.5926 KLD %: 12.5595619124\n",
      "encoder inputs: i 'm still not sure what flavor it is .\n",
      "decoder inputs: i 'm UNK not sure what flavor it is .\n",
      "predictions: i have a to sure what it is is .\n",
      "batch_ind/epoch: 150/3 out of 6961/5\n",
      "Last batch loss:31.6949 KDL: 3.34623 KLD %: 10.5576400682\n",
      "encoder inputs: now i have 5 lbs .\n",
      "decoder inputs: now i UNK UNK lbs .\n",
      "predictions: so i 'm it this .\n",
      "batch_ind/epoch: 200/3 out of 6961/5\n",
      "Last batch loss:31.8055 KDL: 3.54195 KLD %: 11.1362619751\n",
      "encoder inputs: the 4 packages arrived not in an outer box !\n",
      "decoder inputs: UNK UNK packages arrived UNK in an outer box !\n",
      "predictions: the , is and in and a excellent snack .\n",
      "batch_ind/epoch: 250/3 out of 6961/5\n",
      "Last batch loss:36.38 KDL: 3.57388 KLD %: 9.82376407575\n",
      "encoder inputs: they loved it !\n",
      "decoder inputs: they loved it UNK\n",
      "predictions: they are it !\n",
      "batch_ind/epoch: 300/3 out of 6961/5\n",
      "Last batch loss:32.849 KDL: 3.53281 KLD %: 10.7547027006\n",
      "encoder inputs: the best thing ... no UNK .\n",
      "decoder inputs: the UNK UNK ... no UNK .\n",
      "predictions: the taste is is and bitterness .\n",
      "batch_ind/epoch: 350/3 out of 6961/5\n",
      "Last batch loss:32.2423 KDL: 3.52631 KLD %: 10.9369147174\n",
      "encoder inputs: me , into a UNK ! )\n",
      "decoder inputs: me , UNK a UNK UNK )\n",
      "predictions: UNK , i love great .\n",
      "batch_ind/epoch: 400/3 out of 6961/5\n",
      "Last batch loss:32.3621 KDL: 3.6548 KLD %: 11.2934676226\n",
      "encoder inputs: saying she loves these chews is a UNK understatement .\n",
      "decoder inputs: saying she loves UNK chews is a UNK understatement .\n",
      "predictions: so link is them and and the personal . .\n",
      "batch_ind/epoch: 450/3 out of 6961/5\n",
      "Last batch loss:35.0083 KDL: 3.42713 KLD %: 9.78946908185\n",
      "encoder inputs: i compete in UNK and crave carbs while dieting .\n",
      "decoder inputs: UNK UNK in UNK and crave UNK while UNK .\n",
      "predictions: i have the love and they is the brewing .\n",
      "batch_ind/epoch: 500/3 out of 6961/5\n",
      "Last batch loss:33.3371 KDL: 3.53163 KLD %: 10.593693494\n",
      "encoder inputs: that 's really fast .\n",
      "decoder inputs: UNK 's really UNK UNK\n",
      "predictions: it 's a good .\n",
      "batch_ind/epoch: 550/3 out of 6961/5\n",
      "Last batch loss:31.6024 KDL: 3.59678 KLD %: 11.3813561082\n",
      "encoder inputs: but i was pleasantly surprised .\n",
      "decoder inputs: but UNK was UNK UNK UNK\n",
      "predictions: but it is n't good .\n",
      "batch_ind/epoch: 600/3 out of 6961/5\n",
      "Last batch loss:33.9317 KDL: 3.48114 KLD %: 10.2592595611\n",
      "encoder inputs: pour the hot water out of the cup .\n",
      "decoder inputs: pour the UNK water out of the UNK .\n",
      "predictions: the it UNK is is of the UNK .\n",
      "batch_ind/epoch: 650/3 out of 6961/5\n",
      "Last batch loss:33.2276 KDL: 3.54915 KLD %: 10.6813344737\n",
      "encoder inputs: stir until melted .\n",
      "decoder inputs: stir until melted .\n",
      "predictions: great fry melted .\n",
      "batch_ind/epoch: 700/3 out of 6961/5\n",
      "Last batch loss:29.1383 KDL: 3.68893 KLD %: 12.6600656156\n",
      "encoder inputs: i would never buy this coffee again .\n",
      "decoder inputs: i UNK never buy UNK coffee again .\n",
      "predictions: i am n't buy this from again .\n",
      "batch_ind/epoch: 750/3 out of 6961/5\n",
      "Last batch loss:33.6099 KDL: 3.41544 KLD %: 10.1620054779\n",
      "encoder inputs: the above indicates a lifelong relationship .\n",
      "decoder inputs: UNK above UNK a lifelong relationship UNK\n",
      "predictions: the product food a great taste . .\n",
      "batch_ind/epoch: 800/3 out of 6961/5\n",
      "Last batch loss:34.6494 KDL: 3.55945 KLD %: 10.2727627256\n",
      "encoder inputs: the spicing really suits the cashews .\n",
      "decoder inputs: UNK UNK really suits the cashews .\n",
      "predictions: the product is is and flavor .\n",
      "batch_ind/epoch: 850/3 out of 6961/5\n",
      "Last batch loss:28.7915 KDL: 3.58905 KLD %: 12.4656311289\n",
      "encoder inputs: it makes an excellent cup .\n",
      "decoder inputs: UNK makes UNK UNK cup .\n",
      "predictions: it is a great tea .\n",
      "batch_ind/epoch: 900/3 out of 6961/5\n",
      "Last batch loss:33.7836 KDL: 3.4739 KLD %: 10.2827959393\n",
      "encoder inputs: these cookies are a favorite of mine .\n",
      "decoder inputs: UNK UNK UNK a UNK UNK mine .\n",
      "predictions: they are the and lot of UNK .\n",
      "batch_ind/epoch: 950/3 out of 6961/5\n",
      "Last batch loss:36.2966 KDL: 3.47978 KLD %: 9.58706916955\n",
      "encoder inputs: worth a try !\n",
      "decoder inputs: UNK a try !\n",
      "predictions: great and treat .\n",
      "batch_ind/epoch: 1000/3 out of 6961/5\n",
      "Last batch loss:31.7581 KDL: 3.72546 KLD %: 11.7307352283\n",
      "encoder inputs: not to be .\n",
      "decoder inputs: UNK UNK be .\n",
      "predictions: not the ! .\n",
      "batch_ind/epoch: 1050/3 out of 6961/5\n",
      "Last batch loss:33.1655 KDL: 3.69905 KLD %: 11.1533304544\n",
      "encoder inputs: i use it with plain yogurt and equal .\n",
      "decoder inputs: i use it UNK plain yogurt and equal .\n",
      "predictions: i have it for a and and UNK .\n",
      "batch_ind/epoch: 1100/3 out of 6961/5\n",
      "Last batch loss:34.6003 KDL: 3.49099 KLD %: 10.0894648317\n",
      "encoder inputs: i would suggest those flavors over this one .\n",
      "decoder inputs: UNK would suggest those flavors over UNK one UNK\n",
      "predictions: i am recommend this this in the years .\n",
      "batch_ind/epoch: 1150/3 out of 6961/5\n",
      "Last batch loss:30.592 KDL: 3.68558 KLD %: 12.0475147188\n",
      "encoder inputs: but i will be ordering again .\n",
      "decoder inputs: but UNK UNK UNK UNK again UNK\n",
      "predictions: no it is is the good .\n",
      "batch_ind/epoch: 1200/3 out of 6961/5\n",
      "Last batch loss:24.8059 KDL: 3.60466 KLD %: 14.5315036204\n",
      "encoder inputs: love it on popcorn now too !\n",
      "decoder inputs: love it UNK UNK now too !\n",
      "predictions: what the , the it . !\n",
      "batch_ind/epoch: 1250/3 out of 6961/5\n",
      "Last batch loss:28.1908 KDL: 3.73805 KLD %: 13.2597967743\n",
      "encoder inputs: it is neat and resealable .\n",
      "decoder inputs: it is neat and resealable UNK\n",
      "predictions: this is a and UNK .\n",
      "batch_ind/epoch: 1300/3 out of 6961/5\n",
      "Last batch loss:29.6909 KDL: 3.6757 KLD %: 12.3798948259\n",
      "encoder inputs: it 's sweet with a slight tartness .\n",
      "decoder inputs: it 's sweet with UNK slight tartness .\n",
      "predictions: it 's a , a taste flavor .\n",
      "batch_ind/epoch: 1350/3 out of 6961/5\n",
      "Last batch loss:35.6567 KDL: 3.49702 KLD %: 9.80746723986\n",
      "encoder inputs: it 's organic and seems to be nutritious !\n",
      "decoder inputs: UNK 's organic and seems UNK be nutritious !\n",
      "predictions: it is a and not to be used .\n",
      "batch_ind/epoch: 1400/3 out of 6961/5\n",
      "Last batch loss:32.7105 KDL: 3.63868 KLD %: 11.1238988158\n",
      "encoder inputs: i love the taste .\n",
      "decoder inputs: i love the taste .\n",
      "predictions: they love this flavor .\n",
      "batch_ind/epoch: 1450/3 out of 6961/5\n",
      "Last batch loss:33.4526 KDL: 3.56692 KLD %: 10.6626216305\n",
      "encoder inputs: we 'll see .\n",
      "decoder inputs: UNK UNK UNK UNK\n",
      "predictions: what this UNK .\n",
      "batch_ind/epoch: 1500/3 out of 6961/5\n",
      "Last batch loss:30.9903 KDL: 3.60759 KLD %: 11.6410347665\n",
      "encoder inputs: i would n't buy it again .\n",
      "decoder inputs: UNK would n't buy it again .\n",
      "predictions: i will recommend buy it again .\n",
      "batch_ind/epoch: 1550/3 out of 6961/5\n",
      "Last batch loss:31.1383 KDL: 3.45573 KLD %: 11.0980094492\n",
      "encoder inputs: it is good for people on diets thanks\n",
      "decoder inputs: it UNK good for UNK on diets thanks\n",
      "predictions: it 's a and a or your .\n",
      "batch_ind/epoch: 1600/3 out of 6961/5\n",
      "Last batch loss:30.9055 KDL: 3.7008 KLD %: 11.9745730363\n",
      "encoder inputs: very good quality chocolate .\n",
      "decoder inputs: UNK good quality UNK .\n",
      "predictions: not you quality . .\n",
      "batch_ind/epoch: 1650/3 out of 6961/5\n",
      "Last batch loss:33.4602 KDL: 3.70496 KLD %: 11.0727240779\n",
      "encoder inputs: the duck pill pockets are a god send .\n",
      "decoder inputs: UNK duck UNK UNK UNK a god UNK UNK\n",
      "predictions: the flavor , is is is great send .\n",
      "batch_ind/epoch: 1700/3 out of 6961/5\n",
      "Last batch loss:31.8145 KDL: 3.52691 KLD %: 11.0858462593\n",
      "encoder inputs: i really missed my moo .\n",
      "decoder inputs: i really missed my moo .\n",
      "predictions: they have like this dog .\n",
      "batch_ind/epoch: 1750/3 out of 6961/5\n",
      "Last batch loss:33.7568 KDL: 3.55049 KLD %: 10.517869412\n",
      "encoder inputs: ca n't say enough good things about this cocoa .\n",
      "decoder inputs: UNK n't say UNK good things about this UNK .\n",
      "predictions: they are wait enough the price to this product .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_ind/epoch: 1800/3 out of 6961/5\n",
      "Last batch loss:31.7644 KDL: 3.77048 KLD %: 11.8701529877\n",
      "encoder inputs: i ca n't wait to try more flavors !\n",
      "decoder inputs: i UNK n't wait UNK try more UNK UNK\n",
      "predictions: i have this wait to try it soon .\n",
      "batch_ind/epoch: 1850/3 out of 6961/5\n",
      "Last batch loss:32.0137 KDL: 3.60552 KLD %: 11.262423134\n",
      "encoder inputs: the chai latte is delicious !\n",
      "decoder inputs: UNK chai UNK is delicious !\n",
      "predictions: the is is is the .\n",
      "batch_ind/epoch: 1900/3 out of 6961/5\n",
      "Last batch loss:33.7889 KDL: 3.63439 KLD %: 10.7561480194\n",
      "encoder inputs: they arrived quickly and in good shape !\n",
      "decoder inputs: they arrived quickly and in good UNK !\n",
      "predictions: they are in and in perfect shape .\n",
      "batch_ind/epoch: 1950/3 out of 6961/5\n",
      "Last batch loss:32.4559 KDL: 3.48654 KLD %: 10.7424219042\n",
      "encoder inputs: i have to drink about two cups each time !\n",
      "decoder inputs: i have to drink about UNK cups each time UNK\n",
      "predictions: i have been say this the years this day .\n",
      "batch_ind/epoch: 2000/3 out of 6961/5\n",
      "Last batch loss:31.2003 KDL: 3.68614 KLD %: 11.8144459056\n",
      "encoder inputs: also , the food looks like real food .\n",
      "decoder inputs: also , the UNK looks like real food .\n",
      "predictions: a , the price is like this food .\n",
      "batch_ind/epoch: 2050/3 out of 6961/5\n",
      "Last batch loss:31.3768 KDL: 3.65628 KLD %: 11.6528088509\n",
      "encoder inputs: i highly recommend this product .\n",
      "decoder inputs: i highly recommend this product UNK\n",
      "predictions: i highly recommend this product .\n",
      "batch_ind/epoch: 2100/3 out of 6961/5\n",
      "Last batch loss:32.8471 KDL: 3.65411 KLD %: 11.1245910743\n",
      "encoder inputs: dry and tough .\n",
      "decoder inputs: dry and UNK .\n",
      "predictions: it is UNK .\n",
      "batch_ind/epoch: 2150/3 out of 6961/5\n",
      "Last batch loss:33.5264 KDL: 3.58048 KLD %: 10.6795809612\n",
      "encoder inputs: i never got sick once while on this stuff .\n",
      "decoder inputs: UNK never got sick once UNK on UNK stuff .\n",
      "predictions: i was been a to a a this foods .\n",
      "batch_ind/epoch: 2200/3 out of 6961/5\n",
      "Last batch loss:30.1896 KDL: 3.68879 KLD %: 12.2187702943\n",
      "encoder inputs: this candy is addicting !\n",
      "decoder inputs: this candy is addicting !\n",
      "predictions: this product is great !\n",
      "batch_ind/epoch: 2250/3 out of 6961/5\n",
      "Last batch loss:32.9429 KDL: 3.66605 KLD %: 11.1284991371\n",
      "encoder inputs: it makes a great , easy lunch .\n",
      "decoder inputs: UNK makes a great UNK UNK lunch .\n",
      "predictions: it is a great cup of coffee .\n",
      "batch_ind/epoch: 2300/3 out of 6961/5\n",
      "Last batch loss:30.728 KDL: 3.55472 KLD %: 11.5683388464\n",
      "encoder inputs: the spices are perfect .\n",
      "decoder inputs: the spices are UNK .\n",
      "predictions: the taste are great .\n",
      "batch_ind/epoch: 2350/3 out of 6961/5\n",
      "Last batch loss:32.0355 KDL: 3.65936 KLD %: 11.4228529935\n",
      "encoder inputs: no more begging for food every 5 minutes .\n",
      "decoder inputs: no more begging for UNK UNK 5 UNK UNK\n",
      "predictions: no more UNK than me or and minutes .\n",
      "batch_ind/epoch: 2400/3 out of 6961/5\n",
      "Last batch loss:30.7732 KDL: 3.69178 KLD %: 11.9967326854\n",
      "encoder inputs: you 'll have to give it a try .\n",
      "decoder inputs: you 'll have to give it a UNK .\n",
      "predictions: i can be to try it a try .\n",
      "batch_ind/epoch: 2450/3 out of 6961/5\n",
      "Last batch loss:32.986 KDL: 3.68667 KLD %: 11.1764941936\n",
      "encoder inputs: my stomach loves you .\n",
      "decoder inputs: my stomach UNK UNK UNK\n",
      "predictions: my dogs loves it .\n",
      "batch_ind/epoch: 2500/3 out of 6961/5\n",
      "Last batch loss:34.2063 KDL: 3.58655 KLD %: 10.4850313171\n",
      "encoder inputs: it 's too much .\n",
      "decoder inputs: UNK UNK too UNK .\n",
      "predictions: it 's very sweet .\n",
      "batch_ind/epoch: 2550/3 out of 6961/5\n",
      "Last batch loss:30.4855 KDL: 3.71716 KLD %: 12.1932211145\n",
      "encoder inputs: and it worked out even better than the muffins .\n",
      "decoder inputs: and it worked out UNK better than the UNK .\n",
      "predictions: and it is great for the than the store .\n",
      "batch_ind/epoch: 2600/3 out of 6961/5\n",
      "Last batch loss:33.2279 KDL: 3.44136 KLD %: 10.3568343415\n",
      "encoder inputs: great real coconut young coconut taste .\n",
      "decoder inputs: great real coconut young coconut UNK UNK\n",
      "predictions: great for and and the oil .\n",
      "batch_ind/epoch: 2650/3 out of 6961/5\n",
      "Last batch loss:32.6435 KDL: 3.65213 KLD %: 11.1879467609\n",
      "encoder inputs: i am very happy with this food ! ! !\n",
      "decoder inputs: i UNK very UNK with this food ! ! !\n",
      "predictions: i will not happy with this product .\n",
      "batch_ind/epoch: 2700/3 out of 6961/5\n",
      "Last batch loss:32.2141 KDL: 3.50601 KLD %: 10.8834637105\n",
      "encoder inputs: what do i do with it now ? ?\n",
      "decoder inputs: UNK do UNK UNK UNK UNK UNK ? UNK\n",
      "predictions: we have n't have it to it .\n",
      "batch_ind/epoch: 2750/3 out of 6961/5\n",
      "Last batch loss:30.7959 KDL: 3.80122 KLD %: 12.343273177\n",
      "encoder inputs: plus it 's rather noisy .\n",
      "decoder inputs: UNK it 's rather noisy .\n",
      "predictions: not , 's worth expensive .\n",
      "batch_ind/epoch: 2800/3 out of 6961/5\n",
      "Last batch loss:29.4474 KDL: 3.71699 KLD %: 12.6224917334\n",
      "encoder inputs: it overwhelms the flavor .\n",
      "decoder inputs: it overwhelms the flavor .\n",
      "predictions: it 's so best .\n",
      "batch_ind/epoch: 2850/3 out of 6961/5\n",
      "Last batch loss:30.5765 KDL: 3.62796 KLD %: 11.86519826\n",
      "encoder inputs: i strongly recommend this popcorn .\n",
      "decoder inputs: i UNK recommend this popcorn .\n",
      "predictions: i love recommend this product .\n",
      "batch_ind/epoch: 2900/3 out of 6961/5\n",
      "Last batch loss:30.4485 KDL: 3.76605 KLD %: 12.3685899548\n",
      "encoder inputs: it smelled absolutely sinful while it brewed .\n",
      "decoder inputs: UNK smelled UNK sinful UNK UNK brewed .\n",
      "predictions: it is like is and and UNK .\n",
      "batch_ind/epoch: 2950/3 out of 6961/5\n",
      "Last batch loss:32.2175 KDL: 3.61242 KLD %: 11.2125969111\n",
      "encoder inputs: read every label peace\n",
      "decoder inputs: read every label peace\n",
      "predictions: these the bite ! .\n",
      "batch_ind/epoch: 3000/3 out of 6961/5\n",
      "Last batch loss:32.9589 KDL: 3.66936 KLD %: 11.1331120926\n",
      "encoder inputs: the taste is very beef broth like .\n",
      "decoder inputs: the UNK UNK UNK beef UNK like UNK\n",
      "predictions: the price is is is is flavor .\n",
      "batch_ind/epoch: 3050/3 out of 6961/5\n",
      "Last batch loss:32.1669 KDL: 3.62173 KLD %: 11.2592127365\n",
      "encoder inputs: i love it any time of the day .\n",
      "decoder inputs: i love it UNK UNK of UNK day .\n",
      "predictions: i have the and and and the flavors .\n",
      "batch_ind/epoch: 3100/3 out of 6961/5\n",
      "Last batch loss:32.7725 KDL: 3.51583 KLD %: 10.7279817467\n",
      "encoder inputs: best thing i 've ordered on line .\n",
      "decoder inputs: UNK thing i 've ordered UNK UNK .\n",
      "predictions: so is , have been them . .\n",
      "batch_ind/epoch: 3150/3 out of 6961/5\n",
      "Last batch loss:29.4435 KDL: 3.68699 KLD %: 12.5222664928\n",
      "encoder inputs: you wo n't be disappointed .\n",
      "decoder inputs: you UNK UNK UNK UNK .\n",
      "predictions: you wo n't be it .\n",
      "batch_ind/epoch: 3200/3 out of 6961/5\n",
      "Last batch loss:32.7546 KDL: 3.62058 KLD %: 11.0536537866\n",
      "encoder inputs: these wasabi flavored roasted UNK are okay .\n",
      "decoder inputs: these wasabi flavored roasted UNK are UNK .\n",
      "predictions: these are are coffee the the delicious .\n",
      "batch_ind/epoch: 3250/3 out of 6961/5\n",
      "Last batch loss:30.9608 KDL: 3.47127 KLD %: 11.2118136295\n",
      "encoder inputs: enjoy ! gary peterson\n",
      "decoder inputs: enjoy UNK gary peterson\n",
      "predictions: these this it peterson\n",
      "batch_ind/epoch: 3300/3 out of 6961/5\n",
      "Last batch loss:31.3288 KDL: 3.71564 KLD %: 11.8601539613\n",
      "encoder inputs: zico is still amazing .\n",
      "decoder inputs: UNK is still amazing .\n",
      "predictions: the is a good .\n",
      "batch_ind/epoch: 3350/3 out of 6961/5\n",
      "Last batch loss:31.1025 KDL: 3.57713 KLD %: 11.5010769202\n",
      "encoder inputs: no bitterness at all .\n",
      "decoder inputs: no UNK UNK all .\n",
      "predictions: this more or whatsoever .\n",
      "batch_ind/epoch: 3400/3 out of 6961/5\n",
      "Last batch loss:30.4984 KDL: 3.56962 KLD %: 11.7042946791\n",
      "encoder inputs: only 100 calories per bag .\n",
      "decoder inputs: only 100 UNK UNK bag .\n",
      "predictions: UNK the calories are UNK .\n",
      "batch_ind/epoch: 3450/3 out of 6961/5\n",
      "Last batch loss:29.9351 KDL: 3.60503 KLD %: 12.0428048711\n",
      "encoder inputs: it works 85 % of the time .\n",
      "decoder inputs: it works 85 UNK of the time .\n",
      "predictions: it 's well and a the best .\n",
      "batch_ind/epoch: 3500/3 out of 6961/5\n",
      "Last batch loss:33.3184 KDL: 3.68004 KLD %: 11.0450603568\n",
      "encoder inputs: the flavor is excellent UNK great .\n",
      "decoder inputs: the flavor is excellent UNK UNK UNK\n",
      "predictions: the taste is very too .\n",
      "batch_ind/epoch: 3550/3 out of 6961/5\n",
      "Last batch loss:32.7219 KDL: 3.55768 KLD %: 10.8724841711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder inputs: love this product !\n",
      "decoder inputs: love this product UNK\n",
      "predictions: love this product .\n",
      "batch_ind/epoch: 3600/3 out of 6961/5\n",
      "Last batch loss:29.7036 KDL: 3.57646 KLD %: 12.0404760095\n",
      "encoder inputs: her baking mixes are UNK .\n",
      "decoder inputs: her baking mixes UNK UNK .\n",
      "predictions: so coat is in it .\n",
      "batch_ind/epoch: 3650/3 out of 6961/5\n",
      "Last batch loss:33.2664 KDL: 3.82205 KLD %: 11.4892335417\n",
      "encoder inputs: price with subscribe and save is very good .\n",
      "decoder inputs: price with subscribe and save UNK very UNK UNK\n",
      "predictions: so is the and save is the reasonable .\n",
      "batch_ind/epoch: 3700/3 out of 6961/5\n",
      "Last batch loss:31.4828 KDL: 3.67655 KLD %: 11.6779702404\n",
      "encoder inputs: one end is covered with a sticker .\n",
      "decoder inputs: one end UNK covered with a sticker .\n",
      "predictions: so of 's a and the UNK .\n",
      "batch_ind/epoch: 3750/3 out of 6961/5\n",
      "Last batch loss:30.313 KDL: 3.82297 KLD %: 12.6116524522\n",
      "encoder inputs: they are all meat - absolutely nothing else .\n",
      "decoder inputs: they UNK all meat UNK absolutely nothing UNK .\n",
      "predictions: i are a the in the love . .\n",
      "batch_ind/epoch: 3800/3 out of 6961/5\n",
      "Last batch loss:31.4743 KDL: 3.5161 KLD %: 11.1713334992\n",
      "encoder inputs: these cookies taste like the real thing !\n",
      "decoder inputs: these UNK UNK UNK UNK real thing !\n",
      "predictions: so are are are are are deal .\n",
      "batch_ind/epoch: 3850/3 out of 6961/5\n",
      "Last batch loss:32.3459 KDL: 3.63605 KLD %: 11.2411587329\n",
      "encoder inputs: ) , so give them a try .\n",
      "decoder inputs: ) , UNK give UNK UNK try .\n",
      "predictions: but , i , it a try .\n",
      "batch_ind/epoch: 3900/3 out of 6961/5\n",
      "Last batch loss:32.3427 KDL: 3.67962 KLD %: 11.3769745373\n",
      "encoder inputs: we definitely will be buying more .\n",
      "decoder inputs: we UNK will be buying UNK UNK\n",
      "predictions: and have the buy buying more .\n",
      "batch_ind/epoch: 3950/3 out of 6961/5\n",
      "Last batch loss:37.1439 KDL: 3.8865 KLD %: 10.4633448755\n",
      "encoder inputs: too expensive for 15 minutes of entertainment .\n",
      "decoder inputs: UNK expensive UNK 15 minutes UNK entertainment UNK\n",
      "predictions: do , , to and to it .\n",
      "batch_ind/epoch: 4000/3 out of 6961/5\n",
      "Last batch loss:31.8055 KDL: 3.61386 KLD %: 11.3623778294\n",
      "encoder inputs: would definitely order this again and good price too !\n",
      "decoder inputs: would definitely order this again UNK good price too !\n",
      "predictions: my not recommend again again and the for too .\n",
      "batch_ind/epoch: 4050/3 out of 6961/5\n",
      "Last batch loss:32.4619 KDL: 3.65263 KLD %: 11.2520558938\n",
      "encoder inputs: this however is delicious !\n",
      "decoder inputs: UNK however is delicious !\n",
      "predictions: this stuff is great .\n",
      "batch_ind/epoch: 4100/3 out of 6961/5\n",
      "Last batch loss:33.2437 KDL: 3.59796 KLD %: 10.8229853132\n",
      "encoder inputs: loved the spray !\n",
      "decoder inputs: loved the UNK !\n",
      "predictions: UNK the product .\n",
      "batch_ind/epoch: 4150/3 out of 6961/5\n",
      "Last batch loss:27.4614 KDL: 3.70184 KLD %: 13.4801556846\n",
      "encoder inputs: not what i hoped for .\n",
      "decoder inputs: not what i UNK UNK .\n",
      "predictions: not a i was looking .\n",
      "batch_ind/epoch: 4200/3 out of 6961/5\n",
      "Last batch loss:30.4852 KDL: 3.62607 KLD %: 11.8945374297\n",
      "encoder inputs: my kids love it too .\n",
      "decoder inputs: my kids love it too UNK\n",
      "predictions: my dog love these too .\n",
      "batch_ind/epoch: 4250/3 out of 6961/5\n",
      "Last batch loss:29.2258 KDL: 3.74068 KLD %: 12.7992525152\n",
      "encoder inputs: it 's perfect for movie night !\n",
      "decoder inputs: UNK 's perfect for movie UNK !\n",
      "predictions: it is a for my and .\n",
      "batch_ind/epoch: 4300/3 out of 6961/5\n",
      "Last batch loss:28.7885 KDL: 3.8666 KLD %: 13.4310622214\n",
      "encoder inputs: this large package lasts us a long time .\n",
      "decoder inputs: this UNK package UNK us a UNK time .\n",
      "predictions: the product is is a a great gift .\n",
      "batch_ind/epoch: 4350/3 out of 6961/5\n",
      "Last batch loss:29.6285 KDL: 3.61467 KLD %: 12.1999977919\n",
      "encoder inputs: big plus for me .\n",
      "decoder inputs: big plus UNK UNK .\n",
      "predictions: and , for UNK .\n",
      "batch_ind/epoch: 4400/3 out of 6961/5\n",
      "Last batch loss:31.6553 KDL: 3.62288 KLD %: 11.4447887913\n",
      "encoder inputs: perfect for snacking .\n",
      "decoder inputs: perfect UNK snacking .\n",
      "predictions: it for snack .\n",
      "batch_ind/epoch: 4450/3 out of 6961/5\n",
      "Last batch loss:34.5054 KDL: 3.62992 KLD %: 10.519878759\n",
      "encoder inputs: hard to tell that they are baked .\n",
      "decoder inputs: hard UNK UNK that they UNK baked .\n",
      "predictions: not to find to i are great .\n",
      "batch_ind/epoch: 4500/3 out of 6961/5\n",
      "Last batch loss:31.903 KDL: 3.69267 KLD %: 11.5746773017\n",
      "encoder inputs: this yummy little baked confection was truly delicious .\n",
      "decoder inputs: UNK UNK UNK baked confection UNK truly delicious .\n",
      "predictions: this is is great , for my coffee .\n",
      "batch_ind/epoch: 4550/3 out of 6961/5\n",
      "Last batch loss:30.837 KDL: 3.77428 KLD %: 12.2394537812\n",
      "encoder inputs: i was very happy with this product .\n",
      "decoder inputs: i UNK UNK UNK with UNK product .\n",
      "predictions: i love the to of this product .\n",
      "batch_ind/epoch: 4600/3 out of 6961/5\n",
      "Last batch loss:30.4604 KDL: 3.71212 KLD %: 12.1866892636\n",
      "encoder inputs: use this over rice for a meal !\n",
      "decoder inputs: use UNK UNK rice for a meal !\n",
      "predictions: now a for and to a snack .\n",
      "batch_ind/epoch: 4650/3 out of 6961/5\n",
      "Last batch loss:25.1035 KDL: 3.64316 KLD %: 14.5125875284\n",
      "encoder inputs: no heavy flavor .\n",
      "decoder inputs: no UNK flavor .\n",
      "predictions: no complaints here .\n",
      "batch_ind/epoch: 4700/3 out of 6961/5\n",
      "Last batch loss:29.5917 KDL: 3.67906 KLD %: 12.4327503332\n",
      "encoder inputs: everything about this product is excellent .\n",
      "decoder inputs: UNK about this product UNK excellent .\n",
      "predictions: it is the product is great .\n",
      "batch_ind/epoch: 4750/3 out of 6961/5\n",
      "Last batch loss:33.1949 KDL: 3.59393 KLD %: 10.8267770997\n",
      "encoder inputs: i love them !\n",
      "decoder inputs: i love UNK !\n",
      "predictions: i love this tea !\n",
      "batch_ind/epoch: 4800/3 out of 6961/5\n",
      "Last batch loss:31.2181 KDL: 3.79032 KLD %: 12.1414303172\n",
      "encoder inputs: this year everyone is going to be happy !\n",
      "decoder inputs: UNK year everyone is going to UNK happy !\n",
      "predictions: this product old is a to be me .\n",
      "batch_ind/epoch: 4850/3 out of 6961/5\n",
      "Last batch loss:29.4456 KDL: 3.68214 KLD %: 12.5048864909\n",
      "encoder inputs: these are the best tasting pretzels !\n",
      "decoder inputs: these UNK the best UNK pretzels UNK\n",
      "predictions: these are are best pretzels ever .\n",
      "batch_ind/epoch: 4900/3 out of 6961/5\n",
      "Last batch loss:33.9152 KDL: 3.72018 KLD %: 10.969089345\n",
      "encoder inputs: i do n't like overly sweet drinks .\n",
      "decoder inputs: i do n't like overly sweet UNK .\n",
      "predictions: i love n't think the sweet coffee .\n",
      "batch_ind/epoch: 4950/3 out of 6961/5\n",
      "Last batch loss:28.7801 KDL: 3.60747 KLD %: 12.534616146\n",
      "encoder inputs: did you know it was invented by a doctor !\n",
      "decoder inputs: did UNK know UNK was invented UNK a UNK !\n",
      "predictions: and n't mention what i a , , try .\n",
      "batch_ind/epoch: 5000/3 out of 6961/5\n",
      "Last batch loss:29.773 KDL: 3.65904 KLD %: 12.2897870734\n",
      "encoder inputs: the tea is delicious .\n",
      "decoder inputs: UNK tea is delicious .\n",
      "predictions: the is is great .\n",
      "batch_ind/epoch: 5050/3 out of 6961/5\n",
      "Last batch loss:30.207 KDL: 3.60507 KLD %: 11.9345385503\n",
      "encoder inputs: good price even with the shipping costs .\n",
      "decoder inputs: good UNK even UNK the UNK costs .\n",
      "predictions: so price , a a UNK UNK .\n",
      "batch_ind/epoch: 5100/3 out of 6961/5\n",
      "Last batch loss:29.3896 KDL: 3.84695 KLD %: 13.0894901196\n",
      "encoder inputs: thank you cesar !\n",
      "decoder inputs: thank you cesar !\n",
      "predictions: thank you amazon !\n",
      "batch_ind/epoch: 5150/3 out of 6961/5\n",
      "Last batch loss:29.5183 KDL: 3.75008 KLD %: 12.7042839628\n",
      "encoder inputs: recipe available on UNK `` chocolate biscuit cake . ''\n",
      "decoder inputs: UNK available on UNK `` chocolate UNK UNK . UNK\n",
      "predictions: the is in amazon and UNK '' '' . ''\n",
      "batch_ind/epoch: 5200/3 out of 6961/5\n",
      "Last batch loss:34.2478 KDL: 3.65377 KLD %: 10.6686368849\n",
      "encoder inputs: this xylitol in packets is very chalky in taste .\n",
      "decoder inputs: UNK xylitol UNK packets is very chalky in UNK UNK\n",
      "predictions: the product , the and the good and flavor .\n",
      "batch_ind/epoch: 5250/3 out of 6961/5\n",
      "Last batch loss:32.4371 KDL: 3.61754 KLD %: 11.1524647041\n",
      "encoder inputs: even the hot coco has the artificial sweetener .\n",
      "decoder inputs: even UNK hot UNK has UNK artificial UNK .\n",
      "predictions: a my to chocolate is a great sweeteners .\n",
      "batch_ind/epoch: 5300/3 out of 6961/5\n",
      "Last batch loss:28.9524 KDL: 3.7825 KLD %: 13.0645349789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder inputs: ca n't beat that !\n",
      "decoder inputs: ca UNK beat that UNK\n",
      "predictions: these n't beat that !\n",
      "batch_ind/epoch: 5350/3 out of 6961/5\n",
      "Last batch loss:32.9507 KDL: 3.6308 KLD %: 11.018874548\n",
      "encoder inputs: she devours every bite .\n",
      "decoder inputs: she UNK every UNK .\n",
      "predictions: it always wanted bite .\n",
      "batch_ind/epoch: 5400/3 out of 6961/5\n",
      "Last batch loss:32.8427 KDL: 3.71389 KLD %: 11.3081154168\n",
      "encoder inputs: this really tastes like ginger and honey !\n",
      "decoder inputs: this UNK tastes like UNK and UNK !\n",
      "predictions: this product is like a real UNK .\n",
      "batch_ind/epoch: 5450/3 out of 6961/5\n",
      "Last batch loss:35.5932 KDL: 3.59217 KLD %: 10.0922713361\n",
      "encoder inputs: i could n't be happier !\n",
      "decoder inputs: i could UNK UNK UNK UNK\n",
      "predictions: i love n't be it .\n",
      "batch_ind/epoch: 5500/3 out of 6961/5\n",
      "Last batch loss:29.606 KDL: 3.88468 KLD %: 13.1212703501\n",
      "encoder inputs: my havanese just loves these treats with the apples !\n",
      "decoder inputs: UNK UNK just loves UNK UNK with the apples !\n",
      "predictions: my cat is loves these and of this UNK .\n",
      "batch_ind/epoch: 5550/3 out of 6961/5\n",
      "Last batch loss:31.4006 KDL: 3.87716 KLD %: 12.3474119715\n",
      "encoder inputs: all six cans were rancid .\n",
      "decoder inputs: UNK UNK cans were rancid .\n",
      "predictions: UNK , , were dented .\n",
      "batch_ind/epoch: 5600/3 out of 6961/5\n",
      "Last batch loss:36.573 KDL: 3.64108 KLD %: 9.95565696023\n",
      "encoder inputs: this particular one is the mild sweet style .\n",
      "decoder inputs: this particular one is the mild UNK UNK .\n",
      "predictions: this tea brand of the best and UNK .\n",
      "batch_ind/epoch: 5650/3 out of 6961/5\n",
      "Last batch loss:32.2087 KDL: 3.74436 KLD %: 11.6253191134\n",
      "encoder inputs: i wanted to love these .\n",
      "decoder inputs: UNK wanted UNK UNK these UNK\n",
      "predictions: i love to like it .\n",
      "batch_ind/epoch: 5700/3 out of 6961/5\n",
      "Last batch loss:30.5909 KDL: 3.80339 KLD %: 12.4330880871\n",
      "encoder inputs: however , the UNK process is UNK .\n",
      "decoder inputs: however , the UNK process is UNK .\n",
      "predictions: just , the price is is great .\n",
      "batch_ind/epoch: 5750/3 out of 6961/5\n",
      "Last batch loss:34.7742 KDL: 3.59949 KLD %: 10.3510405724\n",
      "encoder inputs: on to a chinese type dish next .\n",
      "decoder inputs: on to UNK UNK type dish next .\n",
      "predictions: so the make , the of oz .\n",
      "batch_ind/epoch: 5800/3 out of 6961/5\n",
      "Last batch loss:31.7293 KDL: 3.94704 KLD %: 12.4397395609\n",
      "encoder inputs: would n't have it any other way !\n",
      "decoder inputs: would n't have it UNK UNK way UNK\n",
      "predictions: my definitely buy to to the it .\n",
      "batch_ind/epoch: 5850/3 out of 6961/5\n",
      "Last batch loss:32.0077 KDL: 3.67125 KLD %: 11.4698968384\n",
      "encoder inputs: and far more nutritious than a standard fruit snack .\n",
      "decoder inputs: and far UNK nutritious than a UNK fruit snack .\n",
      "predictions: and it , it , a little of flavor .\n",
      "batch_ind/epoch: 5900/3 out of 6961/5\n",
      "Last batch loss:33.6114 KDL: 3.8016 KLD %: 11.3104360181\n",
      "encoder inputs: i had my package within 4 days .\n",
      "decoder inputs: UNK had my package within 4 days .\n",
      "predictions: i have a UNK with 2 years .\n",
      "batch_ind/epoch: 5950/3 out of 6961/5\n",
      "Last batch loss:27.0851 KDL: 3.70054 KLD %: 13.6626231214\n",
      "encoder inputs: i love the convenience of the auto ship program .\n",
      "decoder inputs: i love the convenience of the UNK ship program UNK\n",
      "predictions: i have the flavor of the tea of program .\n",
      "batch_ind/epoch: 6000/3 out of 6961/5\n",
      "Last batch loss:36.2339 KDL: 3.4216 KLD %: 9.44309763737\n",
      "encoder inputs: friends of ours were in from great britain .\n",
      "decoder inputs: friends UNK ours UNK UNK from great britain UNK\n",
      "predictions: well , this is the a UNK product .\n",
      "batch_ind/epoch: 6050/3 out of 6961/5\n",
      "Last batch loss:33.4953 KDL: 3.67456 KLD %: 10.970391796\n",
      "encoder inputs: skip this one .\n",
      "decoder inputs: skip this UNK .\n",
      "predictions: great the one .\n",
      "batch_ind/epoch: 6100/3 out of 6961/5\n",
      "Last batch loss:31.121 KDL: 3.46946 KLD %: 11.1483091204\n",
      "encoder inputs: they are really amazing .\n",
      "decoder inputs: they are really amazing .\n",
      "predictions: these are so good .\n",
      "batch_ind/epoch: 6150/3 out of 6961/5\n",
      "Last batch loss:28.9227 KDL: 3.85729 KLD %: 13.336554101\n",
      "encoder inputs: this is a dark , chocolaty UNK .\n",
      "decoder inputs: UNK is UNK dark , UNK UNK UNK\n",
      "predictions: this is a best roast rich coffee .\n",
      "batch_ind/epoch: 6200/3 out of 6961/5\n",
      "Last batch loss:28.4221 KDL: 3.84838 KLD %: 13.5401243002\n",
      "encoder inputs: i contacted the seller but got no response .\n",
      "decoder inputs: i UNK the seller but got no response .\n",
      "predictions: i have this flavor and not a UNK .\n",
      "batch_ind/epoch: 6250/3 out of 6961/5\n",
      "Last batch loss:32.1409 KDL: 3.75038 KLD %: 11.6685529921\n",
      "encoder inputs: most importantly my house is bug free .\n",
      "decoder inputs: UNK importantly my house UNK UNK free UNK\n",
      "predictions: i have , first k this it .\n",
      "batch_ind/epoch: 6300/3 out of 6961/5\n",
      "Last batch loss:31.4623 KDL: 3.73872 KLD %: 11.8831961245\n",
      "encoder inputs: no nasty aftertaste .\n",
      "decoder inputs: no nasty UNK .\n",
      "predictions: what more or .\n",
      "batch_ind/epoch: 6350/3 out of 6961/5\n",
      "Last batch loss:34.297 KDL: 3.68423 KLD %: 10.742134581\n",
      "encoder inputs: catches everything from UNK to UNK .\n",
      "decoder inputs: catches UNK UNK UNK UNK UNK UNK\n",
      "predictions: so is , is is UNK .\n",
      "batch_ind/epoch: 6400/3 out of 6961/5\n",
      "Last batch loss:36.3699 KDL: 3.77131 KLD %: 10.3693145317\n",
      "encoder inputs: give it a try , it 's delicious !\n",
      "decoder inputs: give it UNK try , UNK UNK UNK !\n",
      "predictions: even it a try , you 'll try .\n",
      "batch_ind/epoch: 6450/3 out of 6961/5\n",
      "Last batch loss:31.4847 KDL: 3.70749 KLD %: 11.7755520162\n",
      "encoder inputs: really delicious seasoning and UNK that i highly recommend .\n",
      "decoder inputs: UNK delicious seasoning and UNK that i highly recommend UNK\n",
      "predictions: the , , , the is is love recommend .\n",
      "batch_ind/epoch: 6500/3 out of 6961/5\n",
      "Last batch loss:32.3631 KDL: 3.64922 KLD %: 11.2758753539\n",
      "encoder inputs: not just pleasantly surprised but actually amazed .\n",
      "decoder inputs: UNK just pleasantly UNK but actually amazed UNK\n",
      "predictions: a n't like surprised the not good .\n",
      "batch_ind/epoch: 6550/3 out of 6961/5\n",
      "Last batch loss:32.7977 KDL: 3.80857 KLD %: 11.6122971526\n",
      "encoder inputs: plus they 're biodegradable !\n",
      "decoder inputs: plus they 're UNK !\n",
      "predictions: not it 're addictive .\n",
      "batch_ind/epoch: 6600/3 out of 6961/5\n",
      "Last batch loss:32.7326 KDL: 3.6715 KLD %: 11.2166322521\n",
      "encoder inputs: the cats love it .\n",
      "decoder inputs: the cats love UNK .\n",
      "predictions: great taste love it .\n",
      "batch_ind/epoch: 6650/3 out of 6961/5\n",
      "Last batch loss:31.1907 KDL: 3.73461 KLD %: 11.9734444176\n",
      "encoder inputs: somehow it turned salty soapy very bitter taste .\n",
      "decoder inputs: somehow it turned salty soapy very bitter UNK .\n",
      "predictions: great is was out for day much taste .\n",
      "batch_ind/epoch: 6700/3 out of 6961/5\n",
      "Last batch loss:27.185 KDL: 3.81403 KLD %: 14.0298963802\n",
      "encoder inputs: you choose how often to receive delivery .\n",
      "decoder inputs: you choose how often to receive delivery .\n",
      "predictions: i can to this this the them .\n",
      "batch_ind/epoch: 6750/3 out of 6961/5\n",
      "Last batch loss:30.6126 KDL: 3.80951 KLD %: 12.4442556054\n",
      "encoder inputs: there is no nasty after taste or any jitters .\n",
      "decoder inputs: there is no nasty after taste or any UNK .\n",
      "predictions: it is no reason to taste , to aftertaste .\n",
      "batch_ind/epoch: 6800/3 out of 6961/5\n",
      "Last batch loss:31.2993 KDL: 3.71236 KLD %: 11.8608370039\n",
      "encoder inputs: amazon , of course , popped up !\n",
      "decoder inputs: UNK , UNK UNK UNK UNK up UNK\n",
      "predictions: they are i , is the UNK .\n",
      "batch_ind/epoch: 6850/3 out of 6961/5\n",
      "Last batch loss:28.1639 KDL: 3.68643 KLD %: 13.0891969437\n",
      "encoder inputs: this brand is the best tasting to me .\n",
      "decoder inputs: this brand is the best UNK UNK UNK UNK\n",
      "predictions: this is is a best i i ever .\n",
      "batch_ind/epoch: 6900/3 out of 6961/5\n",
      "Last batch loss:29.4198 KDL: 3.65729 KLD %: 12.4314050916\n",
      "encoder inputs: i would recommend these for kids and adults !\n",
      "decoder inputs: i UNK UNK UNK UNK kids and UNK UNK\n",
      "predictions: i am not to to to love adults .\n",
      "batch_ind/epoch: 6950/3 out of 6961/5\n",
      "Last batch loss:33.2688 KDL: 3.69209 KLD %: 11.0977593182\n",
      "encoder inputs: it is simply superior rice .\n",
      "decoder inputs: UNK is UNK superior rice .\n",
      "predictions: it 's a and too .\n",
      "WARNING:tensorflow:Error encountered when serializing model_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'bytes' object has no attribute 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: %ssave/VAE-0\n",
      "execution took: 42502.0008392285 seconds\n",
      "batch_ind/epoch: 1/4 out of 6961/5\n",
      "Last batch loss:30.2372 KDL: 3.84645 KLD %: 12.7209090408\n",
      "encoder inputs: not too chewy , and very flavorful .\n",
      "decoder inputs: not too UNK , and very flavorful UNK\n",
      "predictions: not too sweet , but not tasty .\n",
      "batch_ind/epoch: 50/4 out of 6961/5\n",
      "Last batch loss:32.6824 KDL: 3.66756 KLD %: 11.2217964791\n",
      "encoder inputs: tastes pretty crappy .\n",
      "decoder inputs: tastes UNK UNK .\n",
      "predictions: these like good .\n",
      "batch_ind/epoch: 100/4 out of 6961/5\n",
      "Last batch loss:27.8107 KDL: 3.79554 KLD %: 13.6477987389\n",
      "encoder inputs: i 'm still not sure what flavor it is .\n",
      "decoder inputs: i 'm still not sure what flavor it UNK .\n",
      "predictions: i 'm so to to what it is is .\n",
      "batch_ind/epoch: 150/4 out of 6961/5\n",
      "Last batch loss:31.0126 KDL: 3.62106 KLD %: 11.6760986305\n",
      "encoder inputs: now i have 5 lbs .\n",
      "decoder inputs: UNK i have 5 lbs .\n",
      "predictions: ( , love a to UNK\n",
      "batch_ind/epoch: 200/4 out of 6961/5\n",
      "Last batch loss:30.8974 KDL: 3.70471 KLD %: 11.9903643692\n",
      "encoder inputs: the 4 packages arrived not in an outer box !\n",
      "decoder inputs: the 4 packages UNK not in an outer UNK !\n",
      "predictions: the flavor pack is is the the outer snack .\n",
      "batch_ind/epoch: 250/4 out of 6961/5\n",
      "Last batch loss:33.935 KDL: 3.58618 KLD %: 10.567814729\n",
      "encoder inputs: they loved it !\n",
      "decoder inputs: they loved it !\n",
      "predictions: they are it .\n",
      "batch_ind/epoch: 300/4 out of 6961/5\n",
      "Last batch loss:31.9078 KDL: 3.77334 KLD %: 11.8257524857\n",
      "encoder inputs: the best thing ... no UNK .\n",
      "decoder inputs: the UNK thing ... no UNK .\n",
      "predictions: the best is happens the preservatives .\n",
      "batch_ind/epoch: 350/4 out of 6961/5\n",
      "Last batch loss:31.0399 KDL: 3.73993 KLD %: 12.048762694\n",
      "encoder inputs: me , into a UNK ! )\n",
      "decoder inputs: me , into UNK UNK ! UNK\n",
      "predictions: great , i the UNK . !\n",
      "batch_ind/epoch: 400/4 out of 6961/5\n",
      "Last batch loss:32.4791 KDL: 3.82265 KLD %: 11.7695860537\n",
      "encoder inputs: saying she loves these chews is a UNK understatement .\n",
      "decoder inputs: saying she UNK UNK chews is a UNK UNK .\n",
      "predictions: so link is a and and a little eater .\n",
      "batch_ind/epoch: 450/4 out of 6961/5\n",
      "Last batch loss:34.2465 KDL: 3.59933 KLD %: 10.5100834485\n",
      "encoder inputs: i compete in UNK and crave carbs while dieting .\n",
      "decoder inputs: i UNK UNK UNK and UNK carbs while dieting UNK\n",
      "predictions: i have the to to they it and it .\n",
      "batch_ind/epoch: 500/4 out of 6961/5\n",
      "Last batch loss:32.2017 KDL: 3.83143 KLD %: 11.8982234761\n",
      "encoder inputs: that 's really fast .\n",
      "decoder inputs: that 's really UNK .\n",
      "predictions: it 's a good .\n",
      "batch_ind/epoch: 550/4 out of 6961/5\n",
      "Last batch loss:30.9898 KDL: 3.8334 KLD %: 12.3698653474\n",
      "encoder inputs: but i was pleasantly surprised .\n",
      "decoder inputs: but i was UNK surprised .\n",
      "predictions: the it love n't . .\n",
      "batch_ind/epoch: 600/4 out of 6961/5\n",
      "Last batch loss:32.7457 KDL: 3.67272 KLD %: 11.2158567836\n",
      "encoder inputs: pour the hot water out of the cup .\n",
      "decoder inputs: pour the hot UNK UNK of the cup .\n",
      "predictions: but , UNK chocolate is is the UNK .\n",
      "batch_ind/epoch: 650/4 out of 6961/5\n",
      "Last batch loss:32.7633 KDL: 3.72111 KLD %: 11.3575724999\n",
      "encoder inputs: stir until melted .\n",
      "decoder inputs: stir until melted UNK\n",
      "predictions: it was dissolved .\n",
      "batch_ind/epoch: 700/4 out of 6961/5\n",
      "Last batch loss:28.1006 KDL: 3.889 KLD %: 13.8395492781\n",
      "encoder inputs: i would never buy this coffee again .\n",
      "decoder inputs: i UNK UNK buy UNK coffee again .\n",
      "predictions: i will definitely buy this product again .\n",
      "batch_ind/epoch: 750/4 out of 6961/5\n",
      "Last batch loss:33.7725 KDL: 3.61323 KLD %: 10.6987326434\n",
      "encoder inputs: the above indicates a lifelong relationship .\n",
      "decoder inputs: the above indicates a lifelong relationship UNK\n",
      "predictions: it UNK UNK is great also .\n",
      "batch_ind/epoch: 800/4 out of 6961/5\n",
      "Last batch loss:34.1902 KDL: 3.72471 KLD %: 10.8940682443\n",
      "encoder inputs: the spicing really suits the cashews .\n",
      "decoder inputs: the spicing really suits UNK cashews UNK\n",
      "predictions: the flavor is is and good .\n",
      "batch_ind/epoch: 850/4 out of 6961/5\n",
      "Last batch loss:26.8185 KDL: 3.80975 KLD %: 14.2057075508\n",
      "encoder inputs: it makes an excellent cup .\n",
      "decoder inputs: UNK makes UNK excellent UNK .\n",
      "predictions: it is a great tea .\n",
      "batch_ind/epoch: 900/4 out of 6961/5\n",
      "Last batch loss:33.0704 KDL: 3.75598 KLD %: 11.3575239592\n",
      "encoder inputs: these cookies are a favorite of mine .\n",
      "decoder inputs: these cookies UNK a favorite of mine .\n",
      "predictions: they are are are great snack mine .\n",
      "batch_ind/epoch: 950/4 out of 6961/5\n",
      "Last batch loss:35.9305 KDL: 3.66776 KLD %: 10.2079330109\n",
      "encoder inputs: worth a try !\n",
      "decoder inputs: UNK a try !\n",
      "predictions: what a disappointment !\n",
      "batch_ind/epoch: 1000/4 out of 6961/5\n",
      "Last batch loss:30.2019 KDL: 3.91675 KLD %: 12.9685600074\n",
      "encoder inputs: not to be .\n",
      "decoder inputs: not to UNK .\n",
      "predictions: thanks too worry .\n",
      "batch_ind/epoch: 1050/4 out of 6961/5\n",
      "Last batch loss:32.198 KDL: 3.96554 KLD %: 12.3160887896\n",
      "encoder inputs: i use it with plain yogurt and equal .\n",
      "decoder inputs: UNK use it with UNK yogurt and equal UNK\n",
      "predictions: i have it in a and and UNK .\n",
      "batch_ind/epoch: 1100/4 out of 6961/5\n",
      "Last batch loss:34.1075 KDL: 3.79422 KLD %: 11.1242898364\n",
      "encoder inputs: i would suggest those flavors over this one .\n",
      "decoder inputs: i would suggest UNK flavors over this one .\n",
      "predictions: i 'm recommend this this from the food .\n",
      "batch_ind/epoch: 1150/4 out of 6961/5\n",
      "Last batch loss:29.6319 KDL: 3.9109 KLD %: 13.198260351\n",
      "encoder inputs: but i will be ordering again .\n",
      "decoder inputs: but i will be ordering UNK .\n",
      "predictions: what i love buy buying again\n",
      "batch_ind/epoch: 1200/4 out of 6961/5\n",
      "Last batch loss:24.3271 KDL: 3.76805 KLD %: 15.4891039946\n",
      "encoder inputs: love it on popcorn now too !\n",
      "decoder inputs: love it on popcorn now too !\n",
      "predictions: but the , the and too !\n",
      "batch_ind/epoch: 1250/4 out of 6961/5\n",
      "Last batch loss:26.3259 KDL: 3.98707 KLD %: 15.1450163783\n",
      "encoder inputs: it is neat and resealable .\n",
      "decoder inputs: it is UNK and resealable UNK\n",
      "predictions: this is a and delicious .\n",
      "batch_ind/epoch: 1300/4 out of 6961/5\n",
      "Last batch loss:29.3858 KDL: 3.83404 KLD %: 13.0472679627\n",
      "encoder inputs: it 's sweet with a slight tartness .\n",
      "decoder inputs: UNK 's sweet UNK a slight tartness .\n",
      "predictions: it 's a , not little kick .\n",
      "batch_ind/epoch: 1350/4 out of 6961/5\n",
      "Last batch loss:35.4978 KDL: 3.65596 KLD %: 10.2991112336\n",
      "encoder inputs: it 's organic and seems to be nutritious !\n",
      "decoder inputs: it UNK UNK and seems to be nutritious !\n",
      "predictions: it 's a and it to be good .\n",
      "batch_ind/epoch: 1400/4 out of 6961/5\n",
      "Last batch loss:32.5581 KDL: 3.74102 KLD %: 11.4903136568\n",
      "encoder inputs: i love the taste .\n",
      "decoder inputs: UNK love UNK UNK UNK\n",
      "predictions: i love this coffee .\n",
      "batch_ind/epoch: 1450/4 out of 6961/5\n",
      "Last batch loss:32.2195 KDL: 3.73859 KLD %: 11.6034908365\n",
      "encoder inputs: we 'll see .\n",
      "decoder inputs: we 'll UNK UNK\n",
      "predictions: we love see !\n",
      "batch_ind/epoch: 1500/4 out of 6961/5\n",
      "Last batch loss:30.4948 KDL: 3.70345 KLD %: 12.1445190974\n",
      "encoder inputs: i would n't buy it again .\n",
      "decoder inputs: UNK UNK n't buy UNK UNK UNK\n",
      "predictions: i would not buy it again .\n",
      "batch_ind/epoch: 1550/4 out of 6961/5\n",
      "Last batch loss:29.988 KDL: 3.68753 KLD %: 12.2966559749\n",
      "encoder inputs: it is good for people on diets thanks\n",
      "decoder inputs: it UNK good for people UNK diets UNK\n",
      "predictions: it 's a and a and too .\n",
      "batch_ind/epoch: 1600/4 out of 6961/5\n",
      "Last batch loss:30.4861 KDL: 3.89286 KLD %: 12.7693045858\n",
      "encoder inputs: very good quality chocolate .\n",
      "decoder inputs: very UNK quality UNK UNK\n",
      "predictions: very happy and product .\n",
      "batch_ind/epoch: 1650/4 out of 6961/5\n",
      "Last batch loss:32.8531 KDL: 3.86945 KLD %: 11.7780228356\n",
      "encoder inputs: the duck pill pockets are a god send .\n",
      "decoder inputs: the UNK pill UNK UNK a god send UNK\n",
      "predictions: this flavor is pockets is and great send .\n",
      "batch_ind/epoch: 1700/4 out of 6961/5\n",
      "Last batch loss:30.9186 KDL: 3.72092 KLD %: 12.0345467325\n",
      "encoder inputs: i really missed my moo .\n",
      "decoder inputs: i UNK UNK UNK moo .\n",
      "predictions: i was not this it .\n",
      "batch_ind/epoch: 1750/4 out of 6961/5\n",
      "Last batch loss:33.185 KDL: 3.7082 KLD %: 11.1743337984\n",
      "encoder inputs: ca n't say enough good things about this cocoa .\n",
      "decoder inputs: UNK n't say enough good UNK UNK this UNK .\n",
      "predictions: my n't wait enough about for you this coffee .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_ind/epoch: 1800/4 out of 6961/5\n",
      "Last batch loss:31.6915 KDL: 3.91165 KLD %: 12.342881571\n",
      "encoder inputs: i ca n't wait to try more flavors !\n",
      "decoder inputs: i ca n't wait UNK UNK more flavors !\n",
      "predictions: i have n't wait to try the flavors .\n",
      "batch_ind/epoch: 1850/4 out of 6961/5\n",
      "Last batch loss:31.5324 KDL: 3.82009 KLD %: 12.1148121381\n",
      "encoder inputs: the chai latte is delicious !\n",
      "decoder inputs: UNK chai latte UNK delicious UNK\n",
      "predictions: the product is is . .\n",
      "batch_ind/epoch: 1900/4 out of 6961/5\n",
      "Last batch loss:33.239 KDL: 3.79386 KLD %: 11.4138537917\n",
      "encoder inputs: they arrived quickly and in good shape !\n",
      "decoder inputs: they UNK UNK and in UNK shape !\n",
      "predictions: they are a and very perfect . .\n",
      "batch_ind/epoch: 1950/4 out of 6961/5\n",
      "Last batch loss:31.9752 KDL: 3.68205 KLD %: 11.5153419416\n",
      "encoder inputs: i have to drink about two cups each time !\n",
      "decoder inputs: i UNK UNK drink UNK two cups UNK UNK UNK\n",
      "predictions: i have this to it a thumbs of day .\n",
      "batch_ind/epoch: 2000/4 out of 6961/5\n",
      "Last batch loss:30.367 KDL: 3.91028 KLD %: 12.8767570701\n",
      "encoder inputs: also , the food looks like real food .\n",
      "decoder inputs: also , UNK food looks like real food UNK\n",
      "predictions: and , the is to like i coconut .\n",
      "batch_ind/epoch: 2050/4 out of 6961/5\n",
      "Last batch loss:31.0131 KDL: 3.86374 KLD %: 12.4584157863\n",
      "encoder inputs: i highly recommend this product .\n",
      "decoder inputs: UNK highly recommend this product .\n",
      "predictions: i will recommend this product .\n",
      "batch_ind/epoch: 2100/4 out of 6961/5\n",
      "Last batch loss:32.2004 KDL: 3.82078 KLD %: 11.8656447767\n",
      "encoder inputs: dry and tough .\n",
      "decoder inputs: UNK and tough UNK\n",
      "predictions: UNK and UNK .\n",
      "batch_ind/epoch: 2150/4 out of 6961/5\n",
      "Last batch loss:33.6375 KDL: 3.80624 KLD %: 11.3154939386\n",
      "encoder inputs: i never got sick once while on this stuff .\n",
      "decoder inputs: i UNK UNK sick once UNK on this stuff UNK\n",
      "predictions: i have this to to a of this product .\n",
      "batch_ind/epoch: 2200/4 out of 6961/5\n",
      "Last batch loss:29.1904 KDL: 3.87631 KLD %: 13.2793776583\n",
      "encoder inputs: this candy is addicting !\n",
      "decoder inputs: this UNK is addicting !\n",
      "predictions: the stuff is great .\n",
      "batch_ind/epoch: 2250/4 out of 6961/5\n",
      "Last batch loss:32.2792 KDL: 3.86606 KLD %: 11.9769617785\n",
      "encoder inputs: it makes a great , easy lunch .\n",
      "decoder inputs: it UNK a great UNK easy UNK .\n",
      "predictions: it 's a great cup to pockets .\n",
      "batch_ind/epoch: 2300/4 out of 6961/5\n",
      "Last batch loss:30.7374 KDL: 3.762 KLD %: 12.239188472\n",
      "encoder inputs: the spices are perfect .\n",
      "decoder inputs: the UNK are perfect UNK\n",
      "predictions: the taste is great .\n",
      "batch_ind/epoch: 2350/4 out of 6961/5\n",
      "Last batch loss:31.5825 KDL: 3.84006 KLD %: 12.1588316739\n",
      "encoder inputs: no more begging for food every 5 minutes .\n",
      "decoder inputs: no more UNK UNK food every 5 UNK UNK\n",
      "predictions: what more UNK to , to to minutes .\n",
      "batch_ind/epoch: 2400/4 out of 6961/5\n",
      "Last batch loss:29.8521 KDL: 3.80414 KLD %: 12.7432733248\n",
      "encoder inputs: you 'll have to give it a try .\n",
      "decoder inputs: you 'll UNK UNK give UNK UNK UNK .\n",
      "predictions: i can be it with it a try .\n",
      "batch_ind/epoch: 2450/4 out of 6961/5\n",
      "Last batch loss:32.1548 KDL: 3.83258 KLD %: 11.9191422002\n",
      "encoder inputs: my stomach loves you .\n",
      "decoder inputs: UNK stomach loves you UNK\n",
      "predictions: my dog loves these .\n",
      "batch_ind/epoch: 2500/4 out of 6961/5\n",
      "Last batch loss:32.4842 KDL: 3.68102 KLD %: 11.3317293521\n",
      "encoder inputs: it 's too much .\n",
      "decoder inputs: it 's UNK UNK .\n",
      "predictions: it 's very good .\n",
      "batch_ind/epoch: 2550/4 out of 6961/5\n",
      "Last batch loss:29.29 KDL: 3.93938 KLD %: 13.4495797575\n",
      "encoder inputs: and it worked out even better than the muffins .\n",
      "decoder inputs: and UNK worked out UNK better than the UNK UNK\n",
      "predictions: if it 's great of the than the store .\n",
      "batch_ind/epoch: 2600/4 out of 6961/5\n",
      "Last batch loss:32.9491 KDL: 3.65274 KLD %: 11.086012642\n",
      "encoder inputs: great real coconut young coconut taste .\n",
      "decoder inputs: great real UNK young UNK taste UNK\n",
      "predictions: great for and and the UNK .\n",
      "batch_ind/epoch: 2650/4 out of 6961/5\n",
      "Last batch loss:31.6705 KDL: 3.86637 KLD %: 12.2081135152\n",
      "encoder inputs: i am very happy with this food ! ! !\n",
      "decoder inputs: i UNK UNK happy with this food ! UNK !\n",
      "predictions: i was not to with this product .\n",
      "batch_ind/epoch: 2700/4 out of 6961/5\n",
      "Last batch loss:31.4783 KDL: 3.74174 KLD %: 11.8867193417\n",
      "encoder inputs: what do i do with it now ? ?\n",
      "decoder inputs: what do i UNK with UNK now ? ?\n",
      "predictions: but 's you do it this product ?\n",
      "batch_ind/epoch: 2750/4 out of 6961/5\n",
      "Last batch loss:29.7545 KDL: 3.99963 KLD %: 13.4421164673\n",
      "encoder inputs: plus it 's rather noisy .\n",
      "decoder inputs: plus UNK UNK rather noisy .\n",
      "predictions: well , is is taste .\n",
      "batch_ind/epoch: 2800/4 out of 6961/5\n",
      "Last batch loss:27.9636 KDL: 3.83897 KLD %: 13.7284886217\n",
      "encoder inputs: it overwhelms the flavor .\n",
      "decoder inputs: it UNK UNK flavor .\n",
      "predictions: it is a good .\n",
      "batch_ind/epoch: 2850/4 out of 6961/5\n",
      "Last batch loss:30.2824 KDL: 3.77112 KLD %: 12.4531562358\n",
      "encoder inputs: i strongly recommend this popcorn .\n",
      "decoder inputs: i strongly UNK this UNK .\n",
      "predictions: i would recommend the product .\n",
      "batch_ind/epoch: 2900/4 out of 6961/5\n",
      "Last batch loss:30.0736 KDL: 3.91543 KLD %: 13.0194718606\n",
      "encoder inputs: it smelled absolutely sinful while it brewed .\n",
      "decoder inputs: UNK UNK UNK UNK while it brewed .\n",
      "predictions: it is is a and in is .\n",
      "batch_ind/epoch: 2950/4 out of 6961/5\n",
      "Last batch loss:32.237 KDL: 3.79689 KLD %: 11.7780569645\n",
      "encoder inputs: read every label peace\n",
      "decoder inputs: UNK every UNK UNK\n",
      "predictions: UNK , penny .\n",
      "batch_ind/epoch: 3000/4 out of 6961/5\n",
      "Last batch loss:32.7353 KDL: 3.85226 KLD %: 11.7679226732\n",
      "encoder inputs: the taste is very beef broth like .\n",
      "decoder inputs: UNK UNK UNK UNK beef broth like UNK\n",
      "predictions: the product is is is and . .\n",
      "batch_ind/epoch: 3050/4 out of 6961/5\n",
      "Last batch loss:31.5794 KDL: 3.87286 KLD %: 12.2638848908\n",
      "encoder inputs: i love it any time of the day .\n",
      "decoder inputs: i UNK it any time of UNK day .\n",
      "predictions: i have this to to of the day .\n",
      "batch_ind/epoch: 3100/4 out of 6961/5\n",
      "Last batch loss:31.8599 KDL: 3.72894 KLD %: 11.7042019008\n",
      "encoder inputs: best thing i 've ordered on line .\n",
      "decoder inputs: best thing i 've UNK on line UNK\n",
      "predictions: the of i have found had amazon .\n",
      "batch_ind/epoch: 3150/4 out of 6961/5\n",
      "Last batch loss:29.5134 KDL: 3.84836 KLD %: 13.0393587391\n",
      "encoder inputs: you wo n't be disappointed .\n",
      "decoder inputs: you UNK UNK be UNK .\n",
      "predictions: you will n't it disappointed .\n",
      "batch_ind/epoch: 3200/4 out of 6961/5\n",
      "Last batch loss:31.8273 KDL: 3.77029 KLD %: 11.8460739206\n",
      "encoder inputs: these wasabi flavored roasted UNK are okay .\n",
      "decoder inputs: these wasabi flavored roasted UNK UNK okay .\n",
      "predictions: these are peas and to the best .\n",
      "batch_ind/epoch: 3250/4 out of 6961/5\n",
      "Last batch loss:30.5512 KDL: 3.71628 KLD %: 12.164107213\n",
      "encoder inputs: enjoy ! gary peterson\n",
      "decoder inputs: enjoy UNK UNK peterson\n",
      "predictions: thanks it tea .\n",
      "batch_ind/epoch: 3300/4 out of 6961/5\n",
      "Last batch loss:30.8065 KDL: 3.86056 KLD %: 12.5316503875\n",
      "encoder inputs: zico is still amazing .\n",
      "decoder inputs: zico is still amazing .\n",
      "predictions: it is a alive .\n",
      "batch_ind/epoch: 3350/4 out of 6961/5\n",
      "Last batch loss:30.6413 KDL: 3.82858 KLD %: 12.4948303393\n",
      "encoder inputs: no bitterness at all .\n",
      "decoder inputs: UNK bitterness at all .\n",
      "predictions: no one , all .\n",
      "batch_ind/epoch: 3400/4 out of 6961/5\n",
      "Last batch loss:28.9398 KDL: 3.72902 KLD %: 12.8854030788\n",
      "encoder inputs: only 100 calories per bag .\n",
      "decoder inputs: UNK UNK UNK per bag UNK\n",
      "predictions: great , , the serving .\n",
      "batch_ind/epoch: 3450/4 out of 6961/5\n",
      "Last batch loss:30.0447 KDL: 3.84551 KLD %: 12.7993121541\n",
      "encoder inputs: it works 85 % of the time .\n",
      "decoder inputs: it works UNK % of the time UNK\n",
      "predictions: it 's well and with the UNK .\n",
      "batch_ind/epoch: 3500/4 out of 6961/5\n",
      "Last batch loss:33.0663 KDL: 3.8794 KLD %: 11.7321947344\n",
      "encoder inputs: the flavor is excellent UNK great .\n",
      "decoder inputs: the flavor is UNK UNK UNK .\n",
      "predictions: the product is very and too .\n",
      "batch_ind/epoch: 3550/4 out of 6961/5\n",
      "Last batch loss:31.8093 KDL: 3.71229 KLD %: 11.6704601594\n",
      "encoder inputs: love this product !\n",
      "decoder inputs: love this product UNK\n",
      "predictions: love the stuff .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_ind/epoch: 3600/4 out of 6961/5\n",
      "Last batch loss:29.0981 KDL: 3.76399 KLD %: 12.9355202052\n",
      "encoder inputs: her baking mixes are UNK .\n",
      "decoder inputs: her UNK mixes are UNK UNK\n",
      "predictions: so coat is are . .\n",
      "batch_ind/epoch: 3650/4 out of 6961/5\n",
      "Last batch loss:32.9444 KDL: 3.86836 KLD %: 11.7420578095\n",
      "encoder inputs: price with subscribe and save is very good .\n",
      "decoder inputs: price with subscribe and UNK is very UNK .\n",
      "predictions: but is the and save is the good .\n",
      "batch_ind/epoch: 3700/4 out of 6961/5\n",
      "Last batch loss:30.4198 KDL: 3.866 KLD %: 12.7088465272\n",
      "encoder inputs: one end is covered with a sticker .\n",
      "decoder inputs: one end is UNK with a sticker .\n",
      "predictions: it of of a for this spoon .\n",
      "batch_ind/epoch: 3750/4 out of 6961/5\n",
      "Last batch loss:29.5038 KDL: 3.93746 KLD %: 13.3455954511\n",
      "encoder inputs: they are all meat - absolutely nothing else .\n",
      "decoder inputs: they are UNK meat - absolutely nothing else .\n",
      "predictions: i are a and and not delicious bad .\n",
      "batch_ind/epoch: 3800/4 out of 6961/5\n",
      "Last batch loss:30.0812 KDL: 3.65394 KLD %: 12.1469401746\n",
      "encoder inputs: these cookies taste like the real thing !\n",
      "decoder inputs: UNK UNK taste like UNK real thing !\n",
      "predictions: these are are like a and thing .\n",
      "batch_ind/epoch: 3850/4 out of 6961/5\n",
      "Last batch loss:32.1374 KDL: 3.89975 KLD %: 12.1346383485\n",
      "encoder inputs: ) , so give them a try .\n",
      "decoder inputs: ) , so UNK UNK a try .\n",
      "predictions: but , i i , the difference .\n",
      "batch_ind/epoch: 3900/4 out of 6961/5\n",
      "Last batch loss:31.8922 KDL: 3.86394 KLD %: 12.1156445076\n",
      "encoder inputs: we definitely will be buying more .\n",
      "decoder inputs: we UNK will be buying more .\n",
      "predictions: what will it buy buying more .\n",
      "batch_ind/epoch: 3950/4 out of 6961/5\n",
      "Last batch loss:35.7413 KDL: 4.0248 KLD %: 11.2609137494\n",
      "encoder inputs: too expensive for 15 minutes of entertainment .\n",
      "decoder inputs: too expensive for UNK minutes UNK entertainment UNK\n",
      "predictions: and bad to the and to UNK .\n",
      "batch_ind/epoch: 4000/4 out of 6961/5\n",
      "Last batch loss:31.3098 KDL: 3.81071 KLD %: 12.1709980853\n",
      "encoder inputs: would definitely order this again and good price too !\n",
      "decoder inputs: would definitely order this again and good price too !\n",
      "predictions: very recommend recommend again again and again for too .\n",
      "batch_ind/epoch: 4050/4 out of 6961/5\n",
      "Last batch loss:31.8776 KDL: 3.78566 KLD %: 11.8756113121\n",
      "encoder inputs: this however is delicious !\n",
      "decoder inputs: UNK however is delicious !\n",
      "predictions: this product is great .\n",
      "batch_ind/epoch: 4100/4 out of 6961/5\n",
      "Last batch loss:33.0958 KDL: 3.7296 KLD %: 11.2690848251\n",
      "encoder inputs: loved the spray !\n",
      "decoder inputs: loved UNK spray !\n",
      "predictions: love the UNK .\n",
      "batch_ind/epoch: 4150/4 out of 6961/5\n",
      "Last batch loss:26.5336 KDL: 3.82989 KLD %: 14.4341193109\n",
      "encoder inputs: not what i hoped for .\n",
      "decoder inputs: not what UNK UNK for .\n",
      "predictions: not a i was for me\n",
      "batch_ind/epoch: 4200/4 out of 6961/5\n",
      "Last batch loss:29.7781 KDL: 3.78132 KLD %: 12.698328414\n",
      "encoder inputs: my kids love it too .\n",
      "decoder inputs: my kids love it too .\n",
      "predictions: they dog love these too !\n",
      "batch_ind/epoch: 4250/4 out of 6961/5\n",
      "Last batch loss:28.949 KDL: 3.88844 KLD %: 13.4320359878\n",
      "encoder inputs: it 's perfect for movie night !\n",
      "decoder inputs: it 's perfect UNK UNK night !\n",
      "predictions: it is a for my snack .\n",
      "batch_ind/epoch: 4300/4 out of 6961/5\n",
      "Last batch loss:27.9151 KDL: 3.95623 KLD %: 14.1723637567\n",
      "encoder inputs: this large package lasts us a long time .\n",
      "decoder inputs: this large package UNK us a long UNK UNK\n",
      "predictions: this tea size is a a great time .\n",
      "batch_ind/epoch: 4350/4 out of 6961/5\n",
      "Last batch loss:27.8534 KDL: 3.73825 KLD %: 13.4211531593\n",
      "encoder inputs: big plus for me .\n",
      "decoder inputs: big plus for me UNK\n",
      "predictions: very mistake , me .\n",
      "batch_ind/epoch: 4400/4 out of 6961/5\n",
      "Last batch loss:31.0762 KDL: 3.82026 KLD %: 12.293168394\n",
      "encoder inputs: perfect for snacking .\n",
      "decoder inputs: perfect for snacking .\n",
      "predictions: it for me .\n",
      "batch_ind/epoch: 4450/4 out of 6961/5\n",
      "Last batch loss:33.7383 KDL: 3.8287 KLD %: 11.3482278881\n",
      "encoder inputs: hard to tell that they are baked .\n",
      "decoder inputs: hard to tell that they are UNK .\n",
      "predictions: all to find the i are good .\n",
      "batch_ind/epoch: 4500/4 out of 6961/5\n",
      "Last batch loss:31.0801 KDL: 3.87399 KLD %: 12.4645364631\n",
      "encoder inputs: this yummy little baked confection was truly delicious .\n",
      "decoder inputs: this yummy little baked confection was truly UNK .\n",
      "predictions: this is is UNK , so a exceptional .\n",
      "batch_ind/epoch: 4550/4 out of 6961/5\n",
      "Last batch loss:30.266 KDL: 3.928 KLD %: 12.978260027\n",
      "encoder inputs: i was very happy with this product .\n",
      "decoder inputs: i was very UNK UNK this product .\n",
      "predictions: i will very disappointed with this product .\n",
      "batch_ind/epoch: 4600/4 out of 6961/5\n",
      "Last batch loss:30.3125 KDL: 3.92283 KLD %: 12.9413247651\n",
      "encoder inputs: use this over rice for a meal !\n",
      "decoder inputs: use this over UNK for a meal !\n",
      "predictions: and a for a a my snack .\n",
      "batch_ind/epoch: 4650/4 out of 6961/5\n",
      "Last batch loss:23.7971 KDL: 3.77228 KLD %: 15.8518615278\n",
      "encoder inputs: no heavy flavor .\n",
      "decoder inputs: UNK UNK UNK .\n",
      "predictions: this stuff is .\n",
      "batch_ind/epoch: 4700/4 out of 6961/5\n",
      "Last batch loss:28.3577 KDL: 3.80374 KLD %: 13.4134194005\n",
      "encoder inputs: everything about this product is excellent .\n",
      "decoder inputs: everything about this product is excellent .\n",
      "predictions: you arrived this product is great .\n",
      "batch_ind/epoch: 4750/4 out of 6961/5\n",
      "Last batch loss:32.2711 KDL: 3.73797 KLD %: 11.5830187428\n",
      "encoder inputs: i love them !\n",
      "decoder inputs: UNK love them UNK\n",
      "predictions: i love it .\n",
      "batch_ind/epoch: 4800/4 out of 6961/5\n",
      "Last batch loss:30.1692 KDL: 3.92958 KLD %: 13.0251469288\n",
      "encoder inputs: this year everyone is going to be happy !\n",
      "decoder inputs: this year everyone is going to be UNK UNK\n",
      "predictions: this product round is a to be working .\n",
      "batch_ind/epoch: 4850/4 out of 6961/5\n",
      "Last batch loss:28.2238 KDL: 3.86767 KLD %: 13.7035717049\n",
      "encoder inputs: these are the best tasting pretzels !\n",
      "decoder inputs: UNK are the best UNK pretzels UNK\n",
      "predictions: these are the best ever ever .\n",
      "batch_ind/epoch: 4900/4 out of 6961/5\n",
      "Last batch loss:33.0207 KDL: 3.80278 KLD %: 11.5163366369\n",
      "encoder inputs: i do n't like overly sweet drinks .\n",
      "decoder inputs: i do UNK like overly sweet drinks .\n",
      "predictions: they love n't think the of potatoes .\n",
      "batch_ind/epoch: 4950/4 out of 6961/5\n",
      "Last batch loss:28.2909 KDL: 3.77402 KLD %: 13.3400613164\n",
      "encoder inputs: did you know it was invented by a doctor !\n",
      "decoder inputs: did UNK UNK UNK was invented by a doctor UNK\n",
      "predictions: these n't mention the , a than the deal .\n",
      "batch_ind/epoch: 5000/4 out of 6961/5\n",
      "Last batch loss:29.3834 KDL: 3.71587 KLD %: 12.6461611024\n",
      "encoder inputs: the tea is delicious .\n",
      "decoder inputs: the UNK UNK UNK .\n",
      "predictions: the flavor is great .\n",
      "batch_ind/epoch: 5050/4 out of 6961/5\n",
      "Last batch loss:28.5887 KDL: 3.69222 KLD %: 12.9149584665\n",
      "encoder inputs: good price even with the shipping costs .\n",
      "decoder inputs: UNK UNK even UNK the UNK costs UNK\n",
      "predictions: the price is better a same flavor .\n",
      "batch_ind/epoch: 5100/4 out of 6961/5\n",
      "Last batch loss:29.0515 KDL: 3.96907 KLD %: 13.6621673852\n",
      "encoder inputs: thank you cesar !\n",
      "decoder inputs: UNK you cesar !\n",
      "predictions: thank you amazon !\n",
      "batch_ind/epoch: 5150/4 out of 6961/5\n",
      "Last batch loss:29.1381 KDL: 3.88376 KLD %: 13.3288013906\n",
      "encoder inputs: recipe available on UNK `` chocolate biscuit cake . ''\n",
      "decoder inputs: recipe UNK UNK UNK UNK UNK biscuit cake . UNK\n",
      "predictions: then , the , , a the more .\n",
      "batch_ind/epoch: 5200/4 out of 6961/5\n",
      "Last batch loss:32.8108 KDL: 3.7965 KLD %: 11.5709004029\n",
      "encoder inputs: this xylitol in packets is very chalky in taste .\n",
      "decoder inputs: this xylitol UNK packets UNK very chalky UNK UNK .\n",
      "predictions: this product is great for the good and . .\n",
      "batch_ind/epoch: 5250/4 out of 6961/5\n",
      "Last batch loss:32.2445 KDL: 3.78626 KLD %: 11.7423728423\n",
      "encoder inputs: even the hot coco has the artificial sweetener .\n",
      "decoder inputs: UNK the UNK coco has the artificial UNK .\n",
      "predictions: try , best of is a best sweeteners .\n",
      "batch_ind/epoch: 5300/4 out of 6961/5\n",
      "Last batch loss:28.4899 KDL: 3.97739 KLD %: 13.9606902869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder inputs: ca n't beat that !\n",
      "decoder inputs: ca n't beat that !\n",
      "predictions: will n't beat it .\n",
      "batch_ind/epoch: 5350/4 out of 6961/5\n",
      "Last batch loss:32.1877 KDL: 3.73951 KLD %: 11.6177910184\n",
      "encoder inputs: she devours every bite .\n",
      "decoder inputs: she devours UNK bite .\n",
      "predictions: these always them it .\n",
      "batch_ind/epoch: 5400/4 out of 6961/5\n",
      "Last batch loss:31.968 KDL: 3.91678 KLD %: 12.2521771922\n",
      "encoder inputs: this really tastes like ginger and honey !\n",
      "decoder inputs: this really UNK like ginger and UNK UNK\n",
      "predictions: this is is the a and UNK .\n",
      "batch_ind/epoch: 5450/4 out of 6961/5\n",
      "Last batch loss:34.4834 KDL: 3.82861 KLD %: 11.1027741177\n",
      "encoder inputs: i could n't be happier !\n",
      "decoder inputs: i could UNK be happier !\n",
      "predictions: i love n't believe happier .\n",
      "batch_ind/epoch: 5500/4 out of 6961/5\n",
      "Last batch loss:28.846 KDL: 4.09104 KLD %: 14.1823571527\n",
      "encoder inputs: my havanese just loves these treats with the apples !\n",
      "decoder inputs: my UNK just UNK these UNK with the apples !\n",
      "predictions: my husband is loves n't treats a the UNK .\n",
      "batch_ind/epoch: 5550/4 out of 6961/5\n",
      "Last batch loss:30.8062 KDL: 4.05211 KLD %: 13.153553318\n",
      "encoder inputs: all six cans were rancid .\n",
      "decoder inputs: UNK six cans UNK rancid .\n",
      "predictions: it is is were . .\n",
      "batch_ind/epoch: 5600/4 out of 6961/5\n",
      "Last batch loss:35.9443 KDL: 3.72395 KLD %: 10.3603365891\n",
      "encoder inputs: this particular one is the mild sweet style .\n",
      "decoder inputs: UNK UNK one is the UNK sweet style .\n",
      "predictions: this tea is of the best nutrient . .\n",
      "batch_ind/epoch: 5650/4 out of 6961/5\n",
      "Last batch loss:31.6412 KDL: 3.93369 KLD %: 12.432185885\n",
      "encoder inputs: i wanted to love these .\n",
      "decoder inputs: i UNK UNK love these .\n",
      "predictions: i love this this it .\n",
      "batch_ind/epoch: 5700/4 out of 6961/5\n",
      "Last batch loss:30.4983 KDL: 3.96292 KLD %: 12.9939370352\n",
      "encoder inputs: however , the UNK process is UNK .\n",
      "decoder inputs: however , the UNK process UNK UNK UNK\n",
      "predictions: but , the taste is is UNK .\n",
      "batch_ind/epoch: 5750/4 out of 6961/5\n",
      "Last batch loss:34.16 KDL: 3.79209 KLD %: 11.1009495585\n",
      "encoder inputs: on to a chinese type dish next .\n",
      "decoder inputs: UNK to UNK chinese type dish UNK .\n",
      "predictions: but , the , a of UNK .\n",
      "batch_ind/epoch: 5800/4 out of 6961/5\n",
      "Last batch loss:30.6146 KDL: 4.03754 KLD %: 13.1882646156\n",
      "encoder inputs: would n't have it any other way !\n",
      "decoder inputs: UNK UNK have UNK any other way !\n",
      "predictions: my family and to a other treats .\n",
      "batch_ind/epoch: 5850/4 out of 6961/5\n",
      "Last batch loss:31.6165 KDL: 3.84228 KLD %: 12.1527913934\n",
      "encoder inputs: and far more nutritious than a standard fruit snack .\n",
      "decoder inputs: and far more nutritious than UNK standard fruit snack UNK\n",
      "predictions: and it , than , a , a punch .\n",
      "batch_ind/epoch: 5900/4 out of 6961/5\n",
      "Last batch loss:32.6869 KDL: 3.94579 KLD %: 12.0714828555\n",
      "encoder inputs: i had my package within 4 days .\n",
      "decoder inputs: i had my package within 4 days UNK\n",
      "predictions: i have to UNK in 2 days .\n",
      "batch_ind/epoch: 5950/4 out of 6961/5\n",
      "Last batch loss:25.0697 KDL: 3.81042 KLD %: 15.1992787143\n",
      "encoder inputs: i love the convenience of the auto ship program .\n",
      "decoder inputs: UNK love the convenience of the UNK ship UNK .\n",
      "predictions: i have the flavor of the tea of program .\n",
      "batch_ind/epoch: 6000/4 out of 6961/5\n",
      "Last batch loss:36.0777 KDL: 3.55405 KLD %: 9.85110885518\n",
      "encoder inputs: friends of ours were in from great britain .\n",
      "decoder inputs: friends UNK ours were UNK from great UNK UNK\n",
      "predictions: in , this is not , the flavor .\n",
      "batch_ind/epoch: 6050/4 out of 6961/5\n",
      "Last batch loss:32.9664 KDL: 3.78057 KLD %: 11.4679431941\n",
      "encoder inputs: skip this one .\n",
      "decoder inputs: skip this one .\n",
      "predictions: love this one .\n",
      "batch_ind/epoch: 6100/4 out of 6961/5\n",
      "Last batch loss:28.5944 KDL: 3.67247 KLD %: 12.8433178125\n",
      "encoder inputs: they are really amazing .\n",
      "decoder inputs: they are really amazing .\n",
      "predictions: they are very good .\n",
      "batch_ind/epoch: 6150/4 out of 6961/5\n",
      "Last batch loss:27.7477 KDL: 3.9966 KLD %: 14.4033446228\n",
      "encoder inputs: this is a dark , chocolaty UNK .\n",
      "decoder inputs: this is UNK dark UNK chocolaty UNK .\n",
      "predictions: this is a best roast coffee tea .\n",
      "batch_ind/epoch: 6200/4 out of 6961/5\n",
      "Last batch loss:27.2819 KDL: 3.93151 KLD %: 14.4107139998\n",
      "encoder inputs: i contacted the seller but got no response .\n",
      "decoder inputs: UNK UNK UNK UNK but UNK no response UNK\n",
      "predictions: i have n't to a not UNK . .\n",
      "batch_ind/epoch: 6250/4 out of 6961/5\n",
      "Last batch loss:32.3505 KDL: 3.86183 KLD %: 11.9374783031\n",
      "encoder inputs: most importantly my house is bug free .\n",
      "decoder inputs: most UNK my house is bug UNK .\n",
      "predictions: so of the dogs , the UNK .\n",
      "batch_ind/epoch: 6300/4 out of 6961/5\n",
      "Last batch loss:30.9346 KDL: 3.88651 KLD %: 12.5636367022\n",
      "encoder inputs: no nasty aftertaste .\n",
      "decoder inputs: no nasty UNK UNK\n",
      "predictions: this more or either .\n",
      "batch_ind/epoch: 6350/4 out of 6961/5\n",
      "Last batch loss:33.8646 KDL: 3.7991 KLD %: 11.2185103394\n",
      "encoder inputs: catches everything from UNK to UNK .\n",
      "decoder inputs: UNK everything from UNK UNK UNK UNK\n",
      "predictions: the , is the is . .\n",
      "batch_ind/epoch: 6400/4 out of 6961/5\n",
      "Last batch loss:35.7918 KDL: 4.0138 KLD %: 11.2143053859\n",
      "encoder inputs: give it a try , it 's delicious !\n",
      "decoder inputs: give it a UNK UNK it 's delicious !\n",
      "predictions: we it a try , you 's a !\n",
      "batch_ind/epoch: 6450/4 out of 6961/5\n",
      "Last batch loss:31.7146 KDL: 3.86205 KLD %: 12.1774939491\n",
      "encoder inputs: really delicious seasoning and UNK that i highly recommend .\n",
      "decoder inputs: UNK UNK seasoning and UNK that i highly recommend .\n",
      "predictions: the is is , the is is love recommend .\n",
      "batch_ind/epoch: 6500/4 out of 6961/5\n",
      "Last batch loss:32.0992 KDL: 3.80006 KLD %: 11.838485856\n",
      "encoder inputs: not just pleasantly surprised but actually amazed .\n",
      "decoder inputs: not just pleasantly UNK but actually amazed UNK\n",
      "predictions: and too the surprised but not good . .\n",
      "batch_ind/epoch: 6550/4 out of 6961/5\n",
      "Last batch loss:32.547 KDL: 3.91804 KLD %: 12.0381138113\n",
      "encoder inputs: plus they 're biodegradable !\n",
      "decoder inputs: plus they 're biodegradable !\n",
      "predictions: well it are great .\n",
      "batch_ind/epoch: 6600/4 out of 6961/5\n",
      "Last batch loss:32.1804 KDL: 3.75009 KLD %: 11.6533245921\n",
      "encoder inputs: the cats love it .\n",
      "decoder inputs: the cats UNK UNK .\n",
      "predictions: the flavor love it .\n",
      "batch_ind/epoch: 6650/4 out of 6961/5\n",
      "Last batch loss:31.5192 KDL: 3.8768 KLD %: 12.2998012665\n",
      "encoder inputs: somehow it turned salty soapy very bitter taste .\n",
      "decoder inputs: somehow it turned salty soapy UNK bitter UNK .\n",
      "predictions: but , is out and day for taste .\n",
      "batch_ind/epoch: 6700/4 out of 6961/5\n",
      "Last batch loss:27.1645 KDL: 3.98649 KLD %: 14.6753590463\n",
      "encoder inputs: you choose how often to receive delivery .\n",
      "decoder inputs: UNK choose how often to receive delivery .\n",
      "predictions: you can to good this order . .\n",
      "batch_ind/epoch: 6750/4 out of 6961/5\n",
      "Last batch loss:30.6171 KDL: 3.99565 KLD %: 13.05039576\n",
      "encoder inputs: there is no nasty after taste or any jitters .\n",
      "decoder inputs: UNK is UNK nasty after taste UNK any jitters .\n",
      "predictions: it is a and , a , the aftertaste .\n",
      "batch_ind/epoch: 6800/4 out of 6961/5\n",
      "Last batch loss:31.451 KDL: 3.82076 KLD %: 12.1482798513\n",
      "encoder inputs: amazon , of course , popped up !\n",
      "decoder inputs: amazon , of course , UNK up !\n",
      "predictions: you has i course , very UNK .\n",
      "batch_ind/epoch: 6850/4 out of 6961/5\n",
      "Last batch loss:27.0932 KDL: 3.88381 KLD %: 14.3350072131\n",
      "encoder inputs: this brand is the best tasting to me .\n",
      "decoder inputs: this brand is the best UNK UNK me .\n",
      "predictions: this coffee is a best i i ever .\n",
      "batch_ind/epoch: 6900/4 out of 6961/5\n",
      "Last batch loss:29.3399 KDL: 3.85308 KLD %: 13.1325410799\n",
      "encoder inputs: i would recommend these for kids and adults !\n",
      "decoder inputs: UNK would recommend UNK UNK UNK and adults UNK\n",
      "predictions: i will recommend this to to to UNK .\n",
      "batch_ind/epoch: 6950/4 out of 6961/5\n",
      "Last batch loss:33.5735 KDL: 3.78775 KLD %: 11.2819670959\n",
      "encoder inputs: it is simply superior rice .\n",
      "decoder inputs: UNK UNK UNK superior rice UNK\n",
      "predictions: it is a good . .\n",
      "WARNING:tensorflow:Error encountered when serializing model_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'bytes' object has no attribute 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: %ssave/VAE-0\n",
      "execution took: 54361.80374712 seconds\n",
      "batch_ind/epoch: 1/5 out of 6961/5\n",
      "Last batch loss:30.3562 KDL: 3.88398 KLD %: 12.7946968037\n",
      "encoder inputs: not too chewy , and very flavorful .\n",
      "decoder inputs: not too UNK , UNK very UNK .\n",
      "predictions: and too sweet , but too good .\n",
      "batch_ind/epoch: 50/5 out of 6961/5\n",
      "Last batch loss:32.2413 KDL: 3.77541 KLD %: 11.7098728776\n",
      "encoder inputs: tastes pretty crappy .\n",
      "decoder inputs: tastes pretty crappy UNK\n",
      "predictions: will great good .\n",
      "batch_ind/epoch: 100/5 out of 6961/5\n",
      "Last batch loss:26.0171 KDL: 3.88032 KLD %: 14.9145059427\n",
      "encoder inputs: i 'm still not sure what flavor it is .\n",
      "decoder inputs: UNK 'm still not sure what flavor it is .\n",
      "predictions: i will not not to what to is is .\n",
      "batch_ind/epoch: 150/5 out of 6961/5\n",
      "Last batch loss:29.6097 KDL: 3.71155 KLD %: 12.5349120559\n",
      "encoder inputs: now i have 5 lbs .\n",
      "decoder inputs: now UNK have UNK UNK .\n",
      "predictions: the i is a it .\n",
      "batch_ind/epoch: 200/5 out of 6961/5\n",
      "Last batch loss:30.4798 KDL: 3.7583 KLD %: 12.3304626206\n",
      "encoder inputs: the 4 packages arrived not in an outer box !\n",
      "decoder inputs: UNK 4 packages UNK UNK in an outer UNK !\n",
      "predictions: the flavor pack is the and the outer snack .\n",
      "batch_ind/epoch: 250/5 out of 6961/5\n",
      "Last batch loss:33.6982 KDL: 3.86141 KLD %: 11.4588098423\n",
      "encoder inputs: they loved it !\n",
      "decoder inputs: they loved it UNK\n",
      "predictions: they are it !\n",
      "batch_ind/epoch: 300/5 out of 6961/5\n",
      "Last batch loss:31.4878 KDL: 3.91203 KLD %: 12.4239325325\n",
      "encoder inputs: the best thing ... no UNK .\n",
      "decoder inputs: UNK UNK thing ... no UNK UNK\n",
      "predictions: the , , is the preservatives .\n",
      "batch_ind/epoch: 350/5 out of 6961/5\n",
      "Last batch loss:30.3825 KDL: 3.863 KLD %: 12.7145581207\n",
      "encoder inputs: me , into a UNK ! )\n",
      "decoder inputs: UNK , UNK UNK UNK ! UNK\n",
      "predictions: these , i , good .\n",
      "batch_ind/epoch: 400/5 out of 6961/5\n",
      "Last batch loss:31.3881 KDL: 3.96329 KLD %: 12.6267439715\n",
      "encoder inputs: saying she loves these chews is a UNK understatement .\n",
      "decoder inputs: saying she loves UNK chews is UNK UNK understatement .\n",
      "predictions: in the does the and and the and treats .\n",
      "batch_ind/epoch: 450/5 out of 6961/5\n",
      "Last batch loss:33.4828 KDL: 3.69819 KLD %: 11.045038256\n",
      "encoder inputs: i compete in UNK and crave carbs while dieting .\n",
      "decoder inputs: i compete UNK UNK and crave carbs UNK dieting .\n",
      "predictions: i have with with the i it to it .\n",
      "batch_ind/epoch: 500/5 out of 6961/5\n",
      "Last batch loss:32.2043 KDL: 3.91236 KLD %: 12.1485663639\n",
      "encoder inputs: that 's really fast .\n",
      "decoder inputs: that 's really fast .\n",
      "predictions: it 's a good .\n",
      "batch_ind/epoch: 550/5 out of 6961/5\n",
      "Last batch loss:30.5504 KDL: 3.92393 KLD %: 12.84409124\n",
      "encoder inputs: but i was pleasantly surprised .\n",
      "decoder inputs: but i was pleasantly surprised .\n",
      "predictions: but i love very surprised .\n",
      "batch_ind/epoch: 600/5 out of 6961/5\n",
      "Last batch loss:32.486 KDL: 3.87359 KLD %: 11.9238617794\n",
      "encoder inputs: pour the hot water out of the cup .\n",
      "decoder inputs: pour the hot water out UNK the UNK .\n",
      "predictions: so it UNK chocolate is of the same .\n",
      "batch_ind/epoch: 650/5 out of 6961/5\n",
      "Last batch loss:31.0879 KDL: 3.8238 KLD %: 12.2999673293\n",
      "encoder inputs: stir until melted .\n",
      "decoder inputs: stir until melted .\n",
      "predictions: oh and melted .\n",
      "batch_ind/epoch: 700/5 out of 6961/5\n",
      "Last batch loss:26.8657 KDL: 3.96313 KLD %: 14.7516610526\n",
      "encoder inputs: i would never buy this coffee again .\n",
      "decoder inputs: i would never buy this coffee again UNK\n",
      "predictions: i will not buy this product again .\n",
      "batch_ind/epoch: 750/5 out of 6961/5\n",
      "Last batch loss:32.1703 KDL: 3.73959 KLD %: 11.6243501611\n",
      "encoder inputs: the above indicates a lifelong relationship .\n",
      "decoder inputs: UNK UNK UNK UNK UNK relationship UNK\n",
      "predictions: the is is is is UNK .\n",
      "batch_ind/epoch: 800/5 out of 6961/5\n",
      "Last batch loss:34.1078 KDL: 3.90857 KLD %: 11.459465505\n",
      "encoder inputs: the spicing really suits the cashews .\n",
      "decoder inputs: the UNK really UNK UNK cashews UNK\n",
      "predictions: the taste is is the good .\n",
      "batch_ind/epoch: 850/5 out of 6961/5\n",
      "Last batch loss:25.8413 KDL: 3.94995 KLD %: 15.2854012308\n",
      "encoder inputs: it makes an excellent cup .\n",
      "decoder inputs: it makes an UNK UNK .\n",
      "predictions: it is a excellent product .\n",
      "batch_ind/epoch: 900/5 out of 6961/5\n",
      "Last batch loss:32.2233 KDL: 3.81618 KLD %: 11.8428934839\n",
      "encoder inputs: these cookies are a favorite of mine .\n",
      "decoder inputs: these cookies are a favorite of mine .\n",
      "predictions: these are are my great treat . .\n",
      "batch_ind/epoch: 950/5 out of 6961/5\n",
      "Last batch loss:35.4564 KDL: 3.77975 KLD %: 10.6602696636\n",
      "encoder inputs: worth a try !\n",
      "decoder inputs: UNK a try !\n",
      "predictions: love this treat !\n",
      "batch_ind/epoch: 1000/5 out of 6961/5\n",
      "Last batch loss:29.3739 KDL: 4.1113 KLD %: 13.9964509278\n",
      "encoder inputs: not to be .\n",
      "decoder inputs: not UNK be UNK\n",
      "predictions: not too sweet .\n",
      "batch_ind/epoch: 1050/5 out of 6961/5\n",
      "Last batch loss:32.3278 KDL: 4.0243 KLD %: 12.448416061\n",
      "encoder inputs: i use it with plain yogurt and equal .\n",
      "decoder inputs: i use it with plain yogurt and equal UNK\n",
      "predictions: i am it for a and and honey .\n",
      "batch_ind/epoch: 1100/5 out of 6961/5\n",
      "Last batch loss:34.0577 KDL: 3.98739 KLD %: 11.7077498805\n",
      "encoder inputs: i would suggest those flavors over this one .\n",
      "decoder inputs: UNK UNK suggest UNK UNK over UNK one .\n",
      "predictions: i would recommend to to a the years .\n",
      "batch_ind/epoch: 1150/5 out of 6961/5\n",
      "Last batch loss:28.8432 KDL: 3.98943 KLD %: 13.8314400853\n",
      "encoder inputs: but i will be ordering again .\n",
      "decoder inputs: UNK i will be UNK again .\n",
      "predictions: what , love buy buying again .\n",
      "batch_ind/epoch: 1200/5 out of 6961/5\n",
      "Last batch loss:23.3742 KDL: 3.85754 KLD %: 16.5034128615\n",
      "encoder inputs: love it on popcorn now too !\n",
      "decoder inputs: UNK it on popcorn now too UNK\n",
      "predictions: we , 's a , too .\n",
      "batch_ind/epoch: 1250/5 out of 6961/5\n",
      "Last batch loss:27.1179 KDL: 4.16635 KLD %: 15.3638127773\n",
      "encoder inputs: it is neat and resealable .\n",
      "decoder inputs: UNK is neat and resealable .\n",
      "predictions: it 's a the UNK .\n",
      "batch_ind/epoch: 1300/5 out of 6961/5\n",
      "Last batch loss:29.1185 KDL: 4.00501 KLD %: 13.7541705739\n",
      "encoder inputs: it 's sweet with a slight tartness .\n",
      "decoder inputs: UNK 's sweet with UNK UNK UNK .\n",
      "predictions: it 's a and a little flavor .\n",
      "batch_ind/epoch: 1350/5 out of 6961/5\n",
      "Last batch loss:34.397 KDL: 3.80848 KLD %: 11.0721256697\n",
      "encoder inputs: it 's organic and seems to be nutritious !\n",
      "decoder inputs: it 's organic UNK seems to be nutritious UNK\n",
      "predictions: it is a and , to be good .\n",
      "batch_ind/epoch: 1400/5 out of 6961/5\n",
      "Last batch loss:31.2415 KDL: 3.91215 KLD %: 12.522294574\n",
      "encoder inputs: i love the taste .\n",
      "decoder inputs: i love the taste .\n",
      "predictions: they love this taste .\n",
      "batch_ind/epoch: 1450/5 out of 6961/5\n",
      "Last batch loss:31.9726 KDL: 3.89071 KLD %: 12.1688855206\n",
      "encoder inputs: we 'll see .\n",
      "decoder inputs: UNK 'll see .\n",
      "predictions: we love see .\n",
      "batch_ind/epoch: 1500/5 out of 6961/5\n",
      "Last batch loss:29.6582 KDL: 3.9632 KLD %: 13.3629488633\n",
      "encoder inputs: i would n't buy it again .\n",
      "decoder inputs: i would UNK buy UNK again UNK\n",
      "predictions: i will not recommend this again .\n",
      "batch_ind/epoch: 1550/5 out of 6961/5\n",
      "Last batch loss:29.5941 KDL: 3.77174 KLD %: 12.7449275774\n",
      "encoder inputs: it is good for people on diets thanks\n",
      "decoder inputs: it is good for people UNK diets thanks\n",
      "predictions: i 's a and you and UNK .\n",
      "batch_ind/epoch: 1600/5 out of 6961/5\n",
      "Last batch loss:30.3368 KDL: 3.99935 KLD %: 13.1831856311\n",
      "encoder inputs: very good quality chocolate .\n",
      "decoder inputs: UNK UNK quality chocolate .\n",
      "predictions: thank you loves product .\n",
      "batch_ind/epoch: 1650/5 out of 6961/5\n",
      "Last batch loss:32.7739 KDL: 4.02784 KLD %: 12.2897512783\n",
      "encoder inputs: the duck pill pockets are a god send .\n",
      "decoder inputs: the duck pill pockets are UNK god send .\n",
      "predictions: the UNK and pockets are the good . .\n",
      "batch_ind/epoch: 1700/5 out of 6961/5\n",
      "Last batch loss:31.2542 KDL: 3.92269 KLD %: 12.5509177709\n",
      "encoder inputs: i really missed my moo .\n",
      "decoder inputs: i UNK missed my moo .\n",
      "predictions: i love this this UNK .\n",
      "batch_ind/epoch: 1750/5 out of 6961/5\n",
      "Last batch loss:32.4078 KDL: 3.92494 KLD %: 12.1110874843\n",
      "encoder inputs: ca n't say enough good things about this cocoa .\n",
      "decoder inputs: ca n't say enough UNK things about this cocoa .\n",
      "predictions: do n't wait enough about it about this product .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_ind/epoch: 1800/5 out of 6961/5\n",
      "Last batch loss:31.8525 KDL: 4.0082 KLD %: 12.5836443637\n",
      "encoder inputs: i ca n't wait to try more flavors !\n",
      "decoder inputs: i ca UNK UNK to try more flavors !\n",
      "predictions: i love n't wait enough try the flavors .\n",
      "batch_ind/epoch: 1850/5 out of 6961/5\n",
      "Last batch loss:31.6797 KDL: 3.90598 KLD %: 12.3295985293\n",
      "encoder inputs: the chai latte is delicious !\n",
      "decoder inputs: the chai latte is delicious !\n",
      "predictions: great taste is is great .\n",
      "batch_ind/epoch: 1900/5 out of 6961/5\n",
      "Last batch loss:32.632 KDL: 3.86472 KLD %: 11.8433530237\n",
      "encoder inputs: they arrived quickly and in good shape !\n",
      "decoder inputs: they UNK UNK and UNK good shape !\n",
      "predictions: they are a and they are too .\n",
      "batch_ind/epoch: 1950/5 out of 6961/5\n",
      "Last batch loss:31.9208 KDL: 3.833 KLD %: 12.0078525613\n",
      "encoder inputs: i have to drink about two cups each time !\n",
      "decoder inputs: i have to UNK UNK UNK cups each time !\n",
      "predictions: i am been say it for the it . .\n",
      "batch_ind/epoch: 2000/5 out of 6961/5\n",
      "Last batch loss:29.5264 KDL: 4.05172 KLD %: 13.7223531696\n",
      "encoder inputs: also , the food looks like real food .\n",
      "decoder inputs: also , the food UNK UNK real food .\n",
      "predictions: and , the price is is is deal .\n",
      "batch_ind/epoch: 2050/5 out of 6961/5\n",
      "Last batch loss:30.2064 KDL: 3.91252 KLD %: 12.9526057787\n",
      "encoder inputs: i highly recommend this product .\n",
      "decoder inputs: i highly recommend this product .\n",
      "predictions: i highly recommend this product .\n",
      "batch_ind/epoch: 2100/5 out of 6961/5\n",
      "Last batch loss:31.3436 KDL: 3.98663 KLD %: 12.7191089346\n",
      "encoder inputs: dry and tough .\n",
      "decoder inputs: dry and tough .\n",
      "predictions: UNK and tasteless .\n",
      "batch_ind/epoch: 2150/5 out of 6961/5\n",
      "Last batch loss:32.5942 KDL: 3.90315 KLD %: 11.9749942067\n",
      "encoder inputs: i never got sick once while on this stuff .\n",
      "decoder inputs: i never UNK UNK once UNK on this UNK .\n",
      "predictions: i have run to to and in this one .\n",
      "batch_ind/epoch: 2200/5 out of 6961/5\n",
      "Last batch loss:28.8226 KDL: 4.06988 KLD %: 14.1204608408\n",
      "encoder inputs: this candy is addicting !\n",
      "decoder inputs: this candy is UNK !\n",
      "predictions: this stuff is great !\n",
      "batch_ind/epoch: 2250/5 out of 6961/5\n",
      "Last batch loss:31.5522 KDL: 4.03734 KLD %: 12.7957466286\n",
      "encoder inputs: it makes a great , easy lunch .\n",
      "decoder inputs: it makes a great , easy lunch UNK\n",
      "predictions: it 's a great cup too cup .\n",
      "batch_ind/epoch: 2300/5 out of 6961/5\n",
      "Last batch loss:30.2572 KDL: 3.86898 KLD %: 12.7869592559\n",
      "encoder inputs: the spices are perfect .\n",
      "decoder inputs: the spices are UNK .\n",
      "predictions: great taste are great .\n",
      "batch_ind/epoch: 2350/5 out of 6961/5\n",
      "Last batch loss:31.4897 KDL: 3.90861 KLD %: 12.4123573183\n",
      "encoder inputs: no more begging for food every 5 minutes .\n",
      "decoder inputs: UNK more UNK for UNK every 5 UNK .\n",
      "predictions: no more can you a to time minutes .\n",
      "batch_ind/epoch: 2400/5 out of 6961/5\n",
      "Last batch loss:28.875 KDL: 3.93926 KLD %: 13.6424664062\n",
      "encoder inputs: you 'll have to give it a try .\n",
      "decoder inputs: you 'll have to UNK it a try .\n",
      "predictions: they can be to try the on try .\n",
      "batch_ind/epoch: 2450/5 out of 6961/5\n",
      "Last batch loss:31.6346 KDL: 3.92667 KLD %: 12.4125811092\n",
      "encoder inputs: my stomach loves you .\n",
      "decoder inputs: my stomach loves you .\n",
      "predictions: my dogs loves these .\n",
      "batch_ind/epoch: 2500/5 out of 6961/5\n",
      "Last batch loss:31.3864 KDL: 3.84322 KLD %: 12.2448484441\n",
      "encoder inputs: it 's too much .\n",
      "decoder inputs: it UNK UNK much UNK\n",
      "predictions: it 's very good .\n",
      "batch_ind/epoch: 2550/5 out of 6961/5\n",
      "Last batch loss:28.6248 KDL: 4.05145 KLD %: 14.1536116581\n",
      "encoder inputs: and it worked out even better than the muffins .\n",
      "decoder inputs: UNK it UNK UNK UNK UNK than UNK muffins .\n",
      "predictions: and , 's a , , a i UNK .\n",
      "batch_ind/epoch: 2600/5 out of 6961/5\n",
      "Last batch loss:31.1234 KDL: 3.74253 KLD %: 12.0248064745\n",
      "encoder inputs: great real coconut young coconut taste .\n",
      "decoder inputs: great real coconut young coconut taste .\n",
      "predictions: great product chocolate and the water .\n",
      "batch_ind/epoch: 2650/5 out of 6961/5\n",
      "Last batch loss:32.0034 KDL: 3.9993 KLD %: 12.4964740172\n",
      "encoder inputs: i am very happy with this food ! ! !\n",
      "decoder inputs: UNK UNK UNK happy with this food ! ! !\n",
      "predictions: i 'm not to with this purchase .\n",
      "batch_ind/epoch: 2700/5 out of 6961/5\n",
      "Last batch loss:30.9572 KDL: 3.87771 KLD %: 12.5260381721\n",
      "encoder inputs: what do i do with it now ? ?\n",
      "decoder inputs: what UNK i do UNK it UNK ? UNK\n",
      "predictions: now a great say with like with ?\n",
      "batch_ind/epoch: 2750/5 out of 6961/5\n",
      "Last batch loss:28.932 KDL: 4.02582 KLD %: 13.9147689733\n",
      "encoder inputs: plus it 's rather noisy .\n",
      "decoder inputs: plus UNK UNK rather noisy UNK\n",
      "predictions: but , is is taste .\n",
      "batch_ind/epoch: 2800/5 out of 6961/5\n",
      "Last batch loss:27.093 KDL: 4.02131 KLD %: 14.8426246448\n",
      "encoder inputs: it overwhelms the flavor .\n",
      "decoder inputs: it overwhelms the UNK .\n",
      "predictions: the 's is best .\n",
      "batch_ind/epoch: 2850/5 out of 6961/5\n",
      "Last batch loss:29.5545 KDL: 3.87448 KLD %: 13.109621751\n",
      "encoder inputs: i strongly recommend this popcorn .\n",
      "decoder inputs: i UNK recommend this UNK .\n",
      "predictions: i love recommend this product anyone\n",
      "batch_ind/epoch: 2900/5 out of 6961/5\n",
      "Last batch loss:29.2736 KDL: 3.92155 KLD %: 13.3962143059\n",
      "encoder inputs: it smelled absolutely sinful while it brewed .\n",
      "decoder inputs: it UNK absolutely sinful UNK it UNK UNK\n",
      "predictions: it 's a delicious and and tastes .\n",
      "batch_ind/epoch: 2950/5 out of 6961/5\n",
      "Last batch loss:32.0562 KDL: 3.90898 KLD %: 12.1941533132\n",
      "encoder inputs: read every label peace\n",
      "decoder inputs: read UNK UNK peace\n",
      "predictions: UNK the labels . .\n",
      "batch_ind/epoch: 3000/5 out of 6961/5\n",
      "Last batch loss:31.7437 KDL: 3.93483 KLD %: 12.3955971335\n",
      "encoder inputs: the taste is very beef broth like .\n",
      "decoder inputs: the UNK is very UNK broth UNK .\n",
      "predictions: the taste is very good and UNK .\n",
      "batch_ind/epoch: 3050/5 out of 6961/5\n",
      "Last batch loss:32.0121 KDL: 3.9181 KLD %: 12.2394185827\n",
      "encoder inputs: i love it any time of the day .\n",
      "decoder inputs: i UNK UNK any time of the day UNK\n",
      "predictions: i love this the other of the UNK . .\n",
      "batch_ind/epoch: 3100/5 out of 6961/5\n",
      "Last batch loss:31.2953 KDL: 3.85409 KLD %: 12.3152646874\n",
      "encoder inputs: best thing i 've ordered on line .\n",
      "decoder inputs: best thing UNK 've ordered on UNK .\n",
      "predictions: the of i have found more amazon .\n",
      "batch_ind/epoch: 3150/5 out of 6961/5\n",
      "Last batch loss:28.7438 KDL: 3.91969 KLD %: 13.6366656357\n",
      "encoder inputs: you wo n't be disappointed .\n",
      "decoder inputs: you wo n't be UNK .\n",
      "predictions: you wo n't regret disappointed .\n",
      "batch_ind/epoch: 3200/5 out of 6961/5\n",
      "Last batch loss:32.0696 KDL: 3.96521 KLD %: 12.3643726187\n",
      "encoder inputs: these wasabi flavored roasted UNK are okay .\n",
      "decoder inputs: these UNK flavored roasted UNK are okay UNK\n",
      "predictions: will are are and to are great .\n",
      "batch_ind/epoch: 3250/5 out of 6961/5\n",
      "Last batch loss:29.1986 KDL: 3.81811 KLD %: 13.0763598141\n",
      "encoder inputs: enjoy ! gary peterson\n",
      "decoder inputs: UNK ! gary peterson\n",
      "predictions: great and ! peterson\n",
      "batch_ind/epoch: 3300/5 out of 6961/5\n",
      "Last batch loss:29.6479 KDL: 3.96854 KLD %: 13.3855601367\n",
      "encoder inputs: zico is still amazing .\n",
      "decoder inputs: zico is UNK UNK UNK\n",
      "predictions: he is a good .\n",
      "batch_ind/epoch: 3350/5 out of 6961/5\n",
      "Last batch loss:30.6492 KDL: 3.84124 KLD %: 12.5329243767\n",
      "encoder inputs: no bitterness at all .\n",
      "decoder inputs: no UNK at UNK UNK\n",
      "predictions: no more or all .\n",
      "batch_ind/epoch: 3400/5 out of 6961/5\n",
      "Last batch loss:28.7058 KDL: 3.86649 KLD %: 13.4693699846\n",
      "encoder inputs: only 100 calories per bag .\n",
      "decoder inputs: only 100 calories per bag .\n",
      "predictions: UNK one calories per serving .\n",
      "batch_ind/epoch: 3450/5 out of 6961/5\n",
      "Last batch loss:29.3456 KDL: 3.96612 KLD %: 13.5152283563\n",
      "encoder inputs: it works 85 % of the time .\n",
      "decoder inputs: it works 85 % UNK the time UNK\n",
      "predictions: it 's well for for and price .\n",
      "batch_ind/epoch: 3500/5 out of 6961/5\n",
      "Last batch loss:32.3429 KDL: 3.93421 KLD %: 12.164058734\n",
      "encoder inputs: the flavor is excellent UNK great .\n",
      "decoder inputs: the flavor is UNK UNK great .\n",
      "predictions: the UNK is very and too .\n",
      "batch_ind/epoch: 3550/5 out of 6961/5\n",
      "Last batch loss:31.4026 KDL: 3.86659 KLD %: 12.3129573646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder inputs: love this product !\n",
      "decoder inputs: love UNK product !\n",
      "predictions: love this stuff .\n",
      "batch_ind/epoch: 3600/5 out of 6961/5\n",
      "Last batch loss:29.1864 KDL: 3.77387 KLD %: 12.930205658\n",
      "encoder inputs: her baking mixes are UNK .\n",
      "decoder inputs: her UNK mixes are UNK .\n",
      "predictions: UNK coat is are great .\n",
      "batch_ind/epoch: 3650/5 out of 6961/5\n",
      "Last batch loss:32.4617 KDL: 4.02115 KLD %: 12.3873484676\n",
      "encoder inputs: price with subscribe and save is very good .\n",
      "decoder inputs: UNK UNK subscribe and save is UNK good UNK\n",
      "predictions: that is the and save is the it .\n",
      "batch_ind/epoch: 3700/5 out of 6961/5\n",
      "Last batch loss:30.5856 KDL: 3.97305 KLD %: 12.989937311\n",
      "encoder inputs: one end is covered with a sticker .\n",
      "decoder inputs: UNK UNK UNK covered UNK a sticker UNK\n",
      "predictions: so is is and and the UNK .\n",
      "batch_ind/epoch: 3750/5 out of 6961/5\n",
      "Last batch loss:28.5498 KDL: 4.0343 KLD %: 14.1307150117\n",
      "encoder inputs: they are all meat - absolutely nothing else .\n",
      "decoder inputs: UNK are UNK meat - absolutely nothing else .\n",
      "predictions: i are the and and very delicious . .\n",
      "batch_ind/epoch: 3800/5 out of 6961/5\n",
      "Last batch loss:30.5106 KDL: 3.83632 KLD %: 12.573721519\n",
      "encoder inputs: these cookies taste like the real thing !\n",
      "decoder inputs: these UNK UNK like UNK real thing !\n",
      "predictions: these are are are a UNK treat .\n",
      "batch_ind/epoch: 3850/5 out of 6961/5\n",
      "Last batch loss:31.4083 KDL: 3.9523 KLD %: 12.5836325027\n",
      "encoder inputs: ) , so give them a try .\n",
      "decoder inputs: ) , UNK give them a try UNK\n",
      "predictions: so , i is it a try .\n",
      "batch_ind/epoch: 3900/5 out of 6961/5\n",
      "Last batch loss:31.3732 KDL: 3.99452 KLD %: 12.7322636599\n",
      "encoder inputs: we definitely will be buying more .\n",
      "decoder inputs: UNK UNK will be buying more .\n",
      "predictions: we love this be buying more .\n",
      "batch_ind/epoch: 3950/5 out of 6961/5\n",
      "Last batch loss:35.1513 KDL: 4.10629 KLD %: 11.6817721487\n",
      "encoder inputs: too expensive for 15 minutes of entertainment .\n",
      "decoder inputs: too expensive UNK UNK minutes UNK UNK .\n",
      "predictions: even bad to the the to UNK .\n",
      "batch_ind/epoch: 4000/5 out of 6961/5\n",
      "Last batch loss:30.6018 KDL: 3.88525 KLD %: 12.6961335244\n",
      "encoder inputs: would definitely order this again and good price too !\n",
      "decoder inputs: would definitely order this UNK UNK good UNK too !\n",
      "predictions: do recommend recommend again again again again for again .\n",
      "batch_ind/epoch: 4050/5 out of 6961/5\n",
      "Last batch loss:31.75 KDL: 4.0075 KLD %: 12.6220448104\n",
      "encoder inputs: this however is delicious !\n",
      "decoder inputs: this however is delicious !\n",
      "predictions: this stuff is great .\n",
      "batch_ind/epoch: 4100/5 out of 6961/5\n",
      "Last batch loss:32.4247 KDL: 3.85021 KLD %: 11.8743138193\n",
      "encoder inputs: loved the spray !\n",
      "decoder inputs: loved UNK spray !\n",
      "predictions: UNK the UNK .\n",
      "batch_ind/epoch: 4150/5 out of 6961/5\n",
      "Last batch loss:25.6103 KDL: 3.92513 KLD %: 15.3264014717\n",
      "encoder inputs: not what i hoped for .\n",
      "decoder inputs: not what i hoped for .\n",
      "predictions: not a i was for .\n",
      "batch_ind/epoch: 4200/5 out of 6961/5\n",
      "Last batch loss:29.6781 KDL: 3.99762 KLD %: 13.4699374095\n",
      "encoder inputs: my kids love it too .\n",
      "decoder inputs: UNK kids UNK it UNK .\n",
      "predictions: my dog love these .\n",
      "batch_ind/epoch: 4250/5 out of 6961/5\n",
      "Last batch loss:29.1578 KDL: 4.00645 KLD %: 13.7405965472\n",
      "encoder inputs: it 's perfect for movie night !\n",
      "decoder inputs: it 's UNK for movie night !\n",
      "predictions: it is a and my theater .\n",
      "batch_ind/epoch: 4300/5 out of 6961/5\n",
      "Last batch loss:28.0872 KDL: 4.1045 KLD %: 14.6134466713\n",
      "encoder inputs: this large package lasts us a long time .\n",
      "decoder inputs: this large UNK lasts us UNK long UNK UNK\n",
      "predictions: this is size is a about a time .\n",
      "batch_ind/epoch: 4350/5 out of 6961/5\n",
      "Last batch loss:27.5179 KDL: 3.8616 KLD %: 14.0330331392\n",
      "encoder inputs: big plus for me .\n",
      "decoder inputs: UNK plus for me UNK\n",
      "predictions: very good it me .\n",
      "batch_ind/epoch: 4400/5 out of 6961/5\n",
      "Last batch loss:30.8473 KDL: 3.96291 KLD %: 12.846867118\n",
      "encoder inputs: perfect for snacking .\n",
      "decoder inputs: UNK for UNK UNK\n",
      "predictions: perfect for me .\n",
      "batch_ind/epoch: 4450/5 out of 6961/5\n",
      "Last batch loss:33.4937 KDL: 3.95129 KLD %: 11.7971043073\n",
      "encoder inputs: hard to tell that they are baked .\n",
      "decoder inputs: hard to UNK UNK they are UNK .\n",
      "predictions: good to find in in 're great .\n",
      "batch_ind/epoch: 4500/5 out of 6961/5\n",
      "Last batch loss:31.0886 KDL: 3.97468 KLD %: 12.7850181277\n",
      "encoder inputs: this yummy little baked confection was truly delicious .\n",
      "decoder inputs: UNK yummy little UNK confection was truly delicious UNK\n",
      "predictions: the flavor and UNK and to the exceptional .\n",
      "batch_ind/epoch: 4550/5 out of 6961/5\n",
      "Last batch loss:29.8548 KDL: 4.04022 KLD %: 13.5329064879\n",
      "encoder inputs: i was very happy with this product .\n",
      "decoder inputs: i UNK very happy with this UNK .\n",
      "predictions: i was not happy with this product .\n",
      "batch_ind/epoch: 4600/5 out of 6961/5\n",
      "Last batch loss:30.2538 KDL: 3.9687 KLD %: 13.1180232888\n",
      "encoder inputs: use this over rice for a meal !\n",
      "decoder inputs: UNK this UNK rice for a meal !\n",
      "predictions: but , is is is a gift .\n",
      "batch_ind/epoch: 4650/5 out of 6961/5\n",
      "Last batch loss:22.2279 KDL: 3.89428 KLD %: 17.5197392018\n",
      "encoder inputs: no heavy flavor .\n",
      "decoder inputs: no UNK UNK .\n",
      "predictions: no more here .\n",
      "batch_ind/epoch: 4700/5 out of 6961/5\n",
      "Last batch loss:27.9846 KDL: 4.00366 KLD %: 14.3066424055\n",
      "encoder inputs: everything about this product is excellent .\n",
      "decoder inputs: UNK about this product is excellent .\n",
      "predictions: so are the product is great .\n",
      "batch_ind/epoch: 4750/5 out of 6961/5\n",
      "Last batch loss:32.1234 KDL: 3.85778 KLD %: 12.0092514953\n",
      "encoder inputs: i love them !\n",
      "decoder inputs: i love UNK !\n",
      "predictions: i love it .\n",
      "batch_ind/epoch: 4800/5 out of 6961/5\n",
      "Last batch loss:28.4902 KDL: 4.01213 KLD %: 14.082456093\n",
      "encoder inputs: this year everyone is going to be happy !\n",
      "decoder inputs: this year UNK is UNK to UNK UNK !\n",
      "predictions: this product round is a for the UNK .\n",
      "batch_ind/epoch: 4850/5 out of 6961/5\n",
      "Last batch loss:27.0976 KDL: 4.06321 KLD %: 14.9947237014\n",
      "encoder inputs: these are the best tasting pretzels !\n",
      "decoder inputs: these are UNK best tasting pretzels !\n",
      "predictions: they are the best chips almonds .\n",
      "batch_ind/epoch: 4900/5 out of 6961/5\n",
      "Last batch loss:33.0636 KDL: 3.98041 KLD %: 12.0386611741\n",
      "encoder inputs: i do n't like overly sweet drinks .\n",
      "decoder inputs: UNK do n't like overly sweet drinks .\n",
      "predictions: i am n't recommend the sweet either .\n",
      "batch_ind/epoch: 4950/5 out of 6961/5\n",
      "Last batch loss:27.7945 KDL: 3.88819 KLD %: 13.9890834748\n",
      "encoder inputs: did you know it was invented by a doctor !\n",
      "decoder inputs: did UNK UNK it was invented UNK a doctor !\n",
      "predictions: my n't like the , a to to try ?\n",
      "batch_ind/epoch: 5000/5 out of 6961/5\n",
      "Last batch loss:29.0104 KDL: 3.93316 KLD %: 13.5577715455\n",
      "encoder inputs: the tea is delicious .\n",
      "decoder inputs: the tea UNK UNK UNK\n",
      "predictions: this price is great .\n",
      "batch_ind/epoch: 5050/5 out of 6961/5\n",
      "Last batch loss:28.4538 KDL: 3.84341 KLD %: 13.5075437391\n",
      "encoder inputs: good price even with the shipping costs .\n",
      "decoder inputs: good price even with the UNK costs UNK\n",
      "predictions: the price , a a other UNK .\n",
      "batch_ind/epoch: 5100/5 out of 6961/5\n",
      "Last batch loss:27.6919 KDL: 4.04659 KLD %: 14.6128914922\n",
      "encoder inputs: thank you cesar !\n",
      "decoder inputs: thank you cesar !\n",
      "predictions: thank you amazon !\n",
      "batch_ind/epoch: 5150/5 out of 6961/5\n",
      "Last batch loss:28.9218 KDL: 4.04285 KLD %: 13.9785453083\n",
      "encoder inputs: recipe available on UNK `` chocolate biscuit cake . ''\n",
      "decoder inputs: recipe available on UNK `` chocolate UNK cake . ''\n",
      "predictions: so , with amazon and subscribe '' '' .\n",
      "batch_ind/epoch: 5200/5 out of 6961/5\n",
      "Last batch loss:32.1618 KDL: 3.89169 KLD %: 12.1003308016\n",
      "encoder inputs: this xylitol in packets is very chalky in taste .\n",
      "decoder inputs: this xylitol in UNK is very UNK in taste .\n",
      "predictions: this product is the and a good and comparison .\n",
      "batch_ind/epoch: 5250/5 out of 6961/5\n",
      "Last batch loss:31.8766 KDL: 3.96167 KLD %: 12.4281346814\n",
      "encoder inputs: even the hot coco has the artificial sweetener .\n",
      "decoder inputs: even the hot coco has UNK UNK sweetener .\n",
      "predictions: a my pickiest chocolate is a great . .\n",
      "batch_ind/epoch: 5300/5 out of 6961/5\n",
      "Last batch loss:27.4358 KDL: 4.04521 KLD %: 14.7442506325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder inputs: ca n't beat that !\n",
      "decoder inputs: ca UNK beat that !\n",
      "predictions: will n't beat that .\n",
      "batch_ind/epoch: 5350/5 out of 6961/5\n",
      "Last batch loss:32.852 KDL: 3.8567 KLD %: 11.7396146137\n",
      "encoder inputs: she devours every bite .\n",
      "decoder inputs: she devours every UNK .\n",
      "predictions: i always them too .\n",
      "batch_ind/epoch: 5400/5 out of 6961/5\n",
      "Last batch loss:31.3959 KDL: 3.99465 KLD %: 12.7234803853\n",
      "encoder inputs: this really tastes like ginger and honey !\n",
      "decoder inputs: UNK really tastes UNK UNK and honey !\n",
      "predictions: this is is like and the UNK .\n",
      "batch_ind/epoch: 5450/5 out of 6961/5\n",
      "Last batch loss:34.2866 KDL: 3.99716 KLD %: 11.6580936318\n",
      "encoder inputs: i could n't be happier !\n",
      "decoder inputs: i could n't be happier UNK\n",
      "predictions: i was n't believe happier .\n",
      "batch_ind/epoch: 5500/5 out of 6961/5\n",
      "Last batch loss:27.6912 KDL: 4.13157 KLD %: 14.920146032\n",
      "encoder inputs: my havanese just loves these treats with the apples !\n",
      "decoder inputs: my havanese UNK loves these treats UNK the apples !\n",
      "predictions: my dog loves the these and for the best .\n",
      "batch_ind/epoch: 5550/5 out of 6961/5\n",
      "Last batch loss:30.2144 KDL: 4.14457 KLD %: 13.7172099755\n",
      "encoder inputs: all six cans were rancid .\n",
      "decoder inputs: all six cans were rancid .\n",
      "predictions: then the of were dented .\n",
      "batch_ind/epoch: 5600/5 out of 6961/5\n",
      "Last batch loss:35.4504 KDL: 3.89288 KLD %: 10.981221119\n",
      "encoder inputs: this particular one is the mild sweet style .\n",
      "decoder inputs: this UNK UNK is the mild sweet style .\n",
      "predictions: the tea is is a best flavor . .\n",
      "batch_ind/epoch: 5650/5 out of 6961/5\n",
      "Last batch loss:31.0761 KDL: 4.05651 KLD %: 13.0534675059\n",
      "encoder inputs: i wanted to love these .\n",
      "decoder inputs: UNK UNK to love these .\n",
      "predictions: i love this buy it .\n",
      "batch_ind/epoch: 5700/5 out of 6961/5\n",
      "Last batch loss:30.0781 KDL: 3.99519 KLD %: 13.2827326328\n",
      "encoder inputs: however , the UNK process is UNK .\n",
      "decoder inputs: UNK UNK the UNK process UNK UNK .\n",
      "predictions: and , , price is is it .\n",
      "batch_ind/epoch: 5750/5 out of 6961/5\n",
      "Last batch loss:33.6307 KDL: 3.9792 KLD %: 11.8320585793\n",
      "encoder inputs: on to a chinese type dish next .\n",
      "decoder inputs: on to a UNK UNK dish UNK .\n",
      "predictions: not the the UNK of of UNK .\n",
      "batch_ind/epoch: 5800/5 out of 6961/5\n",
      "Last batch loss:30.4443 KDL: 4.12138 KLD %: 13.5374445481\n",
      "encoder inputs: would n't have it any other way !\n",
      "decoder inputs: would UNK have UNK any other UNK UNK\n",
      "predictions: my definitely recommend to to other . .\n",
      "batch_ind/epoch: 5850/5 out of 6961/5\n",
      "Last batch loss:31.4383 KDL: 3.91216 KLD %: 12.4439170234\n",
      "encoder inputs: and far more nutritious than a standard fruit snack .\n",
      "decoder inputs: and UNK more UNK than a standard fruit snack UNK\n",
      "predictions: just it 's than than the few a punch .\n",
      "batch_ind/epoch: 5900/5 out of 6961/5\n",
      "Last batch loss:32.1509 KDL: 4.06172 KLD %: 12.6333194315\n",
      "encoder inputs: i had my package within 4 days .\n",
      "decoder inputs: i had my package within 4 days .\n",
      "predictions: i have to first in 2 years later\n",
      "batch_ind/epoch: 5950/5 out of 6961/5\n",
      "Last batch loss:24.5843 KDL: 3.94706 KLD %: 16.0552251335\n",
      "encoder inputs: i love the convenience of the auto ship program .\n",
      "decoder inputs: UNK UNK the convenience of the UNK UNK program .\n",
      "predictions: i have n't UNK and this tea of UNK .\n",
      "batch_ind/epoch: 6000/5 out of 6961/5\n",
      "Last batch loss:34.3401 KDL: 3.7004 KLD %: 10.7757174661\n",
      "encoder inputs: friends of ours were in from great britain .\n",
      "decoder inputs: friends of ours were in UNK great britain .\n",
      "predictions: a , the that not a , tasting .\n",
      "batch_ind/epoch: 6050/5 out of 6961/5\n",
      "Last batch loss:32.4744 KDL: 3.92309 KLD %: 12.0805462156\n",
      "encoder inputs: skip this one .\n",
      "decoder inputs: skip UNK UNK .\n",
      "predictions: thanks this UNK .\n",
      "batch_ind/epoch: 6100/5 out of 6961/5\n",
      "Last batch loss:27.9721 KDL: 3.7266 KLD %: 13.3225410095\n",
      "encoder inputs: they are really amazing .\n",
      "decoder inputs: they UNK UNK amazing .\n",
      "predictions: these are very good .\n",
      "batch_ind/epoch: 6150/5 out of 6961/5\n",
      "Last batch loss:27.0075 KDL: 4.08237 KLD %: 15.1157235705\n",
      "encoder inputs: this is a dark , chocolaty UNK .\n",
      "decoder inputs: this UNK UNK dark , chocolaty UNK .\n",
      "predictions: this is a best roast rich coffee .\n",
      "batch_ind/epoch: 6200/5 out of 6961/5\n",
      "Last batch loss:27.1215 KDL: 4.1423 KLD %: 15.2731083247\n",
      "encoder inputs: i contacted the seller but got no response .\n",
      "decoder inputs: i contacted the seller UNK got UNK response .\n",
      "predictions: i have the UNK and the this UNK .\n",
      "batch_ind/epoch: 6250/5 out of 6961/5\n",
      "Last batch loss:31.2474 KDL: 3.95087 KLD %: 12.6438090376\n",
      "encoder inputs: most importantly my house is bug free .\n",
      "decoder inputs: UNK importantly my UNK is bug free UNK\n",
      "predictions: then , , first love UNK . .\n",
      "batch_ind/epoch: 6300/5 out of 6961/5\n",
      "Last batch loss:31.2345 KDL: 3.91268 KLD %: 12.526769526\n",
      "encoder inputs: no nasty aftertaste .\n",
      "decoder inputs: UNK nasty UNK .\n",
      "predictions: no a it .\n",
      "batch_ind/epoch: 6350/5 out of 6961/5\n",
      "Last batch loss:33.258 KDL: 4.01439 KLD %: 12.0704354083\n",
      "encoder inputs: catches everything from UNK to UNK .\n",
      "decoder inputs: catches everything from UNK to UNK .\n",
      "predictions: the product is the UNK me .\n",
      "batch_ind/epoch: 6400/5 out of 6961/5\n",
      "Last batch loss:35.016 KDL: 4.14489 KLD %: 11.8371312913\n",
      "encoder inputs: give it a try , it 's delicious !\n",
      "decoder inputs: give it a UNK UNK it 's UNK !\n",
      "predictions: even it a try you you 's great .\n",
      "batch_ind/epoch: 6450/5 out of 6961/5\n",
      "Last batch loss:31.6227 KDL: 3.94161 KLD %: 12.4645033855\n",
      "encoder inputs: really delicious seasoning and UNK that i highly recommend .\n",
      "decoder inputs: really delicious UNK UNK UNK UNK UNK highly UNK .\n",
      "predictions: when like , , , , a the recommended .\n",
      "batch_ind/epoch: 6500/5 out of 6961/5\n",
      "Last batch loss:32.021 KDL: 3.91024 KLD %: 12.2114907175\n",
      "encoder inputs: not just pleasantly surprised but actually amazed .\n",
      "decoder inputs: UNK just UNK surprised but actually amazed .\n",
      "predictions: and i like n't to not like it\n",
      "batch_ind/epoch: 6550/5 out of 6961/5\n",
      "Last batch loss:31.8249 KDL: 4.02289 KLD %: 12.6406788653\n",
      "encoder inputs: plus they 're biodegradable !\n",
      "decoder inputs: UNK they 're biodegradable !\n",
      "predictions: thanks it are great !\n",
      "batch_ind/epoch: 6600/5 out of 6961/5\n",
      "Last batch loss:31.1434 KDL: 3.83164 KLD %: 12.3032123091\n",
      "encoder inputs: the cats love it .\n",
      "decoder inputs: UNK cats love it UNK\n",
      "predictions: the product love it .\n",
      "batch_ind/epoch: 6650/5 out of 6961/5\n",
      "Last batch loss:30.3859 KDL: 4.0458 KLD %: 13.3147191648\n",
      "encoder inputs: somehow it turned salty soapy very bitter taste .\n",
      "decoder inputs: somehow it turned salty soapy very bitter taste .\n",
      "predictions: after it is out , stars little taste .\n",
      "batch_ind/epoch: 6700/5 out of 6961/5\n",
      "Last batch loss:26.2206 KDL: 4.12924 KLD %: 15.7480442689\n",
      "encoder inputs: you choose how often to receive delivery .\n",
      "decoder inputs: you choose how often UNK receive delivery .\n",
      "predictions: she can to can this this them .\n",
      "batch_ind/epoch: 6750/5 out of 6961/5\n",
      "Last batch loss:30.0298 KDL: 4.06871 KLD %: 13.5489259926\n",
      "encoder inputs: there is no nasty after taste or any jitters .\n",
      "decoder inputs: UNK is no nasty UNK taste or any jitters UNK\n",
      "predictions: it 's a longer , or or trans kind .\n",
      "batch_ind/epoch: 6800/5 out of 6961/5\n",
      "Last batch loss:30.793 KDL: 3.88297 KLD %: 12.6099446197\n",
      "encoder inputs: amazon , of course , popped up !\n",
      "decoder inputs: amazon , of course UNK UNK up !\n",
      "predictions: you has i course , 's it .\n",
      "batch_ind/epoch: 6850/5 out of 6961/5\n",
      "Last batch loss:26.8741 KDL: 3.95302 KLD %: 14.7093949129\n",
      "encoder inputs: this brand is the best tasting to me .\n",
      "decoder inputs: this brand is the best tasting UNK UNK UNK\n",
      "predictions: this coffee is a best i coffee ever .\n",
      "batch_ind/epoch: 6900/5 out of 6961/5\n",
      "Last batch loss:29.284 KDL: 4.00385 KLD %: 13.6724754165\n",
      "encoder inputs: i would recommend these for kids and adults !\n",
      "decoder inputs: UNK would recommend these for kids UNK adults !\n",
      "predictions: i love recommend this to my and adults .\n",
      "batch_ind/epoch: 6950/5 out of 6961/5\n",
      "Last batch loss:32.5699 KDL: 3.98622 KLD %: 12.2389796296\n",
      "encoder inputs: it is simply superior rice .\n",
      "decoder inputs: it is simply superior UNK .\n",
      "predictions: it is a the . .\n",
      "WARNING:tensorflow:Error encountered when serializing model_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'bytes' object has no attribute 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: %ssave/VAE-0\n",
      "execution took: 66215.46722812699 seconds\n"
     ]
    }
   ],
   "source": [
    "losses,kll_losses=train(load=True,keep_prob=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring saved parameters\n",
      "INFO:tensorflow:Restoring parameters from save\\VAE-0\n",
      "output shape for latent out: (4, 2, 696136, 32)\n"
     ]
    }
   ],
   "source": [
    "input_sent=encoder_inputs_full\n",
    "#printsentence(input_sent,reverse=True)\n",
    "\n",
    "#Give latent outputs shape is (return list (mu, sigma, logsigma),(cell state, outputstate),number of number of sentences,latent variables)\n",
    "latent_out=Givelatent(input_sent)\n",
    "print('output shape for latent out:',np.shape(latent_out))\n",
    "\n",
    "#we only care about mu,cell state, number of sentences and latent variables, shape will be [sentences, latent_var]\n",
    "latent_var=latent_out[0]\n",
    "mus_out_cell=latent_out[0][0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#map them to correctr form        \n",
    "latent_var=np.transpose(latent_var, (1, 0, 2))\n",
    "datalen=np.shape(latent_var)[0]\n",
    "reshaped=np.reshape(latent_var, (datalen, -1))\n",
    "\n",
    "#rereshaped=np.reshape(latent_var, (datalen,2, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores: [ 1.31392154  1.31320906  1.3151783   1.31570079]\n",
      "CV scores: [ 1.31549043  1.31515025  1.31376106  1.31365423]\n",
      "CV scores: [ 1.31601116  1.31319544  1.31140979  1.3175115 ]\n"
     ]
    }
   ],
   "source": [
    "#do prediction\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(reshaped, sentence_scores) #calculate the parameters\n",
    "\n",
    "for i in range(3):\n",
    "    kfold=KFold(n_splits=4, shuffle=True) #random_state=None)\n",
    "    print('CV scores:',np.sqrt(-cross_val_score(linreg, reshaped, sentence_scores, scoring=\"neg_mean_squared_error\", cv = kfold))) \n",
    "\n",
    "#linreg.coef_ contains the coefficients so the positivity axis will be\n",
    "pos_axis=linreg.coef_/np.sqrt(sum(linreg.coef_*linreg.coef_))\n",
    "#reshape back to normal\n",
    "pos_axis_z=np.reshape(pos_axis, (2, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring saved parameters\n",
      "INFO:tensorflow:Restoring parameters from save\\VAE-0\n",
      "Restoring saved parameters\n",
      "INFO:tensorflow:Restoring parameters from save\\VAE-0\n",
      "original: . heavy very are these\n",
      "shifted: \n",
      "original: . thawed slightly arrived\n",
      "shifted: \n",
      "original: . it accept n't would parents my\n",
      "shifted: for\n",
      "original: . perfect are tarts these on crust the\n",
      "shifted: for and size . .\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_sent_en=encoder_inputs_full[:,111:115]\n",
    "input_sent_de=encoder_inputs_full[:,111:115]\n",
    "\n",
    "\n",
    "positivity=0.5#-0.1\n",
    "\n",
    "#Give latent outputs shape is (return list (mu, sigma, logsigma),(cell state, outputstate),number of number of sentences,latent variables)\n",
    "latent_out=Givelatent(input_sent_en)\n",
    "\n",
    "\n",
    "#fix the positivity axis to match the criteria\n",
    "pos_axis_z_batch=np.expand_dims(pos_axis_z,axis=1)\n",
    "\n",
    "pos_axis_z_batch = [pos_axis_z for _ in range(np.shape(input_sent_en)[1])]\n",
    "pos_axis_z_batch = np.stack(pos_axis_z_batch, axis=1)\n",
    "\n",
    "\n",
    "#scale the shifting with the corresponding sigma, move from the means\n",
    "latent_shifted=latent_out[0]+pos_axis_z_batch*positivity*latent_out[1]\n",
    "\n",
    "\n",
    "\n",
    "decoder_out=Giveoutput_fromlatent(latent_shifted,input_sent_de,decoder_inputmode='target')\n",
    "\n",
    "for sent_ind in range(np.shape(decoder_out)[1]):\n",
    "\n",
    "    print('original:',printsentence(input_sent_en[:,sent_ind],reverse=True))\n",
    "    print('shifted:',printsentence(decoder_out[:,sent_ind]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring saved parameters\n",
      "INFO:tensorflow:Restoring parameters from save\\VAE-0\n",
      "(11, 4)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoder_out=Giveoutput_fromlatent(latent_shifted,input_sent_de,decoder_inputmode='target')\n",
    "\n",
    "print(np.shape(decoder_out))\n",
    "for sent_ind in range(np.shape(decoder_out)[1]):\n",
    "\n",
    "    print(printsentence(decoder_out[:,sent_ind]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring saved parameters\n",
      "INFO:tensorflow:Restoring parameters from save\\VAE-0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimension 0 in both shapes must be equal, but are 696136 and 2 for 'Assign_2' (op: 'Assign') with input shapes: [696136,6,20], [2,?,?].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[0;32m    670\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[0;32m    672\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimension 0 in both shapes must be equal, but are 696136 and 2 for 'Assign_2' (op: 'Assign') with input shapes: [696136,6,20], [2,?,?].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-d35c01004744>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mlatent_var_in\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mdecoder_out\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mGiveoutput_fromlatent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_var_in\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_sent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoder_inputmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-102-7c18b2567171>\u001b[0m in \u001b[0;36mGiveoutput_fromlatent\u001b[1;34m(latent_var_in, input_sentences, decoder_inputmode)\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[0mz_holder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m     \u001b[0mlatent_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshapein\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m     \u001b[0massign_z\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlatent_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_holder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;31m#assign z\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(self, value, use_locking)\u001b[0m\n\u001b[0;32m    514\u001b[0m       \u001b[0mthe\u001b[0m \u001b[0massignment\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m     \"\"\"\n\u001b[1;32m--> 516\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mstate_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0massign_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[0;32m    269\u001b[0m     return gen_state_ops.assign(\n\u001b[0;32m    270\u001b[0m         \u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m         validate_shape=validate_shape)\n\u001b[0m\u001b[0;32m    272\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[0;32m     43\u001b[0m   result = _op_def_lib.apply_op(\"Assign\", ref=ref, value=value,\n\u001b[0;32m     44\u001b[0m                                 \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m                                 use_locking=use_locking, name=name)\n\u001b[0m\u001b[0;32m     46\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    765\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    766\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    768\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   2506\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[0;32m   2507\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2508\u001b[1;33m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2509\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2510\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1871\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1872\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1873\u001b[1;33m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1874\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1875\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1821\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[0;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[0;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[0;32m    611\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m       \u001b[1;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[0;32m    674\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimension 0 in both shapes must be equal, but are 696136 and 2 for 'Assign_2' (op: 'Assign') with input shapes: [696136,6,20], [2,?,?]."
     ]
    }
   ],
   "source": [
    "z1=latent_var[:,0,:]\n",
    "z2=latent_var[:,1,:]\n",
    "\n",
    "tvalues=[0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "inputlist=[z1*(1-t)+z2*t for t in tvalues]\n",
    "\n",
    "#input doesn't matter since the decoder works in greedy prediction mode\n",
    "input_sent=encoder_inputs_full[:,:6]\n",
    "\n",
    "latent_var_in=np.stack(inputlist, axis=1)\n",
    "\n",
    "decoder_out=Giveoutput_fromlatent(latent_var_in,input_sent,decoder_inputmode='target')\n",
    "\n",
    "print(np.shape(decoder_out))\n",
    "for sent_ind in range(np.shape(decoder_out)[1]):\n",
    "\n",
    "    print(printsentence(decoder_out[:,sent_ind]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    #has to be modified for lstm\n",
    "    #cell_state =decoder_initial_state[0,:,:] \n",
    "    #output_state =decoder_initial_state[1,:,:] \n",
    "    \n",
    "    #unpack for list which to loop over and feed it as input\n",
    "    #inputs=tf.unstack(decoder_inputs_embedded,num=max_sent_len+1)\n",
    "    #decoder_prediction_list=[]\n",
    "    #decoder_logits_list=[]\n",
    "        \n",
    "    #set up initial input and state\n",
    "    #state = (cell_state,output_state)\n",
    "    #input_in=inputs[0]\n",
    "    \n",
    "    #for input_ in inputs:\n",
    "        \n",
    "        \n",
    "#        if decoder_inputmode=='target':\n",
    "#            input_in=input_\n",
    "            \n",
    "#        output, state = decoder_cell.__call__(input_in, state,scope='manual_decoder')\n",
    "        \n",
    "#        print(decoder_cell)\n",
    "\n",
    "        #map the decoder output to words as logits\n",
    "#        decoder_logits=tf.contrib.layers.fully_connected(output, vocab_size,activation_fn=None,\n",
    "                                                         scope='lstm_to_logits',reuse=reusing)\n",
    "\n",
    "        #take a greedy prediction\n",
    "#        prediction=tf.argmax(decoder_logits, 1)\n",
    "#        decoder_prediction_list.append(prediction)\n",
    "        \n",
    "        #feed the prediction as a next input\n",
    "#        if decoder_inputmode=='prediction':\n",
    "#            input_in=tf.nn.embedding_lookup(embeddings, prediction)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
